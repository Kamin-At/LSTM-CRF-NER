{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import regex as re\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from allennlp.modules.conditional_random_field import ConditionalRandomField\n",
    "from allennlp.modules.conditional_random_field import allowed_transitions\n",
    "from allennlp.modules.lstm_cell_with_projection import LstmCellWithProjection\n",
    "from allennlp.modules.input_variational_dropout import InputVariationalDropout\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#from torchcrf import CRF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "from torchnlp.nn import WeightDropLSTM\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "from typing import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn_crfsuite import metrics\n",
    "from torchnlp.nn import WeightDropGRU\n",
    "from RULE import RULEs\n",
    "from POSMap import POSMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataloader(Dataset):\n",
    "    def __init__(self, TextDir: '.txt extension of samples', LabelDir: '.txt extension of labels',rules:\\\n",
    "                 'the rules to be replaced => see in RULE.py', Len_word_vec: 'size of word vector', \\\n",
    "                delimiter: '(str) delimiter used to separate data', dir_char_dictionary: \\\n",
    "                '(str) see in CharEmbedding', max_len_char: '(int) see in CharEmbedding', \\\n",
    "                fasttext_dictionary_dir: '(str) see in WordEmbedding',\\\n",
    "                Len_embedded_vector: '(int) see in WordEmbedding', device, POSDir: '(str) .txt extension of POS',\\\n",
    "                POSMapping: 'see in POSMap.py') -> None:\n",
    "        super().__init__()\n",
    "        self.DF = pd.read_csv(TextDir, names=['text'])\n",
    "        self.Label_DF = pd.read_csv(LabelDir, names=['text'])\n",
    "        self.pos_DF = pd.read_csv(POSDir, names=['text'])\n",
    "        self.rules = rules\n",
    "        self.Len_word_vec = Len_word_vec\n",
    "        self.delimiter = delimiter\n",
    "        self.char_embedder = CharEmbedding(dir_char_dictionary, max_len_char)\n",
    "        self.word_embedder = WordEmbedding(fasttext_dictionary_dir, Len_embedded_vector)\n",
    "        self.device = device\n",
    "        self.pos_embedder = POSEmbedding(POSMapping)\n",
    "    def __len__(self):\n",
    "        return len(self.DF)\n",
    "    def __getitem__(self, Index) -> '(sample: (torch.tensor), label: (torch.tensor))':\n",
    "        all_words = [word.strip() for word in self.DF['text'][Index].strip().split(self.delimiter)]\n",
    "        for i in range(len(all_words)):\n",
    "            for rule in self.rules:\n",
    "                all_words[i] = re.sub(*rule, all_words[i])\n",
    "        Label = [float(word.strip()) for word in self.Label_DF['text'][Index].strip().split(self.delimiter)]\n",
    "        mask = [1.0]*len(all_words)\n",
    "        POS = [pos.strip() for pos in self.pos_DF['text'][Index].strip().split(self.delimiter)]\n",
    "        tmp_length = len(all_words)\n",
    "        if len(all_words) < self.Len_word_vec:\n",
    "            Label = Label + [3.0]*(self.Len_word_vec - len(all_words))\n",
    "            mask = mask + [0.0]*(self.Len_word_vec - len(all_words))\n",
    "            POS = POS + ['<pad>']*(self.Len_word_vec - len(all_words))\n",
    "            all_words = all_words + ['<pad>']*(self.Len_word_vec - len(all_words))\n",
    "        char_embed = self.char_embedder.embed(all_words)\n",
    "        word_embed = self.word_embedder.embed(all_words)\n",
    "        pos_embed = self.pos_embedder.embed(POS)\n",
    "        # print(len(all_words))\n",
    "        # print(len(Label))\n",
    "        # print(len(mask))\n",
    "        # print('----------')\n",
    "        return (char_embed.to(self.device), word_embed.to(self.device), \\\n",
    "                torch.tensor(Label).to(self.device), torch.tensor(mask).to(self.device), \\\n",
    "                tmp_length, pos_embed.float().to(self.device))\n",
    "    \n",
    "\n",
    "class CharEmbedding():\n",
    "    def __init__(self,\\\n",
    "    dir_char_dictionary: '(str) .txt',\\\n",
    "    max_len_char: '(int) max size of char representation, for example: given max_len_char=3 and word= \"abcde\" => only \"abc\" is used'):\n",
    "    #Example: given embed_capital=True and 'a' is embedded as array([1.,0.,0.,0.,0]). 'A' is then embedded as array([1.,0.,0.,0.,1.])\n",
    "        self.dictionary = {}\n",
    "        self.max_len_char = max_len_char\n",
    "        with open(dir_char_dictionary, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                tmp_data = line.strip().split()\n",
    "                self.dictionary[tmp_data[0]] = np.array([float(Char) for Char in tmp_data[1:]])\n",
    "    def embed(self, list_of_words: '(list[str]) example: [\"ฉัน\",\"กิน\",\"ข้าว\"]'):\n",
    "        #Note: 1 outer list is for 1 word.\n",
    "        output = []\n",
    "        for word in list_of_words:\n",
    "            embedded_word = []\n",
    "            tmp_word = word\n",
    "            if len(word) > self.max_len_char:\n",
    "                tmp_word = tmp_word[:self.max_len_char]\n",
    "            for Char in tmp_word:\n",
    "                if Char in self.dictionary:\n",
    "                    tmp_vector = self.dictionary[Char]\n",
    "                else:\n",
    "                    tmp_vector = np.zeros(self.dictionary['a'].shape)\n",
    "                embedded_word.append(tmp_vector)\n",
    "            if len(embedded_word) < self.max_len_char:\n",
    "                for i in range(self.max_len_char - len(embedded_word)):\n",
    "                    embedded_word.append(np.zeros(self.dictionary['a'].shape))\n",
    "            output.append(torch.tensor(embedded_word))\n",
    "        return torch.stack(output)\n",
    "\n",
    "class WordEmbedding():\n",
    "    #use fasttext embedding ==> read from a file\n",
    "    def __init__(self, fasttext_dictionary_dir: '(str) .vec extension of words and embedded_vectors',\\\n",
    "     Len_embedded_vector: '(int) size of embedded each vector (300 for fasttext) **Count only numbers not words'\\\n",
    "     ) -> None:\n",
    "        #example of format in fasttext_dictionary_dir\n",
    "        #กิน 1.0 -2.666 -3 22.5 .... \\n\n",
    "        #นอน 1.5 -5.666 3 9.5 .... \\n\n",
    "        #...\n",
    "        #...\n",
    "        self.dictionary = {}\n",
    "        self.Len_embedded_vector = Len_embedded_vector\n",
    "        with open(fasttext_dictionary_dir, 'r', encoding = 'utf8') as f:\n",
    "            for line in f:\n",
    "                tmp_line = line.strip()\n",
    "                tmp_words = tmp_line.split()\n",
    "                if tmp_line != '' and len(tmp_words) == self.Len_embedded_vector + 1:\n",
    "                    self.dictionary[tmp_words[0]] = np.array([float(element) for element in tmp_words[1:]])\n",
    "                else:\n",
    "                    continue\n",
    "    def embed(self, list_of_words: '(List[str]) for example: [\"ฉัน\",\"กิน\",\"ข้าว\"]'):\n",
    "        tmp_list = []\n",
    "        for word in list_of_words:\n",
    "            if word in self.dictionary:\n",
    "                tmp_list.append(self.dictionary[word])\n",
    "            else:\n",
    "                #in case of OOV: Zero-vector is used.\n",
    "                tmp_list.append(np.zeros(self.Len_embedded_vector))\n",
    "        return torch.tensor(tmp_list)\n",
    "\n",
    "class POSEmbedding():\n",
    "    def __init__(self, POSMapping: 'see in POSMap.py'):\n",
    "        self.dictionary = POSMapping\n",
    "        self.size = len(self.dictionary)\n",
    "    def embed(self, list_of_POSs:'(list[str]) example: [\"NOUN\",\"VERB\",\"NOUN\"]'):\n",
    "        tmp_list = []\n",
    "        for POS in list_of_POSs:\n",
    "            POS = POS.strip()\n",
    "            if POS == '<pad>':\n",
    "                tmp_list.append(np.zeros(self.size))\n",
    "            else:\n",
    "                tmp_data = np.zeros(self.size)\n",
    "                tmp_data[self.dictionary[POS]] = 1\n",
    "                tmp_list.append(tmp_data)\n",
    "        return torch.tensor(tmp_list)\n",
    "\n",
    "#new\n",
    "############### RNN encoding ######################\n",
    "# class CNN_char(nn.Module):\n",
    "#     def __init__(self, num_filter: '()'):\n",
    "\n",
    "#         class My2DConv(nn.Module):\n",
    "#     def __init__(self, num_filter: '(int) number of filters', use_BN: '(bool) if True, use 2d-batchnorm after linear conv',\\\n",
    "#                  activation_func: '(bool) if True, use RELU after BN', input_channel: '(int) number of input channels', \\\n",
    "#                  kernel_size: '(tuple): (width, height) size of the kernels', same_padding: '(bool) if True, input_w,input_h=output_w,output_h'):\n",
    "#         super().__init__()\n",
    "\n",
    "class RNN_char(nn.Module):\n",
    "    def __init__(self, num_char_vec_features, hidden_size, num_layers, dropout_gru, bidirectional, \\\n",
    "                output_size, dropout_FCN, num_word):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=num_char_vec_features, hidden_size=hidden_size, num_layers=num_layers,\\\n",
    "                          batch_first = True, dropout=dropout_gru, bidirectional=bidirectional)\n",
    "        self.linear = nn.Linear(hidden_size*2*num_layers, output_size)\n",
    "        self.BN = nn.BatchNorm1d(num_word)\n",
    "        self.dropout = nn.Dropout(dropout_FCN)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self, x):\n",
    "        batch_size, word_seq, char_seq, char_vec = x.size()\n",
    "        tmp_list = []\n",
    "        for i in range(word_seq):\n",
    "            tmp_compute , _ = self.gru(x[:,i,:,:].float())\n",
    "            tmp_list.append(tmp_compute.contiguous().view(batch_size,-1))\n",
    "        tmp_compute = torch.stack(tmp_list,1)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_compute = self.dropout(tmp_compute)\n",
    "        tmp_compute = self.linear(tmp_compute)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_compute = F.relu(self.BN(tmp_compute))#>>linear >> BachNorm >> relu\n",
    "        return tmp_compute\n",
    "    \n",
    "class over_all_NER2(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 num_char_vec_features: '(int)',\\\n",
    "                 hidden_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 dropout_gru_char: '(double)',\\\n",
    "                 bidirectional_char: '(bool)',\\\n",
    "                 output_char_embed_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)',\\\n",
    "                 pos_size: '(int) size of pos embedding',\n",
    "                 DO_GRU_out):\n",
    "        super().__init__()\n",
    "        self.gru_char = RNN_char(num_char_vec_features, hidden_size, max_num_char, dropout_gru_char, \\\n",
    "                                 bidirectional_char, output_char_embed_size, DOchar_FCN, num_words)\n",
    "        self.gru_crf_layer = gru_crf(size_of_embedding + output_char_embed_size + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, DO_FCN_GRUCRF, DO_GRU_out)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.gru_char(x[0])\n",
    "        #print(tmp_compute.size())\n",
    "        #print(x[1].size())\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.gru_char(x[0])\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "class CNN_GRU_CRF(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 nums_filter: '(list[int] see in overall_char_embedding)',\\\n",
    "                 use_BN: '(bool) only for CNNchar',\\\n",
    "                 activation_func: '(bool) only for CNNchar',\\\n",
    "                 input_channel: '(int) see in My2DConv',\\\n",
    "                 kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\\\n",
    "                 same_padding: '(bool) same padding for CNNchar',\\\n",
    "                 num_char_encoding_size: '(int) size of each char embedding vector',\\\n",
    "                 output_size: '(int) output dimension of CNNchar',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)',\\\n",
    "                 pos_size: '(int) size of pos embedding',\\\n",
    "                 FCN: '(bool) see overall_char_embedding',\\\n",
    "                 drop_weight):\n",
    "        super().__init__()\n",
    "        if not FCN:\n",
    "            output_size = num_char_encoding_size\n",
    "        #print(f'output_size: {output_size}')\n",
    "        self.overall_char_embedding = overall_char_embedding((Batch_size, output_size), max_num_char, \\\n",
    "                                                             nums_filter, use_BN, activation_func, \\\n",
    "                                                             input_channel, kernel_sizes, same_padding, \\\n",
    "                                                             num_words, num_char_encoding_size, FCN)\n",
    "\n",
    "        self.gru_crf_layer = gru_crf(size_of_embedding + output_size + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, \\\n",
    "                                     DO_FCN_GRUCRF, drop_weight)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        #print(tmp_compute.size())\n",
    "        #print(x[1].size())\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "class CNN_GRU_word_pos(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)',\\\n",
    "                 pos_size: '(int) size of pos embedding',\\\n",
    "                 drop_GRU_out):\n",
    "        super().__init__()\n",
    "        #print(f'output_size: {output_size}')\n",
    "        self.gru_crf_layer = gru_crf(size_of_embedding + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, \\\n",
    "                                     DO_FCN_GRUCRF, drop_GRU_out)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = torch.cat([x[1].float(), x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = torch.cat([x[1].float(), x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    \n",
    "class GRU_CRF_word(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)'):\n",
    "        super().__init__()\n",
    "        self.gru_crf_layer = gru_crf(size_of_embedding , gru_hidden_size, num_words, \\\n",
    "                                     dropout_gru, bidirectional, tags, DO_FCN_GRUCRF)\n",
    "    def forward(self, x):\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((x[1].float(), x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((x[1].float(), x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "class CNN_GRU_char(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 nums_filter: '(list[int] see in overall_char_embedding)',\n",
    "                 use_BN: '(bool) only for CNNchar',\n",
    "                 activation_func: '(bool) only for CNNchar',\n",
    "                 input_channel: '(int) see in My2DConv',\n",
    "                 kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\n",
    "                 same_padding: '(bool) same padding for CNNchar',\n",
    "                 num_char_encoding_size: '(int) size of each char embedding vector',\\\n",
    "                 output_size: '(int) output dimension of CNNchar',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)',\\\n",
    "                 FCN: '(bool) see overall_char_embedding',\\\n",
    "                 DO_weight_gru: '(float) weight dropout'):\n",
    "        super().__init__()\n",
    "        if not FCN:\n",
    "            output_size = num_char_encoding_size\n",
    "        #print(f'output_size: {output_size}')\n",
    "        self.overall_char_embedding = overall_char_embedding((Batch_size, output_size), max_num_char, \\\n",
    "                                                             nums_filter, use_BN, activation_func, \\\n",
    "                                                             input_channel, kernel_sizes, same_padding, \\\n",
    "                                                             num_words, num_char_encoding_size, FCN)\n",
    "\n",
    "        self.gru_crf_layer = gru_crf(output_size, gru_hidden_size, num_words, dropout_gru, bidirectional, tags, \\\n",
    "                                     DO_FCN_GRUCRF, DO_weight_gru)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "class CNN_GRU_char_pos(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 nums_filter: '(list[int] see in overall_char_embedding)',\\\n",
    "                 use_BN: '(bool) only for CNNchar',\\\n",
    "                 activation_func: '(bool) only for CNNchar',\\\n",
    "                 input_channel: '(int) see in My2DConv',\\\n",
    "                 kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\\\n",
    "                 same_padding: '(bool) same padding for CNNchar',\\\n",
    "                 num_char_encoding_size: '(int) size of each char embedding vector',\\\n",
    "                 output_size: '(int) output dimension of CNNchar',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', \\\n",
    "                 DO_FCN_GRUCRF: '(double)', \\\n",
    "                 pos_size: '(int) size of pos embedding', \\\n",
    "                 FCN: '(bool) see overall_char_embedding',\\\n",
    "                 drop_weight):\n",
    "        super().__init__()\n",
    "        if not FCN:\n",
    "            output_size = num_char_encoding_size\n",
    "        #print(f'output_size: {output_size}')\n",
    "        self.overall_char_embedding = overall_char_embedding((Batch_size, output_size), max_num_char, \\\n",
    "                                                             nums_filter, use_BN, activation_func, \\\n",
    "                                                             input_channel, kernel_sizes, same_padding, \\\n",
    "                                                             num_words, num_char_encoding_size, FCN)\n",
    "\n",
    "        self.gru_crf_layer = gru_crf(output_size + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, \\\n",
    "                                     DO_FCN_GRUCRF, drop_weight)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        #print(tmp_compute.size())\n",
    "        #print(x[1].size())\n",
    "        tmp_compute = torch.cat([tmp_compute, x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        tmp_compute = torch.cat([tmp_compute, x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "\n",
    "#new\n",
    "def get_index(len_row, len_col)->'(iterator of all ((int)row, (int)col))':\n",
    "    for i in range(len_row):\n",
    "        for j in range(len_col):\n",
    "            yield(i,j)\n",
    "\n",
    "def get_longest_seq_len(MASK: '(torch.tensor: shape=(batch_size, num_words)) \\\n",
    "    of mask 1 for non padding, 0 for otherwise')->'(int) col index of first zero in\\\n",
    "    of the longest sequence example: x=torch.tensor([[1,1,0],[1,0,0]]) -> return 2':\n",
    "    tmp_mask = MASK.numpy()\n",
    "    if len(tmp_mask.shape) != 1:\n",
    "        tmp_mask = np.sum(tmp_mask,0)\n",
    "    col = 0\n",
    "    for i in range(tmp_mask.shape[0]):\n",
    "        if tmp_mask[i]==0:\n",
    "            col = i\n",
    "            break\n",
    "    if col == 0:\n",
    "        col = tmp_mask.shape[0]\n",
    "    return col\n",
    "\n",
    "class overall_char_embedding(nn.Module):\n",
    "    def __init__(self, output_size: '(tuple of ints): (batch_size, embedding_size_per_word)',\\\n",
    "    max_len_char: '(int) see in CharEmbedding',\\\n",
    "    nums_filter: '(list) list of number of filters according to each kernel_sizes (respectively)',\\\n",
    "    use_BN: 'see in My2DConv',\\\n",
    "    activation_func: 'see in My2DConv',\\\n",
    "    input_channel: 'see in My2DConv',\\\n",
    "    kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\\\n",
    "    same_padding: 'see in My2DConv',\\\n",
    "    num_words: 'number of words used in 1 sample',\\\n",
    "    num_char_encoding_size: 'size of encoding for each char',\\\n",
    "    FCN: '(bool) use FCN after CNN or not'):\n",
    "        super().__init__()\n",
    "        self.batch_size, self.embedding_size_per_word = output_size\n",
    "        tmp_cnn_models = []\n",
    "        for ind_cnn, kernel_size in enumerate(kernel_sizes):\n",
    "            tmp_cnn_models.append(\\\n",
    "            My2DConvChar(nums_filter[ind_cnn], use_BN, activation_func, input_channel,\\\n",
    "            (kernel_size, 1), same_padding)\n",
    "            )\n",
    "        self.num_words = num_words\n",
    "        self.CNNs = nn.ModuleList(tmp_cnn_models)\n",
    "        self.MyMaxPool = nn.MaxPool2d((max_len_char, 1), stride= (1,1))\n",
    "        self.FCN = FCN\n",
    "        if self.FCN:\n",
    "            self.MyFCN = nn.Linear(sum(nums_filter)*num_char_encoding_size, output_size[1])\n",
    "            self.BN = nn.BatchNorm1d(output_size[1])\n",
    "    def forward(self, x):\n",
    "        batch_size, num_word, num_char, embedding_size = x.size()\n",
    "        #print(x.size())\n",
    "        tmp_compute = x.view(batch_size, num_word, 1, num_char, \\\n",
    "        embedding_size)\n",
    "        all_output_list = []\n",
    "        for num_word in range(self.num_words):\n",
    "            tmp_output_cnn = []\n",
    "            for tmp_cnn in self.CNNs:\n",
    "                tmp_output_cnn.append(self.MyMaxPool(tmp_cnn(tmp_compute[:,\\\n",
    "                num_word,:,:,:])).view((batch_size, -1)))\n",
    "            tmp = torch.cat(tmp_output_cnn, 1)\n",
    "            #print(tmp.size())\n",
    "            if self.FCN:\n",
    "                all_output_list.append(F.relu(self.BN(self.MyFCN(tmp))))\n",
    "            else:\n",
    "                all_output_list.append(tmp)\n",
    "        #print(all_output_list[0].size())\n",
    "        #print(len(all_output_list))\n",
    "        all_output_list = torch.stack(all_output_list, dim=1)\n",
    "        #print(all_output_list.size())\n",
    "        return all_output_list\n",
    "                \n",
    "class gru_crf(nn.Module):\n",
    "    def __init__(self, num_input_features: '(int) number of input features', hidden_size: '(int) number of\\\n",
    "    hidden features the outputs will also have hidden_size features', num_layers: '(int) number of \\\n",
    "    recursion', dropout_gru, bidirectional: '(bool) if True, use bidirectional GRU',\\\n",
    "    tags: \"(dict[int: str])example: {0:'I', 1:'B', 2:'O', 3:'<PAD>'}\", dropout_FCN: '(double)', drop_GRU_out):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size = num_input_features, hidden_size = hidden_size, \\\n",
    "                                  num_layers = num_layers, batch_first = True, dropout = dropout_gru, \\\n",
    "                                  bidirectional = bidirectional)\n",
    "        #self.gru = WeightDropGRU(input_size = num_input_features, hidden_size = hidden_size, \\\n",
    "        #                         num_layers = num_layers, batch_first = True, dropout = dropout_gru, \\\n",
    "        #                         bidirectional = bidirectional, weight_dropout=drop_weight)\n",
    "        all_transition=allowed_transitions('BIO', tags)\n",
    "        #self.crf = CRF(num_tags=len(tags), batch_first= True)\n",
    "        self.linear = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.BN = nn.BatchNorm1d(num_layers)\n",
    "        self.linear2 = nn.Linear(hidden_size, len(tags))\n",
    "        self.BN2 = nn.BatchNorm1d(num_layers)\n",
    "        self.crf = ConditionalRandomField(len(tags), all_transition)\n",
    "        self.dropout = dropout_FCN\n",
    "        self.drop_GRU_out = drop_GRU_out\n",
    "        \n",
    "    def forward(self, samples, target: '(torch.tensor) shape=(...............,)the target tags to be used',\\\n",
    "                mask: 'True for non-pad elements'):\n",
    "        length = samples[1]\n",
    "        samples = samples[0]\n",
    "        batch_size, words, _ = samples.size()\n",
    "        tmp_t = time()\n",
    "        #print(samples.size())\n",
    "        tmp_compute = F.dropout(self.gru(samples)[0], p=self.dropout)\n",
    "        #print('pass inference gru')\n",
    "        tmp_compute = tmp_compute.view(batch_size, words, -1)\n",
    "        #print('pass reshape gru')\n",
    "#         print(f'total GRU time: {time() - tmp_t}')\n",
    "        index_to_cut = max(length).item()#get_longest_seq_len(mask)\n",
    "        #length = torch.mean(length.float()).item()\n",
    "        ##############################################\n",
    "        ###cut padding some parts out#################\n",
    "        #print(tmp_compute.size())\n",
    "        #tmp_compute = self.dropout(tmp_compute)\n",
    "        tmp_compute = F.dropout(F.relu(self.BN(self.linear(tmp_compute))), p=self.drop_GRU_out)\n",
    "        tmp_compute = F.relu(self.BN2(self.linear2(tmp_compute)))\n",
    "        tmp_compute = F.dropout(tmp_compute[:, :index_to_cut,:],  p=self.dropout)\n",
    "        target = target[:, :index_to_cut]\n",
    "        mask = mask[:, :index_to_cut]\n",
    "        #print(tmp_compute.size())\n",
    "        nll_loss = self.crf(tmp_compute,target.long(),mask)\n",
    "#         print(f'total CRF time: {time() - tmp_t}')\n",
    "        return nll_loss#/length\n",
    "    def predict(self, samples, mask):\n",
    "        length = samples[1]\n",
    "        samples = samples[0]\n",
    "        batch_size, words, _ = samples.size()\n",
    "        tmp_t = time()\n",
    "        tmp_compute = self.gru(samples)[0].view(batch_size, words, -1)\n",
    "#         print(f'total GRU time: {time() - tmp_t}')\n",
    "        index_to_cut = max(length).item()#get_longest_seq_len(mask)\n",
    "        ##############################################\n",
    "        ###cut padding some parts out#################\n",
    "        #print(tmp_compute.size())\n",
    "        \n",
    "        tmp_compute = F.relu(self.BN(self.linear(tmp_compute)))\n",
    "        tmp_compute = F.relu(self.BN2(self.linear2(tmp_compute)))\n",
    "        tmp_compute = tmp_compute[:, :index_to_cut,:]\n",
    "        mask = mask[:, :index_to_cut]\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_t = time()\n",
    "        tmp_tags = self.crf.viterbi_tags(tmp_compute,mask)\n",
    "#         print(f'total CRF prediction time: {time() - tmp_t}')\n",
    "        return tmp_tags\n",
    "    \n",
    "class My2DConv(nn.Module):\n",
    "    def __init__(self, num_filter: '(int) number of filters', use_BN: '(bool) if True, use 2d-batchnorm after linear conv',\\\n",
    "    activation_func: '(bool) if True, use RELU after BN', input_channel: '(int) number of input channels', \\\n",
    "    kernel_size: '(tuple): (width, height) size of the kernels', same_padding: '(bool) if True, input_w,input_h=output_w,output_h'):\n",
    "        super().__init__()\n",
    "        if same_padding:\n",
    "            #assume that dialation = 1 and stride = 1\n",
    "            self.padding = (math.floor((kernel_size[0] - 1)/2), math.floor((kernel_size[1] -1)/2))\n",
    "        else:\n",
    "            self.padding = 0\n",
    "        self.Conv = nn.Conv2d(input_channel, num_filter, kernel_size, padding= self.padding)\n",
    "        self.use_BN = use_BN\n",
    "        self.activation_func = activation_func\n",
    "        if self.use_BN:\n",
    "            self.BN = nn.BatchNorm2d(num_filter)\n",
    "\n",
    "    def forward(self, input_data: '(torch.tensor) dimension= (batch_size, num_channel_in, in_height, in_width)') \\\n",
    "    -> '(torch.tensor) shape= (batch_size, num_filter, in_height, in_width)':\n",
    "        tmp_compute = self.Conv(input_data.float())\n",
    "        if self.use_BN:\n",
    "            tmp_compute = self.BN(tmp_compute)\n",
    "        if self.activation_func:\n",
    "            tmp_compute = nn.ReLU()(tmp_compute)\n",
    "        return tmp_compute\n",
    "        \n",
    "class My2DConvChar(nn.Module):\n",
    "    def __init__(self, num_filter: '(int) number of filters', use_BN: '(bool) if True, \\\n",
    "                 use 2d-batchnorm after linear conv', activation_func: '(bool) if True, use RELU\\\n",
    "                 after BN', input_channel: '(int) number of input channels', \\\n",
    "                 kernel_size: '(tuple): (width, height) size of the kernels', \\\n",
    "                 same_padding: '(bool) if True, input_w,input_h=output_w,output_h'):\n",
    "        super().__init__()\n",
    "        if same_padding:\n",
    "            #assume that dialation = 1 and stride = 1\n",
    "            self.padding = (math.floor((kernel_size[0] - 1)/2), 0)\n",
    "        else:\n",
    "            self.padding = 0\n",
    "        self.Conv = nn.Conv2d(input_channel, num_filter, kernel_size, padding= self.padding)\n",
    "        self.use_BN = use_BN\n",
    "        self.activation_func = activation_func\n",
    "        if self.use_BN:\n",
    "            self.BN = nn.BatchNorm2d(num_filter)\n",
    "\n",
    "    def forward(self, input_data: '(torch.tensor) dimension= (batch_size, num_channel_in, in_height, in_width)') \\\n",
    "    -> '(torch.tensor) shape= (batch_size, num_filter, in_height, in_width)':\n",
    "        tmp_compute = self.Conv(input_data.float())\n",
    "        if self.use_BN:\n",
    "            tmp_compute = self.BN(tmp_compute)\n",
    "        if self.activation_func:\n",
    "            tmp_compute = F.relu(tmp_compute)\n",
    "        return tmp_compute\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2))\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)\n",
    "\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "class AttentionBetweenWordsAndChars(nn.Module):\n",
    "    def __init__(self, hidden_size: '(int) size of key, query and value vectors',\\\n",
    "    input_vec_size: '(int) incase of fasttext input_vec_size=300'):\n",
    "        super().__init__()\n",
    "        self.K_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.Q_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.V_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.AttLayer = ScaledDotProductAttention(math.sqrt(hidden_size), 0.1)\n",
    "    def forward(self, char_vectors, word_vectors):\n",
    "        batch_size, word_size, _ = word_vectors.size()\n",
    "        word_vectors = word_vectors.float()\n",
    "        char_vectors = char_vectors.float()\n",
    "#         print(word_vectors.size())\n",
    "#         print(char_vectors.size())\n",
    "        K = torch.stack([self.K_FCN(word_vectors),self.K_FCN(char_vectors)],dim = 2)\n",
    "        Q = torch.stack([self.Q_FCN(word_vectors),self.Q_FCN(char_vectors)],dim = 2)\n",
    "        V = torch.stack([self.V_FCN(word_vectors),self.V_FCN(char_vectors)],dim = 2)\n",
    "        all_output_list = []\n",
    "        for word_ind in range(word_size):\n",
    "            all_output_list.append(self.AttLayer(Q[:,word_ind,:,:], \\\n",
    "            K[:,word_ind,:,:], V[:,word_ind,:,:])[0].view(batch_size,-1))\n",
    "\n",
    "        return torch.stack(all_output_list,dim = 1)\n",
    "    \n",
    "class over_all_NER(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 max_len_char: '(int) see overall_char_embedding',\\\n",
    "                 num_conv_filters: '(list[int]) see in overall_char_embedding', \\\n",
    "                 use_BN: '(bool) see in overall_char_embedding', \\\n",
    "                 use_activation: '(bool) see in overall_char_embedding', \\\n",
    "                 num_conv_input_channel: '(int) see in overall_char_embedding', \\\n",
    "                 kernel_sizes: '(list[tuple[int, int]]) see in overall_char_embedding', \\\n",
    "                 use_same_padding: '(bool) see in overall_char_embedding', \\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 num_char_encoding_size: '(int) see in overall_char_embedding', \\\n",
    "                 att_hidden_size: '(int) see in AttentionBetweenWordsAndChars', \\\n",
    "                 num_input_features: '(int) see in gru_crf', gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf'):\n",
    "        super().__init__()\n",
    "        self.char_embed = overall_char_embedding((Batch_size,size_of_embedding), max_len_char, num_conv_filters, \\\n",
    "                                                 use_BN, use_activation, num_conv_input_channel, kernel_sizes, \\\n",
    "                                                 use_same_padding, num_words, num_char_encoding_size)\n",
    "        self.my_attention = AttentionBetweenWordsAndChars(att_hidden_size, size_of_embedding)\n",
    "        self.gru_crf_layer = gru_crf(num_input_features, gru_hidden_size, num_words, dropout_gru, \\\n",
    "                                bidirectional, tags)\n",
    "        self.Batch_size = Batch_size\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.char_embed(x[0])\n",
    "        tmp_att = self.my_attention(tmp_compute, x[1])\n",
    "        tmp_gru_crf = self.gru_crf_layer(tmp_att, x[2], x[3].long())\n",
    "        return tmp_gru_crf#/self.Batch_size\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.char_embed(x[0])\n",
    "        tmp_att = self.my_attention(tmp_compute, x[1])\n",
    "        tmp_tags = self.gru_crf_layer.predict(tmp_att, x[3].long())\n",
    "        return tmp_tags\n",
    "\n",
    "def get_indices_random_train_test_split(dataset_size:'(int) number of rows', random_seed: '(int)',\\\n",
    "                                        validation_split: '(double)', shuffle_dataset: '(bool)'):\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return train_sampler, valid_sampler\n",
    "  \n",
    "def get_indices_random_val_test_split(dataset_size:'(int) number of rows', random_seed: '(int)',\\\n",
    "                                        validation_split: '(double)', shuffle_dataset: '(bool)'):\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    test_indices, val_indices = indices[split: 2*split], indices[:split]\n",
    "    # Creating PT data samplers and loaders:\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return test_sampler, valid_sampler\n",
    "\n",
    "def eval_score(tags: '(dict[int: str])', pred: '(list[(list, float)])', label: 'torch.tensor'):\n",
    "    pred = np.array([np.array(i[0]) for i in pred])\n",
    "    label = label.cpu().numpy().astype('int8')\n",
    "    label = [label[i][:len(pred[i])] for i in range(len(pred))]\n",
    "    conf_mat = np.zeros((len(tags), len(tags)))\n",
    "#     print(len(label))\n",
    "#     print(len(pred))\n",
    "#     print('---------------')\n",
    "    for i in range(len(label)):\n",
    "#         print(len(label[i]))\n",
    "#         print(len(pred[i]))\n",
    "        conf_mat += confusion_matrix(label[i],pred[i],range(len(tags)))\n",
    "    performance_mat = np.zeros((len(tags), 3))#recall, precision, f1-score\n",
    "    for i in range(len(tags)):\n",
    "        if np.sum(conf_mat[i]) == 0:\n",
    "            performance_mat[i][0] = 0\n",
    "        else:\n",
    "            performance_mat[i][0] = conf_mat[i][i]/np.sum(conf_mat[i])\n",
    "        if np.sum(conf_mat[:,i]) == 0:\n",
    "            performance_mat[i][1] = 0\n",
    "        else:\n",
    "            performance_mat[i][1] = conf_mat[i][i]/np.sum(conf_mat[:,i])\n",
    "        if performance_mat[i][1]+performance_mat[i][0] == 0:\n",
    "            performance_mat[i][2] = 0\n",
    "        else:\n",
    "            performance_mat[i][2] = (2*performance_mat[i][0]*performance_mat[i][1])/(performance_mat[i][1]+performance_mat[i][0])\n",
    "    return performance_mat, conf_mat[:,:-1]\n",
    "\n",
    "class CNN_GRU_char_pos(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 nums_filter: '(list[int] see in overall_char_embedding)',\\\n",
    "                 use_BN: '(bool) only for CNNchar',\\\n",
    "                 activation_func: '(bool) only for CNNchar',\\\n",
    "                 input_channel: '(int) see in My2DConv',\\\n",
    "                 kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\\\n",
    "                 same_padding: '(bool) same padding for CNNchar',\\\n",
    "                 num_char_encoding_size: '(int) size of each char embedding vector',\\\n",
    "                 output_size: '(int) output dimension of CNNchar',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', \\\n",
    "                 DO_FCN_GRUCRF: '(double)', \\\n",
    "                 pos_size: '(int) size of pos embedding', \\\n",
    "                 FCN: '(bool) see overall_char_embedding', \\\n",
    "                 drop_weight\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if not FCN:\n",
    "            output_size = num_char_encoding_size\n",
    "        #print(f'output_size: {output_size}')\n",
    "        self.overall_char_embedding = overall_char_embedding((Batch_size, output_size), max_num_char, \\\n",
    "                                                             nums_filter, use_BN, activation_func, \\\n",
    "                                                             input_channel, kernel_sizes, same_padding, \\\n",
    "                                                             num_words, num_char_encoding_size, FCN)\n",
    "\n",
    "        self.gru_crf_layer = gru_crf(output_size + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, \\\n",
    "                                     DO_FCN_GRUCRF, drop_weight)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        #print(tmp_compute.size())\n",
    "        #print(x[1].size())\n",
    "        tmp_compute = torch.cat([tmp_compute, x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.overall_char_embedding(x[0])\n",
    "        tmp_compute = torch.cat([tmp_compute, x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf\n",
    "\n",
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for ind, tmp in enumerate(named_parameters):\n",
    "        n, p= tmp\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cur_ind: 0. gru_weight_dropout: 0.20635630823301318\n",
      "grucrf_dropout: 0.24840664118118352, DO_FCN_GRUCRF: 0.3266306490218036\n",
      "grucrf_hidden_size: 128, LR: 0.0002994937337779445\n",
      "cpu\n",
      "epoch 0\n",
      "0\n",
      "0.00018978118896484375\n"
     ]
    }
   ],
   "source": [
    "BS = 4\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 2000\n",
    "word_length = 2000\n",
    "early_stop_n = 100\n",
    "max_size_char = 6\n",
    "num_search = 1000\n",
    "filename = 'aaaaaaaaa'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "data = MyDataloader('../clean84withpos.txt', '../label84withpos.txt', RULEs, \\\n",
    "                    word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "                    '../fasttext.th.vec', 300, device, '../pos_tag84withpos.txt',POSMAP)\n",
    "\n",
    "tr, te = get_indices_random_val_test_split(len(data), 1, 0.0005, True)\n",
    "train_loader = DataLoader(data, batch_size=BS, sampler=tr)\n",
    "test_loader = DataLoader(data, batch_size=BS, sampler=te)\n",
    "\n",
    "# NER = over_all_NER(BS,300, max_size_char, num_kernels,True,True,1,kernel_sizes,\\\n",
    "#                    True,word_length,135,attention_in, attention_out, gru_hidden_size, \\\n",
    "#                    gru_dropout, True, tags)\n",
    "#####\n",
    "# Batch_size: '(int)',\\\n",
    "#                  num_char_vec_features: '(int)',\\\n",
    "#                  hidden_size: '(int)',\\\n",
    "#                  max_num_char: '(int)',\\\n",
    "#                  dropout_gru_char: '(double)',\\\n",
    "#                  bidirectional_char: '(bool)',\\\n",
    "#                  output_char_embed_size: '(int)',\\\n",
    "#                  size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "#                  num_words: '(int) see in overall_char_embedding', \\\n",
    "#                  gru_hidden_size: '(int) see in gru_crf', \\\n",
    "#                  dropout_gru: '(double) see in gru_crf', \\\n",
    "#                  bidirectional: '(bool)', \\\n",
    "#                  tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)')\n",
    "#####\n",
    "for cur_ind in range(num_search):\n",
    "    torch.cuda.empty_cache()\n",
    "    grucrf_dropout = random.uniform(0.2,0.5)#0.5\n",
    "    DO_FCN_GRUCRF = random.uniform(0.2,0.5)#0.5\n",
    "    grucrf_hidden_size = 128#random.choice([128, 256])#5\n",
    "    gru_weight_dropout = random.uniform(0.1,0.4)\n",
    "    LR = 5*10**random.uniform(-3,-5)#0.001\n",
    "    \n",
    "    print(f'cur_ind: {cur_ind}. gru_weight_dropout: {gru_weight_dropout}')\n",
    "    print(f'grucrf_dropout: {grucrf_dropout}, DO_FCN_GRUCRF: {DO_FCN_GRUCRF}')\n",
    "    print(f'grucrf_hidden_size: {grucrf_hidden_size}, LR: {LR}')\n",
    "\n",
    "    NER = CNN_GRU_CRF(BS, max_size_char, [1], True, True, 1, \\\n",
    "                      [3], True, 135, 135,\\\n",
    "                      300, word_length, grucrf_hidden_size, grucrf_dropout, \\\n",
    "                      True, tags, DO_FCN_GRUCRF, len(POSMAP), False)\n",
    "\n",
    "    optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "    my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "    print(device)\n",
    "    NER.to(device)\n",
    "    best_score = 0\n",
    "    best_mat = np.zeros((len(tags)-1,3))\n",
    "    cnt_idle = 0\n",
    "    for epoch in range(10):\n",
    "        print(f'epoch {epoch}')\n",
    "        all_loss = []\n",
    "        for ind, batch_x in enumerate(train_loader):\n",
    "            if ind%5 == 0:\n",
    "                print(ind)\n",
    "            t2 = time()\n",
    "            NER = NER.train()\n",
    "            print(time() - t2)\n",
    "            NER.zero_grad()\n",
    "            t1 = time()\n",
    "            loss = NER(batch_x)\n",
    "            loss = loss*(-1)\n",
    "            print(f'time per batch: {time() - t1}')\n",
    "            print(loss)\n",
    "            all_loss.append(loss)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(NER.parameters(), 10)\n",
    "            optimizer.step()\n",
    "        total_loss = sum(all_loss)/(ind + 1)\n",
    "        my_scheduler.step(total_loss)\n",
    "        print(f'total loss of epoch: {total_loss.item()}')\n",
    "        print('testing')\n",
    "        per_mat = np.zeros((len(tags), 3))\n",
    "        for ind, batch_test in enumerate(test_loader):\n",
    "            NER = NER.eval()\n",
    "            output = NER.predict(batch_test)\n",
    "            per_mat += eval_score(tags, output, batch_test[2])\n",
    "        per_mat = per_mat/(ind+1)\n",
    "        per_mat = per_mat[:len(tags),:]\n",
    "        print(per_mat)\n",
    "        score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "        if best_score < score:\n",
    "            best_mat=per_mat\n",
    "            best_score = score\n",
    "            cnt_idle = 0\n",
    "        else:\n",
    "            cnt_idle += 1\n",
    "        print(f'overall score: {score}')\n",
    "        print('--------------------')\n",
    "        if early_stop_n == cnt_idle:\n",
    "            break\n",
    "    break\n",
    "\n",
    "    print(f'best_score: {best_score}\\n')\n",
    "    #print(f'best_mat\\n')\n",
    "    print(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "    print(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "    print(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "    #print(f'best_mat\\n')\n",
    "    print(f'----------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "LE: 0.0019529859275205712\n",
      "dropouti: 0, DO_FCN_LSTMCRF: 0.41411433791047636\n",
      "lstmcrf_hidden_size: 128, dropouti: 0\n",
      "dropouto: 0, dropoutw: 0.3811934675043389\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CNN_LSTM_CRF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3bdc1bebf111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     NER = CNN_LSTM_CRF(BS, max_size_char, nums_filter, use_BN, activation_func, input_channel, \\\n\u001b[0m\u001b[1;32m     67\u001b[0m                        \u001b[0mkernel_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_char_encoding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                        \u001b[0msize_of_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstmcrf_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN_LSTM_CRF' is not defined"
     ]
    }
   ],
   "source": [
    "BS = 2\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 50\n",
    "word_length = 84\n",
    "early_stop_n = 5\n",
    "max_size_char = 20\n",
    "num_search = 100\n",
    "nums_filter = [1]\n",
    "use_BN = True\n",
    "activation_func = True\n",
    "input_channel = 1\n",
    "kernel_sizes = [3]\n",
    "same_padding = True\n",
    "num_char_encoding_size = 135\n",
    "output_size = 64\n",
    "size_of_embedding = 300\n",
    "pos_size = len(POSMAP)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "data = MyDataloader('../clean84withpos.txt', '../label84withpos.txt', RULEs, \\\n",
    "                    word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "                    '../fasttext.th.vec', 300, device, '../pos_tag84withpos.txt',POSMAP)\n",
    "\n",
    "\n",
    "tr, te = get_indices_random_val_test_split(len(data), 1, 0.00005, True)\n",
    "train_loader = DataLoader(data, batch_size=BS, sampler=tr)\n",
    "test_loader = DataLoader(data, batch_size=BS, sampler=te)\n",
    "\n",
    "# NER = over_all_NER(BS,300, max_size_char, num_kernels,True,True,1,kernel_sizes,\\\n",
    "#                    True,word_length,135,attention_in, attention_out, gru_hidden_size, \\\n",
    "#                    gru_dropout, True, tags)\n",
    "#####\n",
    "# Batch_size: '(int)',\\\n",
    "#                  num_char_vec_features: '(int)',\\\n",
    "#                  hidden_size: '(int)',\\\n",
    "#                  max_num_char: '(int)',\\\n",
    "#                  dropout_gru_char: '(double)',\\\n",
    "#                  bidirectional_char: '(bool)',\\\n",
    "#                  output_char_embed_size: '(int)',\\\n",
    "#                  size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "#                  num_words: '(int) see in overall_char_embedding', \\\n",
    "#                  gru_hidden_size: '(int) see in gru_crf', \\\n",
    "#                  dropout_gru: '(double) see in gru_crf', \\\n",
    "#                  bidirectional: '(bool)', \\\n",
    "#                  tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)')\n",
    "#####\n",
    "for cur_ind in range(num_search):\n",
    "    torch.cuda.empty_cache()\n",
    "    #grucrf_dropout = random.uniform(0.3,0.7)#0.5\n",
    "    DO_FCN_LSTMCRF = random.uniform(0.3,0.7)#0.5\n",
    "    \n",
    "    dropouti = 0#random.uniform(0.1,0.7)\n",
    "    dropouto = 0#random.uniform(0.1,0.7)\n",
    "    dropoutw = random.uniform(0.1,0.7)\n",
    "    \n",
    "    lstmcrf_hidden_size = random.choice([128])#5\n",
    "    LR = 5*10**random.uniform(-3,-5)#0.001\n",
    "    print(f'LE: {LR}')\n",
    "    print(f'dropouti: {dropouti}, DO_FCN_LSTMCRF: {DO_FCN_LSTMCRF}')\n",
    "    print(f'lstmcrf_hidden_size: {lstmcrf_hidden_size}, dropouti: {dropouti}')\n",
    "    print(f'dropouto: {dropouto}, dropoutw: {dropoutw}')\n",
    "\n",
    "    \n",
    "    NER = CNN_LSTM_CRF(BS, max_size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "                       kernel_sizes, same_padding, num_char_encoding_size, output_size,\\\n",
    "                       size_of_embedding, word_length, lstmcrf_hidden_size, \\\n",
    "                       True, tags, DO_FCN_LSTMCRF, pos_size, False, dropouti=dropouti, \\\n",
    "                       dropouto=dropouto, dropoutw=dropoutw)\n",
    "#self, Batch_size, max_num_char, nums_filter, use_BN, activation_func, input_channel, \n",
    "#kernel_sizes, same_padding, num_char_encoding_size, output_size, size_of_embedding, \n",
    "#num_words, gru_hidden_size, dropout_gru, bidirectional, tags, DO_FCN_GRUCRF, pos_size, FCN, dropouti, \n",
    "#dropoutw, dropouto\n",
    "\n",
    "    optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "    my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "    print(device)\n",
    "    NER.to(device)\n",
    "    best_score = 0\n",
    "    best_mat = np.zeros((len(tags)-1,3))\n",
    "    cnt_idle = 0\n",
    "    for epoch in range(6):\n",
    "        print(f'epoch {epoch}')\n",
    "        all_loss = []\n",
    "        for ind, batch_x in enumerate(train_loader):\n",
    "            if ind%5 == 0:\n",
    "                print(ind)\n",
    "            t2 = time()\n",
    "            print('------------train--------------------')\n",
    "            NER = NER.train()\n",
    "            print(time() - t2)\n",
    "            NER.zero_grad()\n",
    "            t1 = time()\n",
    "            loss = NER(batch_x)\n",
    "            output = NER.predict(batch_x)\n",
    "#             for i in range(len(output)):\n",
    "#                 print(batch_x[2][i])\n",
    "#                 print(output[i])\n",
    "            loss = loss*(-1)\n",
    "            print(f'time per batch: {time() - t1}')\n",
    "            print(loss)\n",
    "            all_loss.append(loss)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(NER.parameters(), 1)\n",
    "            plot_grad_flow(NER.named_parameters())\n",
    "            optimizer.step()\n",
    "        total_loss = sum(all_loss)/(ind + 1)\n",
    "        my_scheduler.step(total_loss)\n",
    "        print(f'total loss of epoch: {total_loss.item()}')\n",
    "        print('testing')\n",
    "        per_mat = np.zeros((len(tags), 3))\n",
    "        for ind, batch_test in enumerate(test_loader):\n",
    "            NER = NER.eval()\n",
    "            output = NER.predict(batch_test)\n",
    "            for i in range(len(output)):\n",
    "                print(batch_test[2][i])\n",
    "                print(output[i])\n",
    "            per_mat += eval_score(tags, output, batch_test[2])\n",
    "        per_mat = per_mat/(ind+1)\n",
    "        per_mat = per_mat[:len(tags),:]\n",
    "        print(per_mat)\n",
    "        score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "        if best_score < score:\n",
    "            best_mat=per_mat\n",
    "            best_score = score\n",
    "            cnt_idle = 0\n",
    "        else:\n",
    "            cnt_idle += 1\n",
    "        print(f'overall score: {score}')\n",
    "        print('--------------------')\n",
    "        if early_stop_n == cnt_idle:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment1 word with POS only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "lstmcrf_dropout = DO_FCN_LSTMCRF: 0\n",
      "lstmcrf_hidden_size: 128, LR: 0.0001\n",
      "cpu\n",
      "epoch 0\n",
      "progress: 10.0\n",
      "0\n",
      "8.416175842285156e-05\n",
      "time per batch: 11.097868204116821\n",
      "tensor(961.2801, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001049041748046875\n",
      "time per batch: 9.962333917617798\n",
      "tensor(953.5808, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015616416931152344\n",
      "time per batch: 5.370298147201538\n",
      "tensor(379.1391, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 764.6666870117188\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.230e+02 7.400e+01 0.000e+00]\n",
      " [1.164e+03 2.310e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.39222793 0.28005128 0.32374882]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.10791627233758282\n",
      "--------------------\n",
      "total epoch time: -145.08972597122192\n",
      "epoch 1\n",
      "progress: 10.0\n",
      "0\n",
      "9.322166442871094e-05\n",
      "time per batch: 7.407656192779541\n",
      "tensor(574.2061, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.703636169433594e-05\n",
      "time per batch: 7.822667837142944\n",
      "tensor(740.0278, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00010609626770019531\n",
      "time per batch: 3.7627217769622803\n",
      "tensor(299.1276, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 537.7871704101562\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+02 7.700e+01 0.000e+00]\n",
      " [1.156e+03 2.390e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.39144531 0.24487748 0.30023169]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.10007722886215414\n",
      "--------------------\n",
      "total epoch time: -126.96932315826416\n",
      "epoch 2\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012683868408203125\n",
      "time per batch: 6.246838808059692\n",
      "tensor(631.9189, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.96453857421875e-05\n",
      "time per batch: 7.080614805221558\n",
      "tensor(642.7448, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.082389831542969e-05\n",
      "time per batch: 3.8573899269104004\n",
      "tensor(273.5601, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 516.0745239257812\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+02 7.700e+01 0.000e+00]\n",
      " [1.156e+03 2.390e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.41328472 0.23863128 0.29941412]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09980470544986675\n",
      "--------------------\n",
      "total epoch time: -126.67728996276855\n",
      "epoch 3\n",
      "progress: 10.0\n",
      "0\n",
      "8.0108642578125e-05\n",
      "time per batch: 6.147094964981079\n",
      "tensor(618.6656, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.393692016601562e-05\n",
      "time per batch: 6.373827695846558\n",
      "tensor(576.1425, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.106231689453125e-05\n",
      "time per batch: 3.7199649810791016\n",
      "tensor(335.4594, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 510.0891418457031\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+02 7.700e+01 0.000e+00]\n",
      " [1.156e+03 2.390e+02 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.40164939 0.24804184 0.3065615 ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.1021871669659411\n",
      "--------------------\n",
      "total epoch time: -119.18494415283203\n",
      "epoch 4\n",
      "progress: 10.0\n",
      "0\n",
      "7.510185241699219e-05\n",
      "time per batch: 6.174929857254028\n",
      "tensor(572.1866, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.487701416015625e-05\n",
      "time per batch: 7.371708154678345\n",
      "tensor(629.2031, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.679794311523438e-05\n",
      "time per batch: 3.724454164505005\n",
      "tensor(321.4597, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 507.616455078125\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.200e+02 7.400e+01 3.000e+00]\n",
      " [1.139e+03 2.420e+02 1.400e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.37407462 0.23718967 0.29000272]\n",
      " [0.01022874 0.85714286 0.02021549]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.10340607086769894\n",
      "--------------------\n",
      "total epoch time: -123.02503609657288\n",
      "epoch 5\n",
      "progress: 10.0\n",
      "0\n",
      "0.00010228157043457031\n",
      "time per batch: 6.949829816818237\n",
      "tensor(647.9399, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.606910705566406e-05\n",
      "time per batch: 6.225802898406982\n",
      "tensor(558.4005, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.416175842285156e-05\n",
      "time per batch: 3.6938719749450684\n",
      "tensor(310.3044, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 505.5482482910156\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [1.110e+02 7.800e+01 8.000e+00]\n",
      " [1.009e+03 3.000e+02 8.600e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.39115539 0.20221774 0.26520091]\n",
      " [0.06218744 0.91858974 0.11648716]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.12722935470372815\n",
      "--------------------\n",
      "total epoch time: -121.0958240032196\n",
      "epoch 6\n",
      "progress: 10.0\n",
      "0\n",
      "8.487701416015625e-05\n",
      "time per batch: 6.118570804595947\n",
      "tensor(615.9763, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.869171142578125e-05\n",
      "time per batch: 6.524427175521851\n",
      "tensor(617.6133, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.274482727050781e-05\n",
      "time per batch: 3.68881893157959\n",
      "tensor(278.4992, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 504.0296325683594\n",
      "testing\n",
      "[[  0.   1.   0.]\n",
      " [  0. 142.  55.]\n",
      " [  0. 802. 593.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.73958644 0.15457622 0.25558131]\n",
      " [0.41975386 0.91899733 0.57606157]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.27721429488119226\n",
      "--------------------\n",
      "total epoch time: -124.08520078659058\n",
      "epoch 7\n",
      "progress: 10.0\n",
      "0\n",
      "9.226799011230469e-05\n",
      "time per batch: 6.0872461795806885\n",
      "tensor(603.7670, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.7738037109375e-05\n",
      "time per batch: 6.341602087020874\n",
      "tensor(630.8356, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.392333984375e-05\n",
      "time per batch: 3.656920909881592\n",
      "tensor(273.6653, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 502.7559509277344\n",
      "testing\n",
      "[[  0.   1.   0.]\n",
      " [  0. 134.  63.]\n",
      " [  0. 755. 640.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.67481158 0.15245735 0.24806009]\n",
      " [0.45966657 0.90647835 0.60974403]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2859347057097622\n",
      "--------------------\n",
      "total epoch time: -122.17727208137512\n",
      "epoch 8\n",
      "progress: 10.0\n",
      "0\n",
      "9.322166442871094e-05\n",
      "time per batch: 5.982855796813965\n",
      "tensor(675.6348, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.916854858398438e-05\n",
      "time per batch: 6.392994165420532\n",
      "tensor(543.5979, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00010895729064941406\n",
      "time per batch: 3.741655111312866\n",
      "tensor(285.7734, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 501.668701171875\n",
      "testing\n",
      "[[  0.   1.   0.]\n",
      " [  0. 104.  93.]\n",
      " [  0. 510. 885.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.5462585  0.18223926 0.27199967]\n",
      " [0.62631775 0.90202523 0.73918635]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.33706200702156774\n",
      "--------------------\n",
      "total epoch time: -120.58084201812744\n",
      "epoch 9\n",
      "progress: 10.0\n",
      "0\n",
      "9.417533874511719e-05\n",
      "time per batch: 5.961509943008423\n",
      "tensor(669.4999, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.082389831542969e-05\n",
      "time per batch: 7.222738981246948\n",
      "tensor(548.2810, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00011396408081054688\n",
      "time per batch: 5.483802795410156\n",
      "tensor(284.2962, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 500.6924133300781\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 7.500e+01 1.220e+02]\n",
      " [0.000e+00 3.800e+02 1.015e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.38635982 0.16856662 0.23445901]\n",
      " [0.7313051  0.89395727 0.80446203]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3463070121336251\n",
      "--------------------\n",
      "total epoch time: -144.0538511276245\n",
      "epoch 10\n",
      "progress: 10.0\n",
      "0\n",
      "8.082389831542969e-05\n",
      "time per batch: 8.14328908920288\n",
      "tensor(558.7604, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.000102996826171875\n",
      "time per batch: 6.697031021118164\n",
      "tensor(647.8097, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.0108642578125e-05\n",
      "time per batch: 3.7378950119018555\n",
      "tensor(292.6599, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 499.7433166503906\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 6.900e+01 1.280e+02]\n",
      " [0.000e+00 3.340e+02 1.061e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.34163596 0.16331375 0.22039246]\n",
      " [0.75856598 0.88926556 0.81867017]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.34635420769133435\n",
      "--------------------\n",
      "total epoch time: -128.81049704551697\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10.0\n",
      "0\n",
      "0.00010180473327636719\n",
      "time per batch: 6.081189870834351\n",
      "tensor(573.8969, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.296966552734375e-05\n",
      "time per batch: 6.310005187988281\n",
      "tensor(620.9992, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.012222290039062e-05\n",
      "time per batch: 3.8401989936828613\n",
      "tensor(301.7004, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 498.865478515625\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 6.800e+01 1.290e+02]\n",
      " [0.000e+00 3.230e+02 1.072e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33433433 0.17268224 0.22663641]\n",
      " [0.7647567  0.88254162 0.8193834 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3486732691214918\n",
      "--------------------\n",
      "total epoch time: -121.03786206245422\n",
      "epoch 12\n",
      "progress: 10.0\n",
      "0\n",
      "0.00010275840759277344\n",
      "time per batch: 6.103687047958374\n",
      "tensor(528.2590, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.298324584960938e-05\n",
      "time per batch: 7.309694766998291\n",
      "tensor(638.6710, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.320808410644531e-05\n",
      "time per batch: 3.6961188316345215\n",
      "tensor(327.2003, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 498.0434265136719\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 6.800e+01 1.290e+02]\n",
      " [0.000e+00 3.230e+02 1.072e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.34321903 0.1753749  0.2312508 ]\n",
      " [0.76383512 0.88720436 0.82079599]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35068226087791093\n",
      "--------------------\n",
      "total epoch time: -123.09337782859802\n",
      "epoch 13\n",
      "progress: 10.0\n",
      "0\n",
      "7.987022399902344e-05\n",
      "time per batch: 6.018311023712158\n",
      "tensor(558.4789, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.416175842285156e-05\n",
      "time per batch: 5.971937894821167\n",
      "tensor(671.5660, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.510185241699219e-05\n",
      "time per batch: 3.557487964630127\n",
      "tensor(261.7580, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 497.2676696777344\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 6.800e+01 1.290e+02]\n",
      " [0.000e+00 3.230e+02 1.072e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.36384586 0.18754016 0.24738574]\n",
      " [0.77244991 0.89421084 0.82886927]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35875167087875953\n",
      "--------------------\n",
      "total epoch time: -123.73733806610107\n",
      "epoch 14\n",
      "progress: 10.0\n",
      "0\n",
      "7.295608520507812e-05\n",
      "time per batch: 6.17205023765564\n",
      "tensor(581.9780, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.797645568847656e-05\n",
      "time per batch: 6.514224052429199\n",
      "tensor(632.9359, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013017654418945312\n",
      "time per batch: 3.5965609550476074\n",
      "tensor(274.6038, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 496.505859375\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.900e+01 1.480e+02]\n",
      " [0.000e+00 2.530e+02 1.142e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.25422705 0.15923558 0.1953277 ]\n",
      " [0.81843951 0.88875639 0.85208445]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3491373850159883\n",
      "--------------------\n",
      "total epoch time: -122.60936903953552\n",
      "epoch 15\n",
      "progress: 10.0\n",
      "0\n",
      "9.918212890625e-05\n",
      "time per batch: 6.12260890007019\n",
      "tensor(548.0369, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.867813110351562e-05\n",
      "time per batch: 6.432404041290283\n",
      "tensor(640.9636, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001239776611328125\n",
      "time per batch: 3.5010759830474854\n",
      "tensor(298.2675, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 495.7560119628906\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.600e+01 1.510e+02]\n",
      " [0.000e+00 1.920e+02 1.203e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.24361341 0.21637045 0.22640381]\n",
      " [0.86176373 0.87891769 0.87000739]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.36547039952254207\n",
      "--------------------\n",
      "total epoch time: -119.03819990158081\n",
      "epoch 16\n",
      "progress: 10.0\n",
      "0\n",
      "9.918212890625e-05\n",
      "time per batch: 6.156962156295776\n",
      "tensor(651.1808, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.392333984375e-05\n",
      "time per batch: 6.611357927322388\n",
      "tensor(589.8164, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.012222290039062e-05\n",
      "time per batch: 3.509821891784668\n",
      "tensor(244.2075, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 495.0682678222656\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.880e+02 1.207e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.22179618 0.19239041 0.20554602]\n",
      " [0.86531424 0.88255501 0.87379392]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3597799788690139\n",
      "--------------------\n",
      "total epoch time: -123.01033806800842\n",
      "epoch 17\n",
      "progress: 10.0\n",
      "0\n",
      "9.489059448242188e-05\n",
      "time per batch: 9.787472009658813\n",
      "tensor(555.9355, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00027298927307128906\n",
      "time per batch: 6.309532880783081\n",
      "tensor(665.7479, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.082389831542969e-05\n",
      "time per batch: 3.62567400932312\n",
      "tensor(261.3269, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 494.3367614746094\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.880e+02 1.207e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.21458054 0.18244949 0.19717308]\n",
      " [0.86506883 0.88608884 0.87544905]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3575407112115134\n",
      "--------------------\n",
      "total epoch time: -128.20186114311218\n",
      "epoch 18\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001068115234375\n",
      "time per batch: 6.2307960987091064\n",
      "tensor(541.0229, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.296966552734375e-05\n",
      "time per batch: 6.5905022621154785\n",
      "tensor(647.8252, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.606910705566406e-05\n",
      "time per batch: 3.650344133377075\n",
      "tensor(292.0873, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 493.6451721191406\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.860e+02 1.209e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.22404635 0.19595647 0.20880009]\n",
      " [0.86382895 0.88153006 0.87257325]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3604577805763441\n",
      "--------------------\n",
      "total epoch time: -121.60668992996216\n",
      "epoch 19\n",
      "progress: 10.0\n",
      "0\n",
      "8.106231689453125e-05\n",
      "time per batch: 6.205398082733154\n",
      "tensor(596.0409, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.20159912109375e-05\n",
      "time per batch: 6.3481879234313965\n",
      "tensor(595.7095, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.726119995117188e-05\n",
      "time per batch: 3.6222901344299316\n",
      "tensor(287.1158, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 492.9553527832031\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.860e+02 1.209e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.24026437 0.20022194 0.21782779]\n",
      " [0.86869201 0.8907342  0.87951226]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.36578001665028453\n",
      "--------------------\n",
      "total epoch time: -123.72975707054138\n",
      "epoch 20\n",
      "progress: 10.0\n",
      "0\n",
      "9.107589721679688e-05\n",
      "time per batch: 6.1857240200042725\n",
      "tensor(624.9792, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.417533874511719e-05\n",
      "time per batch: 6.37824010848999\n",
      "tensor(622.8087, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.987022399902344e-05\n",
      "time per batch: 3.5250182151794434\n",
      "tensor(229.1385, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 492.3088073730469\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.860e+02 1.209e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.22337729 0.19554473 0.2069388 ]\n",
      " [0.86598493 0.88473084 0.87510188]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3606802266360217\n",
      "--------------------\n",
      "total epoch time: -120.47584271430969\n",
      "epoch 21\n",
      "progress: 10.0\n",
      "0\n",
      "7.796287536621094e-05\n",
      "time per batch: 6.045033931732178\n",
      "tensor(600.7070, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.987022399902344e-05\n",
      "time per batch: 6.239064931869507\n",
      "tensor(602.2858, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.915496826171875e-05\n",
      "time per batch: 3.592785120010376\n",
      "tensor(271.9406, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 491.6444396972656\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.400e+01 1.530e+02]\n",
      " [0.000e+00 1.860e+02 1.209e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.2318904  0.19752353 0.21176471]\n",
      " [0.86849107 0.88714083 0.8776062 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.36312363372340956\n",
      "--------------------\n",
      "total epoch time: -119.90596508979797\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10.0\n",
      "0\n",
      "9.202957153320312e-05\n",
      "time per batch: 6.074416875839233\n",
      "tensor(575.2055, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.82012939453125e-05\n",
      "time per batch: 6.412566900253296\n",
      "tensor(622.0676, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.608268737792969e-05\n",
      "time per batch: 3.559398889541626\n",
      "tensor(275.6323, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 490.9684753417969\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.810e+02 1.214e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.202905   0.17827807 0.18896552]\n",
      " [0.86933397 0.8853206  0.87717994]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35538181750455117\n",
      "--------------------\n",
      "total epoch time: -120.38819813728333\n",
      "epoch 23\n",
      "progress: 10.0\n",
      "0\n",
      "7.677078247070312e-05\n",
      "time per batch: 6.097383737564087\n",
      "tensor(643.4900, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.775161743164062e-05\n",
      "time per batch: 5.997034072875977\n",
      "tensor(597.4818, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.893013000488281e-05\n",
      "time per batch: 3.3980350494384766\n",
      "tensor(229.8701, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 490.2806091308594\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.810e+02 1.214e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.20376673 0.18408449 0.19281304]\n",
      " [0.86806386 0.87855343 0.8732092 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3553407447624375\n",
      "--------------------\n",
      "total epoch time: -119.01625919342041\n",
      "epoch 24\n",
      "progress: 10.0\n",
      "0\n",
      "8.034706115722656e-05\n",
      "time per batch: 6.014433860778809\n",
      "tensor(690.4906, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "9.608268737792969e-05\n",
      "time per batch: 6.386043071746826\n",
      "tensor(596.3513, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.702278137207031e-05\n",
      "time per batch: 3.495384693145752\n",
      "tensor(181.9180, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 489.5866394042969\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.810e+02 1.214e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.18947015 0.16757001 0.17763371]\n",
      " [0.86790936 0.87979969 0.87378075]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3504714882360797\n",
      "--------------------\n",
      "total epoch time: -119.81085801124573\n",
      "epoch 25\n",
      "progress: 10.0\n",
      "0\n",
      "7.987022399902344e-05\n",
      "time per batch: 6.109483003616333\n",
      "tensor(692.9451, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.511543273925781e-05\n",
      "time per batch: 6.154193878173828\n",
      "tensor(580.3124, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.916854858398438e-05\n",
      "time per batch: 3.4267921447753906\n",
      "tensor(193.3060, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 488.8545227050781\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.810e+02 1.214e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.21315536 0.18959994 0.20000151]\n",
      " [0.86813947 0.88537289 0.87661141]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35887097594220646\n",
      "--------------------\n",
      "total epoch time: -117.9408311843872\n",
      "epoch 26\n",
      "progress: 10.0\n",
      "0\n",
      "7.987022399902344e-05\n",
      "time per batch: 6.127968072891235\n",
      "tensor(522.7873, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "7.915496826171875e-05\n",
      "time per batch: 6.452107906341553\n",
      "tensor(630.8315, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.606910705566406e-05\n",
      "time per batch: 3.61252498626709\n",
      "tensor(310.3924, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 488.0037536621094\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.810e+02 1.214e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.21198593 0.1825274  0.19570707]\n",
      " [0.87109291 0.88853267 0.87967597]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35846101521453305\n",
      "--------------------\n",
      "total epoch time: -119.66630506515503\n",
      "epoch 27\n",
      "progress: 10.0\n",
      "0\n",
      "9.584426879882812e-05\n",
      "time per batch: 7.591739892959595\n",
      "tensor(643.8626, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.606910705566406e-05\n",
      "time per batch: 7.746450901031494\n",
      "tensor(582.8212, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.702278137207031e-05\n",
      "time per batch: 3.6765098571777344\n",
      "tensor(234.8835, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 487.1891174316406\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.780e+02 1.217e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.21154401 0.17987947 0.19329627]\n",
      " [0.87190781 0.88946842 0.88047465]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3579236419763012\n",
      "--------------------\n",
      "total epoch time: -127.80161309242249\n",
      "epoch 28\n",
      "progress: 10.0\n",
      "0\n",
      "9.226799011230469e-05\n",
      "time per batch: 5.891179084777832\n",
      "tensor(563.4091, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.082389831542969e-05\n",
      "time per batch: 6.629899978637695\n",
      "tensor(606.2596, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.296966552734375e-05\n",
      "time per batch: 3.5430030822753906\n",
      "tensor(289.2938, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 486.3208312988281\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.780e+02 1.217e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.20374045 0.18018548 0.1908841 ]\n",
      " [0.87160504 0.88773601 0.87956589]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3568166643529774\n",
      "--------------------\n",
      "total epoch time: -121.2184829711914\n",
      "epoch 29\n",
      "progress: 10.0\n",
      "0\n",
      "7.82012939453125e-05\n",
      "time per batch: 5.886667966842651\n",
      "tensor(629.5219, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.7738037109375e-05\n",
      "time per batch: 6.994304895401001\n",
      "tensor(577.0563, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "8.606910705566406e-05\n",
      "time per batch: 3.5959508419036865\n",
      "tensor(249.9295, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 485.5025329589844\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.780e+02 1.217e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.20117578 0.18091466 0.19026728]\n",
      " [0.87258918 0.88746444 0.87994628]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35673785151486775\n",
      "--------------------\n",
      "total epoch time: -122.1373770236969\n",
      "best_score: 0.36578001665028453\n",
      "\n",
      "I => recall: 0.0, precision: 0.0, , f1: 0.0\n",
      "\n",
      "B => recall: 0.24026436856087607, precision: 0.20022194039315155, , f1: 0.21782778768072886\n",
      "\n",
      "O => recall: 0.8686920125183905, precision: 0.8907342010560657, , f1: 0.8795122622701249\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "end!!!\n"
     ]
    }
   ],
   "source": [
    "stop_sign = False\n",
    "time_list1 = []\n",
    "BS = 32\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 1000\n",
    "word_length = 84\n",
    "early_stop_n = 1000\n",
    "size_char = 6\n",
    "num_search = 1000\n",
    "num_epoch = 30\n",
    "pos_size = len(POSMAP)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "data_tr = MyDataloader('../Data/clean84withpos_ne_tr0.txt', '../Data/label84withpos_ne_tr0.txt',\\\n",
    "                               RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "                               '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr0.txt',POSMAP)\n",
    "data_te = MyDataloader('../Data/clean84withpos_ne_te0.txt', '../Data/label84withpos_ne_te0.txt', \\\n",
    "                       RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "                       '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te0.txt',POSMAP)\n",
    "\n",
    "#         train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "#         test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "tr, te = get_indices_random_val_test_split(len(data_tr), 1, 0.0015, True)\n",
    "train_loader = DataLoader(data_tr, batch_size=BS, sampler=tr)\n",
    "test_loader = DataLoader(data_tr, batch_size=BS, sampler=te)\n",
    "BS = 8\n",
    "for IND in range(2):\n",
    "    #BS = 8\n",
    "    tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "    scheduler_n = 1000\n",
    "    word_length = 84\n",
    "    early_stop_n = 1000\n",
    "    max_size_char = 6\n",
    "    num_search = 1000\n",
    "    num_epoch = 30\n",
    "    pos_size = len(POSMAP)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(device)\n",
    "\n",
    "#     data_tr = MyDataloader('../Data/clean84withpos_ne_tr'+ str(IND) +'.txt', '../Data/label84withpos_ne_tr'+ str(IND) +'.txt',\\\n",
    "#                            RULEs, word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "#                            '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr'+ str(IND) +'.txt',POSMAP)\n",
    "#     data_te = MyDataloader('../Data/clean84withpos_ne_te'+ str(IND) +'.txt', '../Data/label84withpos_ne_te'+ str(IND) +'.txt', \\\n",
    "#                            RULEs, word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "#                            '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te'+ str(IND) +'.txt',POSMAP)\n",
    "\n",
    "#     train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "#     test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    grucrf_dropout = [0, 0.15, 0.30, 0.45, 0.60]#random.uniform(0.2,0.5)#0.5#random.uniform(0.2,0.5)#0.5\n",
    "    total_search = len(grucrf_dropout)*2\n",
    "    for i in grucrf_dropout:\n",
    "        grucrf_hidden_size = 128#random.choice([128])#5\n",
    "        LR = 10**(-4)#**random.uniform(-4,-5)#0.001\n",
    "        print(f'lstmcrf_dropout = DO_FCN_LSTMCRF: {i}')\n",
    "        print(f'lstmcrf_hidden_size: {grucrf_hidden_size}, LR: {LR}')\n",
    "\n",
    "#         NER = CNN_GRU_word_pos(BS, 300, word_length, grucrf_hidden_size, i, True, tags, \\\n",
    "#                                i, pos_size, 0.5)\n",
    "        NER = CNN_GRU_word_pos(BS, 300, word_length, grucrf_hidden_size, 0, True, tags, \\\n",
    "                               0, pos_size, 0)\n",
    "\n",
    "        optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "        my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "        print(device)\n",
    "        NER.to(device)\n",
    "        best_score = 0\n",
    "        best_mat = np.zeros((len(tags)-1,3))\n",
    "        cnt_idle = 0\n",
    "        for epoch in range(num_epoch):\n",
    "            ttt = time()\n",
    "            print(f'epoch {epoch}')\n",
    "            all_loss = []\n",
    "            for ind, batch_x in enumerate(train_loader):\n",
    "                ttt2 = time()\n",
    "                print(f'progress: {(100*(grucrf_dropout.index(i)+1)*(IND+1))/total_search}')\n",
    "                if ind%5 == 0:\n",
    "                    print(ind)\n",
    "                t2 = time()\n",
    "                NER = NER.train()\n",
    "                print(time() - t2)\n",
    "                NER.zero_grad()\n",
    "                t1 = time()\n",
    "                loss = NER(batch_x)\n",
    "                loss = loss*(-1)\n",
    "                print(f'time per batch: {time() - t1}')\n",
    "                print(loss)\n",
    "                all_loss.append(loss)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "                optimizer.step()\n",
    "                time_list1.append(time()-ttt2)\n",
    "            total_loss = sum(all_loss)/(ind + 1)\n",
    "            my_scheduler.step(total_loss)\n",
    "            print(f'total loss of epoch: {total_loss.item()}')\n",
    "            print('testing')\n",
    "            per_mat = np.zeros((len(tags), 3))\n",
    "            cnt_mat = np.zeros((len(tags), 3))\n",
    "            for ind, batch_test in enumerate(test_loader):\n",
    "                NER = NER.eval()\n",
    "                output = NER.predict(batch_test)\n",
    "                a, b= eval_score(tags, output, batch_test[2])\n",
    "                per_mat += a\n",
    "                cnt_mat += b\n",
    "            per_mat = per_mat/(ind+1)\n",
    "            per_mat = per_mat[:len(tags),:]\n",
    "            cnt_mat = cnt_mat[:len(tags),:]\n",
    "            print(cnt_mat)\n",
    "            print(per_mat)\n",
    "            score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "            if best_score < score:\n",
    "                best_mat=per_mat\n",
    "                best_score = score\n",
    "                cnt_idle = 0\n",
    "            else:\n",
    "                cnt_idle += 1\n",
    "            print(f'overall score: {score}')\n",
    "            print('--------------------')\n",
    "            if early_stop_n == cnt_idle:\n",
    "                break\n",
    "            print(f'total epoch time: {ttt-time()}')\n",
    "        print(f'best_score: {best_score}\\n')\n",
    "        print(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "        print(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "        print(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "        print(f'----------------------------------\\n')\n",
    "        break\n",
    "    break\n",
    "print('end!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.]\n",
      " [  0.   6.  29.]\n",
      " [  0.  37. 253.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 4.100e+01 1.560e+02]\n",
      " [0.000e+00 1.780e+02 1.217e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(cnt_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment2 char with POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "lstmcrf_dropout = DO_FCN_LSTMCRF: 0.6\n",
      "lstmcrf_hidden_size: 128, LR: 0.001\n",
      "cpu\n",
      "epoch 0\n",
      "progress: 50.0\n",
      "0\n",
      "0.00010704994201660156\n",
      "time per batch: 8.43209195137024\n",
      "tensor(1379.6573, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001819133758544922\n",
      "time per batch: 8.654768943786621\n",
      "tensor(876.6379, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00040411949157714844\n",
      "time per batch: 4.156712055206299\n",
      "tensor(291.5123, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 849.2692260742188\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.95e+02 2.00e+00]\n",
      " [0.00e+00 1.39e+03 5.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.98780488 0.12186748 0.2165372 ]\n",
      " [0.00353813 0.72222222 0.00703907]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.07452542321587348\n",
      "--------------------\n",
      "total epoch time: -132.42664098739624\n",
      "epoch 1\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011801719665527344\n",
      "time per batch: 6.686136960983276\n",
      "tensor(907.5428, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001342296600341797\n",
      "time per batch: 7.336103916168213\n",
      "tensor(986.6364, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012803077697753906\n",
      "time per batch: 3.4878640174865723\n",
      "tensor(314.1108, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 736.0966796875\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.920e+02 5.000e+00]\n",
      " [0.000e+00 1.375e+03 2.000e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.96939836 0.12430949 0.21997861]\n",
      " [0.01239886 0.68686869 0.02434929]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08144263357821335\n",
      "--------------------\n",
      "total epoch time: -130.029935836792\n",
      "epoch 2\n",
      "progress: 50.0\n",
      "0\n",
      "0.000125885009765625\n",
      "time per batch: 7.0607311725616455\n",
      "tensor(884.1835, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001647472381591797\n",
      "time per batch: 7.705854892730713\n",
      "tensor(883.5129, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014209747314453125\n",
      "time per batch: 3.807629108428955\n",
      "tensor(425.6598, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 731.1188354492188\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.880e+02 9.000e+00]\n",
      " [0.000e+00 1.366e+03 2.900e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.96148268 0.12206176 0.21636287]\n",
      " [0.02042279 0.82407407 0.03966359]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08534215575868032\n",
      "--------------------\n",
      "total epoch time: -128.07795906066895\n",
      "epoch 3\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012302398681640625\n",
      "time per batch: 6.007447242736816\n",
      "tensor(908.1423, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012493133544921875\n",
      "time per batch: 6.300598621368408\n",
      "tensor(900.5726, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001289844512939453\n",
      "time per batch: 3.6019701957702637\n",
      "tensor(372.7352, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 727.1499633789062\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.860e+02 1.100e+01]\n",
      " [0.000e+00 1.359e+03 3.600e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.93868922 0.11885353 0.21059786]\n",
      " [0.02525948 0.74191033 0.04882306]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08647364042142974\n",
      "--------------------\n",
      "total epoch time: -123.3330328464508\n",
      "epoch 4\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012493133544921875\n",
      "time per batch: 7.905043840408325\n",
      "tensor(1020.8658, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0002040863037109375\n",
      "time per batch: 7.676162004470825\n",
      "tensor(913.5485, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00038814544677734375\n",
      "time per batch: 3.626680612564087\n",
      "tensor(235.2586, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 723.2243041992188\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.820e+02 1.500e+01]\n",
      " [0.000e+00 1.349e+03 4.600e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.91871083 0.12250061 0.21591492]\n",
      " [0.0312652  0.70742407 0.05981786]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09191092528824374\n",
      "--------------------\n",
      "total epoch time: -129.3985538482666\n",
      "epoch 5\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011491775512695312\n",
      "time per batch: 6.017075777053833\n",
      "tensor(880.5450, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00011587142944335938\n",
      "time per batch: 6.407957077026367\n",
      "tensor(917.9563, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00019407272338867188\n",
      "time per batch: 3.6133179664611816\n",
      "tensor(359.2771, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 719.259521484375\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.820e+02 1.500e+01]\n",
      " [0.000e+00 1.339e+03 5.600e+01]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.93245514 0.12004894 0.21265487]\n",
      " [0.04421373 0.80897266 0.08374434]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09879973616387443\n",
      "--------------------\n",
      "total epoch time: -126.63132286071777\n",
      "epoch 6\n",
      "progress: 50.0\n",
      "0\n",
      "0.00013709068298339844\n",
      "time per batch: 7.140580892562866\n",
      "tensor(1065.3236, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001327991485595703\n",
      "time per batch: 8.025575160980225\n",
      "tensor(720.3581, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00019502639770507812\n",
      "time per batch: 3.9549901485443115\n",
      "tensor(360.8815, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 715.52099609375\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.710e+02 2.600e+01]\n",
      " [0.000e+00 1.272e+03 1.230e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.87595253 0.12419881 0.21681201]\n",
      " [0.08917786 0.84948565 0.16121771]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.1260099045529948\n",
      "--------------------\n",
      "total epoch time: -130.94645404815674\n",
      "epoch 7\n",
      "progress: 50.0\n",
      "0\n",
      "0.00015592575073242188\n",
      "time per batch: 6.247288703918457\n",
      "tensor(866.1232, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.000125885009765625\n",
      "time per batch: 6.143205165863037\n",
      "tensor(835.8469, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012183189392089844\n",
      "time per batch: 3.732448101043701\n",
      "tensor(432.8053, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 711.591796875\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.670e+02 3.000e+01]\n",
      " [0.000e+00 1.232e+03 1.630e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.85148492 0.12195106 0.21327074]\n",
      " [0.11921146 0.84853996 0.20897175]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.14074749769515335\n",
      "--------------------\n",
      "total epoch time: -126.22384595870972\n",
      "epoch 8\n",
      "progress: 50.0\n",
      "0\n",
      "0.00015807151794433594\n",
      "time per batch: 7.084740877151489\n",
      "tensor(994.6403, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.000141143798828125\n",
      "time per batch: 7.729798793792725\n",
      "tensor(711.1148, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001628398895263672\n",
      "time per batch: 3.9137279987335205\n",
      "tensor(417.9324, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 707.8958129882812\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.640e+02 3.300e+01]\n",
      " [0.000e+00 1.219e+03 1.760e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.8219703  0.11253745 0.19750728]\n",
      " [0.12731402 0.84456875 0.22126193]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.13958973888959011\n",
      "--------------------\n",
      "total epoch time: -130.37937211990356\n",
      "epoch 9\n",
      "progress: 50.0\n",
      "0\n",
      "0.0001347064971923828\n",
      "time per batch: 6.169068813323975\n",
      "tensor(854.3845, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001380443572998047\n",
      "time per batch: 6.1466851234436035\n",
      "tensor(1005.4902, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001220703125\n",
      "time per batch: 3.469615936279297\n",
      "tensor(252.6964, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 704.1903686523438\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.640e+02 3.300e+01]\n",
      " [0.000e+00 1.215e+03 1.800e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.84130182 0.12052772 0.21080529]\n",
      " [0.12731951 0.85091771 0.22140219]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.14406915849075586\n",
      "--------------------\n",
      "total epoch time: -126.04300808906555\n",
      "epoch 10\n",
      "progress: 50.0\n",
      "0\n",
      "0.0001399517059326172\n",
      "time per batch: 7.192466974258423\n",
      "tensor(980.9722, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00017213821411132812\n",
      "time per batch: 7.657400131225586\n",
      "tensor(652.6318, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012493133544921875\n",
      "time per batch: 6.7382588386535645\n",
      "tensor(467.6538, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 700.4192504882812\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.47e+02 5.00e+01]\n",
      " [0.00e+00 1.07e+03 3.25e+02]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.73696433 0.12621634 0.21488906]\n",
      " [0.23450068 0.85566486 0.36792387]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.1942709770471621\n",
      "--------------------\n",
      "total epoch time: -150.66186213493347\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 50.0\n",
      "0\n",
      "0.00013589859008789062\n",
      "time per batch: 7.830029010772705\n",
      "tensor(748.0881, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014710426330566406\n",
      "time per batch: 8.668892860412598\n",
      "tensor(956.8408, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014090538024902344\n",
      "time per batch: 4.933787822723389\n",
      "tensor(384.9534, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 696.62744140625\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  84. 113.]\n",
      " [  0. 790. 605.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.4251715  0.10351797 0.16550619]\n",
      " [0.43470905 0.83069014 0.57048898]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.24533172438511205\n",
      "--------------------\n",
      "total epoch time: -146.51898646354675\n",
      "epoch 12\n",
      "progress: 50.0\n",
      "0\n",
      "0.0001430511474609375\n",
      "time per batch: 8.059916019439697\n",
      "tensor(930.5657, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013899803161621094\n",
      "time per batch: 9.062623023986816\n",
      "tensor(821.2032, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00017833709716796875\n",
      "time per batch: 4.737653970718384\n",
      "tensor(327.5558, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 693.1082153320312\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  84. 113.]\n",
      " [  0. 790. 605.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.41417749 0.09632922 0.15580412]\n",
      " [0.43295082 0.83047274 0.56896901]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2415910437871649\n",
      "--------------------\n",
      "total epoch time: -135.90027689933777\n",
      "epoch 13\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012803077697753906\n",
      "time per batch: 7.6587042808532715\n",
      "tensor(822.5904, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001380443572998047\n",
      "time per batch: 7.937855958938599\n",
      "tensor(985.3568, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014495849609375\n",
      "time per batch: 4.0033440589904785\n",
      "tensor(260.2136, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 689.3869018554688\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  82. 115.]\n",
      " [  0. 737. 658.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.42378866 0.10050594 0.16053603]\n",
      " [0.47306881 0.85471489 0.60818112]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2562390483653061\n",
      "--------------------\n",
      "total epoch time: -132.4392910003662\n",
      "epoch 14\n",
      "progress: 50.0\n",
      "0\n",
      "0.0001251697540283203\n",
      "time per batch: 6.903527736663818\n",
      "tensor(940.3549, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012493133544921875\n",
      "time per batch: 7.547945261001587\n",
      "tensor(839.4220, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00016379356384277344\n",
      "time per batch: 4.478035926818848\n",
      "tensor(277.5579, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 685.7782592773438\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  82. 115.]\n",
      " [  0. 736. 659.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.37854738 0.09493518 0.15055386]\n",
      " [0.47762927 0.82975124 0.60519961]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2519178245378902\n",
      "--------------------\n",
      "total epoch time: -129.68704295158386\n",
      "epoch 15\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011277198791503906\n",
      "time per batch: 6.148126125335693\n",
      "tensor(953.7232, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001342296600341797\n",
      "time per batch: 7.649188280105591\n",
      "tensor(768.2325, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013399124145507812\n",
      "time per batch: 3.764753818511963\n",
      "tensor(324.4458, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 682.1338500976562\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  82. 115.]\n",
      " [  0. 736. 659.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.41689338 0.09749272 0.15778309]\n",
      " [0.47557115 0.85584314 0.61139739]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2563934917336745\n",
      "--------------------\n",
      "total epoch time: -128.63531279563904\n",
      "epoch 16\n",
      "progress: 50.0\n",
      "0\n",
      "0.00022292137145996094\n",
      "time per batch: 7.285146951675415\n",
      "tensor(701.4238, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00015020370483398438\n",
      "time per batch: 7.569026231765747\n",
      "tensor(1005.0816, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00019311904907226562\n",
      "time per batch: 3.7664618492126465\n",
      "tensor(328.6127, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 678.3726806640625\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  78. 119.]\n",
      " [  0. 695. 700.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.39250745 0.10033014 0.15961998]\n",
      " [0.50535614 0.85445663 0.63504014]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2648867053209177\n",
      "--------------------\n",
      "total epoch time: -127.94174885749817\n",
      "epoch 17\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011396408081054688\n",
      "time per batch: 6.2994890213012695\n",
      "tensor(906.0571, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013780593872070312\n",
      "time per batch: 6.653800010681152\n",
      "tensor(772.7779, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001392364501953125\n",
      "time per batch: 3.5613300800323486\n",
      "tensor(345.9049, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 674.9132690429688\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  73. 124.]\n",
      " [  0. 653. 742.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.39151614 0.10284634 0.16271772]\n",
      " [0.52873213 0.86048558 0.65430002]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.27233924776976576\n",
      "--------------------\n",
      "total epoch time: -126.93590998649597\n",
      "epoch 18\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011515617370605469\n",
      "time per batch: 7.1783201694488525\n",
      "tensor(843.6984, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014328956604003906\n",
      "time per batch: 7.383732795715332\n",
      "tensor(843.1890, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013327598571777344\n",
      "time per batch: 3.738996982574463\n",
      "tensor(327.0091, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 671.2988891601562\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  73. 124.]\n",
      " [  0. 653. 742.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.36837359 0.10554173 0.16219856]\n",
      " [0.53949838 0.84885529 0.65887026]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.27368960690350125\n",
      "--------------------\n",
      "total epoch time: -126.45839190483093\n",
      "epoch 19\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012230873107910156\n",
      "time per batch: 6.026087045669556\n",
      "tensor(807.2769, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.000125885009765625\n",
      "time per batch: 6.188384056091309\n",
      "tensor(751.1797, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013494491577148438\n",
      "time per batch: 3.469506025314331\n",
      "tensor(444.4811, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 667.6459350585938\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  73. 124.]\n",
      " [  0. 653. 742.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33972071 0.0917336  0.14434492]\n",
      " [0.53288567 0.85518515 0.6565865 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2669771409742023\n",
      "--------------------\n",
      "total epoch time: -122.08648705482483\n",
      "epoch 20\n",
      "progress: 50.0\n",
      "0\n",
      "0.0001399517059326172\n",
      "time per batch: 6.643809080123901\n",
      "tensor(684.4137, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00011706352233886719\n",
      "time per batch: 8.055520057678223\n",
      "tensor(902.3742, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00018286705017089844\n",
      "time per batch: 3.6182122230529785\n",
      "tensor(405.4409, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 664.0762329101562\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  73. 124.]\n",
      " [  0. 653. 742.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33731347 0.09148491 0.1438803 ]\n",
      " [0.53158952 0.85251214 0.65479389]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2662247276988011\n",
      "--------------------\n",
      "total epoch time: -127.67536091804504\n",
      "epoch 21\n",
      "progress: 50.0\n",
      "0\n",
      "0.00011610984802246094\n",
      "time per batch: 6.419595956802368\n",
      "tensor(814.0471, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001289844512939453\n",
      "time per batch: 6.670370101928711\n",
      "tensor(808.3391, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014400482177734375\n",
      "time per batch: 3.4627890586853027\n",
      "tensor(359.6456, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 660.67724609375\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 565. 830.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.31529199 0.09656392 0.14623011]\n",
      " [0.58449217 0.8651959  0.6966863 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.28097213620266054\n",
      "--------------------\n",
      "total epoch time: -130.43819189071655\n",
      "epoch 22\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012302398681640625\n",
      "time per batch: 6.973567962646484\n",
      "tensor(845.9450, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00011491775512695312\n",
      "time per batch: 7.64679479598999\n",
      "tensor(797.0176, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012302398681640625\n",
      "time per batch: 3.6278321743011475\n",
      "tensor(328.6620, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 657.2081909179688\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 565. 830.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.34331659 0.10427764 0.15972027]\n",
      " [0.59210639 0.86573381 0.70298189]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2875673849900551\n",
      "--------------------\n",
      "total epoch time: -129.4585587978363\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 50.0\n",
      "0\n",
      "0.00012421607971191406\n",
      "time per batch: 6.147907018661499\n",
      "tensor(741.3986, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00043892860412597656\n",
      "time per batch: 7.257084131240845\n",
      "tensor(939.1605, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012993812561035156\n",
      "time per batch: 3.4747719764709473\n",
      "tensor(280.5001, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 653.6864013671875\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 565. 830.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33374486 0.10537539 0.15996578]\n",
      " [0.59287982 0.86049757 0.70182819]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.28726465583729754\n",
      "--------------------\n",
      "total epoch time: -126.87371873855591\n",
      "epoch 24\n",
      "progress: 50.0\n",
      "0\n",
      "0.000141143798828125\n",
      "time per batch: 6.237536191940308\n",
      "tensor(793.9743, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00017690658569335938\n",
      "time per batch: 7.7300169467926025\n",
      "tensor(845.2818, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00011992454528808594\n",
      "time per batch: 3.592409133911133\n",
      "tensor(311.3255, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 650.19384765625\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 565. 830.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33148241 0.11743171 0.16931814]\n",
      " [0.6095665  0.85094013 0.70862666]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.29264826624071755\n",
      "--------------------\n",
      "total epoch time: -126.70733904838562\n",
      "epoch 25\n",
      "progress: 50.0\n",
      "0\n",
      "0.00013113021850585938\n",
      "time per batch: 7.74974799156189\n",
      "tensor(802.0696, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00013589859008789062\n",
      "time per batch: 7.771142959594727\n",
      "tensor(828.5862, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.000125885009765625\n",
      "time per batch: 3.7502520084381104\n",
      "tensor(309.5113, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 646.7223510742188\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 565. 830.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33029127 0.09847462 0.14994125]\n",
      " [0.59099175 0.87002246 0.70326998]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2844037427897974\n",
      "--------------------\n",
      "total epoch time: -129.31591606140137\n",
      "epoch 26\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012683868408203125\n",
      "time per batch: 7.085926055908203\n",
      "tensor(826.3359, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012612342834472656\n",
      "time per batch: 7.831796169281006\n",
      "tensor(672.5177, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00011396408081054688\n",
      "time per batch: 3.635496139526367\n",
      "tensor(430.8483, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 643.2339477539062\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  64. 133.]\n",
      " [  0. 550. 845.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.31076583 0.09919896 0.15031384]\n",
      " [0.59312303 0.8550938  0.69991793]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.28341058838310956\n",
      "--------------------\n",
      "total epoch time: -131.3945689201355\n",
      "epoch 27\n",
      "progress: 50.0\n",
      "0\n",
      "0.00012803077697753906\n",
      "time per batch: 7.232934951782227\n",
      "tensor(707.8414, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001430511474609375\n",
      "time per batch: 7.271362781524658\n",
      "tensor(807.8517, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00015401840209960938\n",
      "time per batch: 3.6089470386505127\n",
      "tensor(403.5873, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 639.7601928710938\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  64. 133.]\n",
      " [  0. 543. 852.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33259424 0.10624429 0.16006053]\n",
      " [0.61110549 0.86790351 0.71692592]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.2923288168690092\n",
      "--------------------\n",
      "total epoch time: -129.47852993011475\n",
      "epoch 28\n",
      "progress: 50.0\n",
      "0\n",
      "0.00014901161193847656\n",
      "time per batch: 7.254479885101318\n",
      "tensor(881.6584, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001239776611328125\n",
      "time per batch: 7.746945142745972\n",
      "tensor(718.2367, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.0001971721649169922\n",
      "time per batch: 3.703584671020508\n",
      "tensor(309.6643, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 636.5198364257812\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  64. 133.]\n",
      " [  0. 541. 854.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.34125978 0.11473886 0.17158701]\n",
      " [0.61282607 0.86372469 0.71693077]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.29617259577583765\n",
      "--------------------\n",
      "total epoch time: -130.52075481414795\n",
      "epoch 29\n",
      "progress: 50.0\n",
      "0\n",
      "0.00013589859008789062\n",
      "time per batch: 7.038178205490112\n",
      "tensor(724.6938, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00012373924255371094\n",
      "time per batch: 6.311290264129639\n",
      "tensor(822.9444, grad_fn=<MulBackward>)\n",
      "progress: 50.0\n",
      "0.00014495849609375\n",
      "time per batch: 3.7723751068115234\n",
      "tensor(351.3015, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 632.9799194335938\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  64. 133.]\n",
      " [  0. 541. 854.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.30719807 0.11928381 0.16577741]\n",
      " [0.62298218 0.84202108 0.71431574]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.29336438383269997\n",
      "--------------------\n",
      "total epoch time: -129.24605321884155\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30\n",
    "time_list2 = []\n",
    "\n",
    "for IND in range(2):\n",
    "    \n",
    "    #BS = 8\n",
    "    tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "    scheduler_n = 10002\n",
    "    word_length = 84\n",
    "    early_stop_n = 10003\n",
    "    max_size_char = [6]#[5, 10, 20]\n",
    "    nums_filter = [1]\n",
    "    use_BN = True\n",
    "    activation_func = True\n",
    "    input_channel = 1\n",
    "    kernel_sizes = [3]\n",
    "    same_padding = True\n",
    "    num_char_encoding_size = 135\n",
    "    output_size = 64\n",
    "    size_of_embedding = 300\n",
    "    pos_size = len(POSMAP)\n",
    "    FCN = False\n",
    "    grucrf_dropout = [0.6]#[0, 0.15, 0.30, 0.45, 0.60]\n",
    "    total_search = len(max_size_char)*len(grucrf_dropout)*2\n",
    "    for size_char in max_size_char:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "\n",
    "#         data_tr = MyDataloader('../Data/clean84withpos_ne_tr'+ str(IND) +'.txt', '../Data/label84withpos_ne_tr'+ str(IND) +'.txt',\\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr'+ str(IND) +'.txt',POSMAP)\n",
    "#         data_te = MyDataloader('../Data/clean84withpos_ne_te'+ str(IND) +'.txt', '../Data/label84withpos_ne_te'+ str(IND) +'.txt', \\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te'+ str(IND) +'.txt',POSMAP)\n",
    "\n",
    "# #         train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "# #         test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "#         tr, te = get_indices_random_val_test_split(len(data_tr), 1, 0.0005, True)\n",
    "#         train_loader = DataLoader(data_tr, batch_size=BS, sampler=tr)\n",
    "#         test_loader = DataLoader(data_tr, batch_size=BS, sampler=te)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        for i in grucrf_dropout:\n",
    "            \n",
    "            grucrf_hidden_size = 128\n",
    "            LR = 10**(-3)\n",
    "            print(f'lstmcrf_dropout = DO_FCN_LSTMCRF: {i}')\n",
    "            print(f'lstmcrf_hidden_size: {grucrf_hidden_size}, LR: {LR}')\n",
    "            NER = CNN_GRU_char_pos(BS, size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "                 kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, grucrf_hidden_size, \\\n",
    "                 0, True, tags, 0, pos_size, FCN, 0)\n",
    "            \n",
    "            class over_all_NER2( BS, 135, word_length, size_char, 0, True, 5, size_of_embedding:, num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)',\\\n",
    "                 pos_size: '(int) size of pos embedding'):\n",
    "#             NER = CNN_GRU_char_pos(BS, size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "#                  kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, grucrf_hidden_size, \\\n",
    "#                  i, True, tags, i, pos_size, FCN, 0.5)\n",
    "\n",
    "            optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "            my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "            print(device)\n",
    "            NER.to(device)\n",
    "            best_score = 0\n",
    "            best_mat = np.zeros((len(tags)-1,3))\n",
    "            cnt_idle = 0\n",
    "            for epoch in range(num_epoch):\n",
    "                ttt = time()\n",
    "                print(f'epoch {epoch}')\n",
    "                all_loss = []\n",
    "                for ind, batch_x in enumerate(train_loader):\n",
    "                    ttt2 = time()\n",
    "                    print(f'progress: {(100*(grucrf_dropout.index(i)+1)*(max_size_char.index(size_char)+1)*(IND+1))/total_search}')\n",
    "                    if ind%5 == 0:\n",
    "                        print(ind)\n",
    "                    t2 = time()\n",
    "                    NER = NER.train()\n",
    "                    print(time() - t2)\n",
    "                    NER.zero_grad()\n",
    "                    t1 = time()\n",
    "                    loss = NER(batch_x)\n",
    "                    loss = loss*(-1)\n",
    "                    print(f'time per batch: {time() - t1}')\n",
    "                    print(loss)\n",
    "                    all_loss.append(loss)\n",
    "                    loss.backward()\n",
    "                    #nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "                    optimizer.step()\n",
    "                    time_list2.append(time()-ttt2)\n",
    "                total_loss = sum(all_loss)/(ind + 1)\n",
    "                my_scheduler.step(total_loss)\n",
    "                \n",
    "                print(f'total loss of epoch: {total_loss.item()}')\n",
    "                print('testing')\n",
    "                per_mat = np.zeros((len(tags), 3))\n",
    "                cnt_mat = np.zeros((len(tags), 3))\n",
    "                for ind, batch_test in enumerate(test_loader):\n",
    "                    NER = NER.eval()\n",
    "                    output = NER.predict(batch_test)\n",
    "                    a, b = eval_score(tags, output, batch_test[2])\n",
    "                    per_mat += a\n",
    "                    cnt_mat += b\n",
    "                per_mat = per_mat/(ind+1)\n",
    "                per_mat = per_mat[:len(tags),:]\n",
    "                cnt_mat = cnt_mat[:len(tags),:]\n",
    "                print(cnt_mat)\n",
    "                print(per_mat)\n",
    "                score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "                if best_score < score:\n",
    "                    best_mat=per_mat\n",
    "                    best_score = score\n",
    "                    cnt_idle = 0\n",
    "                else:\n",
    "                    cnt_idle += 1\n",
    "                print(f'overall score: {score}')\n",
    "                print('--------------------')\n",
    "                if early_stop_n == cnt_idle:\n",
    "                    break\n",
    "                print(f'total epoch time: {ttt-time()}')\n",
    "            break\n",
    "            print(f'best_score: {best_score}\\n')\n",
    "            print(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "            print(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "            print(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "            print(f'----------------------------------\\n')\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment3 char, word, POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "lstmcrf_dropout = DO_FCN_LSTMCRF: 0\n",
      "lstmcrf_hidden_size: 128, LR: 0.0001\n",
      "cpu\n",
      "epoch 0\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011801719665527344\n",
      "time per batch: 7.582920074462891\n",
      "tensor(514.3008, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015115737915039062\n",
      "time per batch: 9.895946025848389\n",
      "tensor(517.1383, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015020370483398438\n",
      "time per batch: 3.740856170654297\n",
      "tensor(210.5461, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 413.9951171875\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.86017316 0.10804996 0.19160554]\n",
      " [0.03809868 0.68005952 0.07214797]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08791783595881804\n",
      "--------------------\n",
      "total epoch time: -153.87249088287354\n",
      "epoch 1\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012803077697753906\n",
      "time per batch: 5.742196798324585\n",
      "tensor(436.2852, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013303756713867188\n",
      "time per batch: 6.1176698207855225\n",
      "tensor(539.6360, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001220703125\n",
      "time per batch: 3.4480550289154053\n",
      "tensor(203.5579, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 393.1597595214844\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.8866571  0.11742743 0.20730334]\n",
      " [0.04297224 0.7202381  0.08101424]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09610585814192078\n",
      "--------------------\n",
      "total epoch time: -117.18610882759094\n",
      "epoch 2\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001251697540283203\n",
      "time per batch: 5.7881810665130615\n",
      "tensor(458.0338, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001220703125\n",
      "time per batch: 5.806968688964844\n",
      "tensor(509.7504, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001239776611328125\n",
      "time per batch: 3.310884952545166\n",
      "tensor(210.2195, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 392.6678771972656\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.87926591 0.11978246 0.21039412]\n",
      " [0.03854977 0.68005952 0.07295349]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09444920548319263\n",
      "--------------------\n",
      "total epoch time: -112.3110511302948\n",
      "epoch 3\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011610984802246094\n",
      "time per batch: 5.772711992263794\n",
      "tensor(436.1103, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00011801719665527344\n",
      "time per batch: 5.763248920440674\n",
      "tensor(563.4471, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001239776611328125\n",
      "time per batch: 3.3054449558258057\n",
      "tensor(176.4939, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 392.01708984375\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.88316139 0.11122292 0.19660544]\n",
      " [0.03833203 0.70684524 0.07253142]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08971228506793627\n",
      "--------------------\n",
      "total epoch time: -112.96583914756775\n",
      "epoch 4\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001342296600341797\n",
      "time per batch: 5.768923759460449\n",
      "tensor(450.9390, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00011682510375976562\n",
      "time per batch: 5.829744815826416\n",
      "tensor(470.4933, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012612342834472656\n",
      "time per batch: 3.3062846660614014\n",
      "tensor(253.1288, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 391.5203857421875\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.89308273 0.11110945 0.19696953]\n",
      " [0.04064471 0.73363095 0.07698881]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09131944802950857\n",
      "--------------------\n",
      "total epoch time: -113.07147097587585\n",
      "epoch 5\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011897087097167969\n",
      "time per batch: 5.76698112487793\n",
      "tensor(510.1457, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013208389282226562\n",
      "time per batch: 5.794419050216675\n",
      "tensor(479.3688, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015783309936523438\n",
      "time per batch: 3.3932011127471924\n",
      "tensor(183.4206, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 390.9783630371094\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.887841   0.11070878 0.19623299]\n",
      " [0.03874637 0.7202381  0.07345919]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08989739164682102\n",
      "--------------------\n",
      "total epoch time: -112.63052916526794\n",
      "epoch 6\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011801719665527344\n",
      "time per batch: 5.7526819705963135\n",
      "tensor(481.6405, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.000125885009765625\n",
      "time per batch: 5.79227876663208\n",
      "tensor(451.0718, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001227855682373047\n",
      "time per batch: 3.4265222549438477\n",
      "tensor(238.7406, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 390.4842834472656\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.86952711 0.115278   0.20346207]\n",
      " [0.03911736 0.68005952 0.07394582]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.0924692976845531\n",
      "--------------------\n",
      "total epoch time: -112.6517858505249\n",
      "epoch 7\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012302398681640625\n",
      "time per batch: 5.848320007324219\n",
      "tensor(543.3920, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001220703125\n",
      "time per batch: 5.810476064682007\n",
      "tensor(415.9974, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001232624053955078\n",
      "time per batch: 3.2949321269989014\n",
      "tensor(210.2877, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 389.8923645019531\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.88616235 0.1126     0.19970921]\n",
      " [0.03981324 0.7202381  0.07542861]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09171260834196227\n",
      "--------------------\n",
      "total epoch time: -113.11657094955444\n",
      "epoch 8\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011777877807617188\n",
      "time per batch: 5.758566856384277\n",
      "tensor(588.3013, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001347064971923828\n",
      "time per batch: 5.767100811004639\n",
      "tensor(352.5039, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00014400482177734375\n",
      "time per batch: 3.3182590007781982\n",
      "tensor(227.2146, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 389.3399658203125\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.8659107  0.1114818  0.1974867 ]\n",
      " [0.03721139 0.66666667 0.07048024]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.08932231189807753\n",
      "--------------------\n",
      "total epoch time: -111.98029494285583\n",
      "epoch 9\n",
      "progress: 10.0\n",
      "0\n",
      "0.000125885009765625\n",
      "time per batch: 5.774779796600342\n",
      "tensor(442.1125, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001361370086669922\n",
      "time per batch: 5.785161018371582\n",
      "tensor(512.1271, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013303756713867188\n",
      "time per batch: 3.307157039642334\n",
      "tensor(211.8488, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 388.6961364746094\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.87981427 0.14720233 0.24526554]\n",
      " [0.04554016 0.68005952 0.08459499]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.10995350880227973\n",
      "--------------------\n",
      "total epoch time: -113.34611415863037\n",
      "epoch 10\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012111663818359375\n",
      "time per batch: 6.168184995651245\n",
      "tensor(489.1552, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015878677368164062\n",
      "time per batch: 5.872562885284424\n",
      "tensor(492.0105, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00011801719665527344\n",
      "time per batch: 3.3490500450134277\n",
      "tensor(182.0571, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 387.740966796875\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.88297307 0.1140344  0.20185818]\n",
      " [0.0394817  0.70684524 0.07477167]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09220995095853703\n",
      "--------------------\n",
      "total epoch time: -113.26805090904236\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10.0\n",
      "0\n",
      "0.0001239776611328125\n",
      "time per batch: 5.758953094482422\n",
      "tensor(500.7930, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013399124145507812\n",
      "time per batch: 5.790640115737915\n",
      "tensor(462.2381, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013303756713867188\n",
      "time per batch: 3.342494010925293\n",
      "tensor(197.4832, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 386.8381042480469\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.88590073 0.12260971 0.21467757]\n",
      " [0.04130592 0.70684524 0.07794573]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09754109782677522\n",
      "--------------------\n",
      "total epoch time: -111.84771919250488\n",
      "epoch 12\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012373924255371094\n",
      "time per batch: 5.820000886917114\n",
      "tensor(397.1657, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013375282287597656\n",
      "time per batch: 5.876884937286377\n",
      "tensor(583.8167, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012302398681640625\n",
      "time per batch: 3.3095543384552\n",
      "tensor(177.0110, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 385.997802734375\n",
      "testing\n",
      "[[0.00e+00 1.00e+00 0.00e+00]\n",
      " [0.00e+00 1.74e+02 2.30e+01]\n",
      " [0.00e+00 1.34e+03 5.50e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.89381914 0.11588354 0.20497869]\n",
      " [0.04062486 0.73363095 0.07696268]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09398045753713113\n",
      "--------------------\n",
      "total epoch time: -113.52608180046082\n",
      "epoch 13\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012493133544921875\n",
      "time per batch: 5.86775279045105\n",
      "tensor(428.7290, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001251697540283203\n",
      "time per batch: 5.819853067398071\n",
      "tensor(515.9017, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013589859008789062\n",
      "time per batch: 3.3185322284698486\n",
      "tensor(210.8866, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 385.1724548339844\n",
      "testing\n",
      "[[0.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.680e+02 2.900e+01]\n",
      " [0.000e+00 1.276e+03 1.190e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.84805195 0.11674793 0.20518633]\n",
      " [0.08027236 0.77529359 0.14496402]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.11671678424683589\n",
      "--------------------\n",
      "total epoch time: -113.76529479026794\n",
      "epoch 14\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012111663818359375\n",
      "time per batch: 5.794619083404541\n",
      "tensor(469.9680, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012373924255371094\n",
      "time per batch: 5.776652097702026\n",
      "tensor(451.3557, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001239776611328125\n",
      "time per batch: 3.32283616065979\n",
      "tensor(232.8217, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 384.715087890625\n",
      "testing\n",
      "[[  0.   0.   1.]\n",
      " [  0.  67. 130.]\n",
      " [  0. 467. 928.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.32522429 0.11375407 0.16541698]\n",
      " [0.66125309 0.88474275 0.75610608]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3071743510668426\n",
      "--------------------\n",
      "total epoch time: -113.05658197402954\n",
      "epoch 15\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001251697540283203\n",
      "time per batch: 5.95993185043335\n",
      "tensor(465.0542, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00019407272338867188\n",
      "time per batch: 5.793684005737305\n",
      "tensor(503.8742, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013208389282226562\n",
      "time per batch: 3.3434808254241943\n",
      "tensor(183.5056, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 384.1446838378906\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 3.000e+01 1.670e+02]\n",
      " [0.000e+00 1.590e+02 1.236e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.15202692 0.17737358 0.16161616]\n",
      " [0.88686994 0.8685792  0.87727787]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3462980099709952\n",
      "--------------------\n",
      "total epoch time: -113.68573999404907\n",
      "epoch 16\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001251697540283203\n",
      "time per batch: 5.7583699226379395\n",
      "tensor(439.2734, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001380443572998047\n",
      "time per batch: 5.788043975830078\n",
      "tensor(532.0347, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001437664031982422\n",
      "time per batch: 3.3468310832977295\n",
      "tensor(180.3141, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 383.8740539550781\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 3.000e+01 1.670e+02]\n",
      " [0.000e+00 1.520e+02 1.243e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.14479899 0.1833766  0.15298272]\n",
      " [0.8966281  0.86457509 0.87910631]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3440296758481698\n",
      "--------------------\n",
      "total epoch time: -112.6177167892456\n",
      "epoch 17\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001201629638671875\n",
      "time per batch: 5.752647161483765\n",
      "tensor(447.7891, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012373924255371094\n",
      "time per batch: 6.032990217208862\n",
      "tensor(522.8253, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012612342834472656\n",
      "time per batch: 3.3540661334991455\n",
      "tensor(180.1098, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 383.5747375488281\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 3.000e+01 1.670e+02]\n",
      " [0.000e+00 1.520e+02 1.243e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.15308458 0.19047619 0.16581836]\n",
      " [0.89522952 0.87284231 0.88347788]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3497654122748734\n",
      "--------------------\n",
      "total epoch time: -120.54055786132812\n",
      "epoch 18\n",
      "progress: 10.0\n",
      "0\n",
      "0.00013303756713867188\n",
      "time per batch: 5.7866737842559814\n",
      "tensor(425.6640, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013303756713867188\n",
      "time per batch: 5.788981676101685\n",
      "tensor(490.2740, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013399124145507812\n",
      "time per batch: 3.348059892654419\n",
      "tensor(233.5597, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 383.1658935546875\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 1.800e+01 1.790e+02]\n",
      " [0.000e+00 1.120e+02 1.283e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.09484834 0.13238418 0.10899466]\n",
      " [0.91248512 0.88094791 0.89625474]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.33508313592433114\n",
      "--------------------\n",
      "total epoch time: -112.75857424736023\n",
      "epoch 19\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011897087097167969\n",
      "time per batch: 5.786427021026611\n",
      "tensor(506.5905, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001647472381591797\n",
      "time per batch: 5.921589136123657\n",
      "tensor(458.6030, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012111663818359375\n",
      "time per batch: 3.3341031074523926\n",
      "tensor(183.2664, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 382.8199768066406\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 1.800e+01 1.790e+02]\n",
      " [0.000e+00 1.120e+02 1.283e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.07989777 0.12242424 0.09597609]\n",
      " [0.92074167 0.87762554 0.89854456]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.33150688310164356\n",
      "--------------------\n",
      "total epoch time: -113.72935914993286\n",
      "epoch 20\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001220703125\n",
      "time per batch: 6.079696893692017\n",
      "tensor(410.8860, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013375282287597656\n",
      "time per batch: 5.932872772216797\n",
      "tensor(525.0716, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012493133544921875\n",
      "time per batch: 3.332249164581299\n",
      "tensor(211.1322, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 382.36328125\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.500e+01 1.720e+02]\n",
      " [0.000e+00 1.320e+02 1.263e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.108285   0.14429321 0.12121748]\n",
      " [0.90285111 0.88338704 0.89275435]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3379906091327988\n",
      "--------------------\n",
      "total epoch time: -112.81809425354004\n",
      "epoch 21\n",
      "progress: 10.0\n",
      "0\n",
      "0.00013184547424316406\n",
      "time per batch: 5.76755690574646\n",
      "tensor(468.1788, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012373924255371094\n",
      "time per batch: 5.8417627811431885\n",
      "tensor(450.3152, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012302398681640625\n",
      "time per batch: 3.346498966217041\n",
      "tensor(227.9255, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 382.1397705078125\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.900e+01 1.680e+02]\n",
      " [0.000e+00 1.490e+02 1.246e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.1551169  0.15326322 0.15261408]\n",
      " [0.88828042 0.8836303  0.88575569]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.34612325758044665\n",
      "--------------------\n",
      "total epoch time: -113.17489790916443\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 10.0\n",
      "0\n",
      "0.0001232624053955078\n",
      "time per batch: 5.766570806503296\n",
      "tensor(519.6766, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013113021850585938\n",
      "time per batch: 5.800692081451416\n",
      "tensor(416.8517, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012183189392089844\n",
      "time per batch: 3.354806900024414\n",
      "tensor(209.0154, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 381.847900390625\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.500e+01 1.720e+02]\n",
      " [0.000e+00 1.320e+02 1.263e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.12261905 0.15346586 0.13598157]\n",
      " [0.9027639  0.87727548 0.88979355]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.34192504116954053\n",
      "--------------------\n",
      "total epoch time: -112.88307189941406\n",
      "epoch 23\n",
      "progress: 10.0\n",
      "0\n",
      "0.000125885009765625\n",
      "time per batch: 5.784952878952026\n",
      "tensor(517.9050, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001239776611328125\n",
      "time per batch: 5.809537172317505\n",
      "tensor(404.7404, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012493133544921875\n",
      "time per batch: 3.3256208896636963\n",
      "tensor(221.2065, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 381.2839660644531\n",
      "testing\n",
      "[[0.00e+00 0.00e+00 1.00e+00]\n",
      " [0.00e+00 1.80e+01 1.79e+02]\n",
      " [0.00e+00 1.15e+02 1.28e+03]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.0932612  0.14225816 0.11219317]\n",
      " [0.91337258 0.8717556  0.89201914]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.33473743904616\n",
      "--------------------\n",
      "total epoch time: -111.64317393302917\n",
      "epoch 24\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001251697540283203\n",
      "time per batch: 5.7588210105896\n",
      "tensor(541.7186, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012373924255371094\n",
      "time per batch: 5.810349941253662\n",
      "tensor(381.1986, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013399124145507812\n",
      "time per batch: 3.50168514251709\n",
      "tensor(220.0051, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 380.97412109375\n",
      "testing\n",
      "[[0.00e+00 0.00e+00 1.00e+00]\n",
      " [0.00e+00 1.80e+01 1.79e+02]\n",
      " [0.00e+00 1.15e+02 1.28e+03]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.08666383 0.11706349 0.09798358]\n",
      " [0.91787132 0.87333314 0.89483145]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.330938343965781\n",
      "--------------------\n",
      "total epoch time: -112.61533713340759\n",
      "epoch 25\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012421607971191406\n",
      "time per batch: 5.8023293018341064\n",
      "tensor(549.7752, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013685226440429688\n",
      "time per batch: 5.852281808853149\n",
      "tensor(383.5668, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001327991485595703\n",
      "time per batch: 3.3461098670959473\n",
      "tensor(208.7127, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 380.6849365234375\n",
      "testing\n",
      "[[0.00e+00 0.00e+00 1.00e+00]\n",
      " [0.00e+00 1.80e+01 1.79e+02]\n",
      " [0.00e+00 1.15e+02 1.28e+03]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.09362169 0.14135297 0.11165158]\n",
      " [0.91633101 0.87713535 0.89623191]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3359611632606499\n",
      "--------------------\n",
      "total epoch time: -112.56040382385254\n",
      "epoch 26\n",
      "progress: 10.0\n",
      "0\n",
      "0.00012087821960449219\n",
      "time per batch: 5.792948007583618\n",
      "tensor(483.2599, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001609325408935547\n",
      "time per batch: 5.810086965560913\n",
      "tensor(457.3505, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013184547424316406\n",
      "time per batch: 3.3264541625976562\n",
      "tensor(200.4136, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 380.34130859375\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.500e+01 1.720e+02]\n",
      " [0.000e+00 1.320e+02 1.263e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.1398226  0.16379715 0.14928586]\n",
      " [0.90328258 0.88264133 0.89268586]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3473239081357835\n",
      "--------------------\n",
      "total epoch time: -111.93874979019165\n",
      "epoch 27\n",
      "progress: 10.0\n",
      "0\n",
      "0.00011897087097167969\n",
      "time per batch: 5.775130987167358\n",
      "tensor(499.9742, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00015997886657714844\n",
      "time per batch: 5.810477256774902\n",
      "tensor(413.6180, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00013494491577148438\n",
      "time per batch: 3.323314905166626\n",
      "tensor(226.4257, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 380.0059509277344\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.500e+01 1.720e+02]\n",
      " [0.000e+00 1.320e+02 1.263e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.12929056 0.17777778 0.14804127]\n",
      " [0.9041523  0.86528132 0.88396842]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3440032294349207\n",
      "--------------------\n",
      "total epoch time: -111.7910590171814\n",
      "epoch 28\n",
      "progress: 10.0\n",
      "0\n",
      "0.0001227855682373047\n",
      "time per batch: 6.079081773757935\n",
      "tensor(390.3539, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.0001399517059326172\n",
      "time per batch: 5.805154085159302\n",
      "tensor(539.7726, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012087821960449219\n",
      "time per batch: 3.3280928134918213\n",
      "tensor(209.1861, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 379.7709045410156\n",
      "testing\n",
      "[[0.000e+00 0.000e+00 1.000e+00]\n",
      " [0.000e+00 2.500e+01 1.720e+02]\n",
      " [0.000e+00 1.320e+02 1.263e+03]\n",
      " [0.000e+00 0.000e+00 0.000e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.14733827 0.16656096 0.15466176]\n",
      " [0.89439857 0.87676389 0.8853667 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3466761523161998\n",
      "--------------------\n",
      "total epoch time: -112.65316867828369\n",
      "epoch 29\n",
      "progress: 10.0\n",
      "0\n",
      "0.00013303756713867188\n",
      "time per batch: 5.796473026275635\n",
      "tensor(412.3851, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00011801719665527344\n",
      "time per batch: 5.819869041442871\n",
      "tensor(497.5612, grad_fn=<MulBackward>)\n",
      "progress: 10.0\n",
      "0.00012183189392089844\n",
      "time per batch: 3.3653228282928467\n",
      "tensor(228.3264, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 379.4242248535156\n",
      "testing\n",
      "[[0.00e+00 0.00e+00 1.00e+00]\n",
      " [0.00e+00 1.80e+01 1.79e+02]\n",
      " [0.00e+00 1.15e+02 1.28e+03]\n",
      " [0.00e+00 0.00e+00 0.00e+00]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.09671905 0.14241546 0.11364945]\n",
      " [0.91363419 0.86583513 0.88886258]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.33417067716731697\n",
      "--------------------\n",
      "total epoch time: -112.57854175567627\n",
      "best_score: 0.3497654122748734\n",
      "\n",
      "I => recall: 0.0, precision: 0.0, , f1: 0.0\n",
      "\n",
      "B => recall: 0.15308457711442788, precision: 0.19047619047619047, , f1: 0.16581835666756442\n",
      "\n",
      "O => recall: 0.8952295180025711, precision: 0.8728423053198405, , f1: 0.8834778801570558\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 30\n",
    "time_list3 = []\n",
    "for IND in range(2):\n",
    "    #BS = 8\n",
    "    tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "    scheduler_n = 100002\n",
    "    word_length = 84\n",
    "    early_stop_n = 100003\n",
    "    max_size_char = [6]#[5, 10, 20]\n",
    "    nums_filter = [1]\n",
    "    use_BN = True\n",
    "    activation_func = True\n",
    "    input_channel = 1\n",
    "    kernel_sizes = [3]\n",
    "    same_padding = True\n",
    "    num_char_encoding_size = 135\n",
    "    output_size = 64\n",
    "    size_of_embedding = 300\n",
    "    pos_size = len(POSMAP)\n",
    "    FCN = False\n",
    "    grucrf_dropout = [0, 0.15, 0.30, 0.45, 0.60]\n",
    "    total_search = len(max_size_char)*len(grucrf_dropout)*2\n",
    "    for size_char in max_size_char:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "\n",
    "#         data_tr = MyDataloader('../Data/clean84withpos_ne_tr'+ str(IND) +'.txt', '../Data/label84withpos_ne_tr'+ str(IND) +'.txt',\\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr'+ str(IND) +'.txt',POSMAP)\n",
    "#         data_te = MyDataloader('../Data/clean84withpos_ne_te'+ str(IND) +'.txt', '../Data/label84withpos_ne_te'+ str(IND) +'.txt', \\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te'+ str(IND) +'.txt',POSMAP)\n",
    "\n",
    "#         train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "#         test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        for i in grucrf_dropout:\n",
    "            grucrf_hidden_size = 128\n",
    "            LR = 10**(-4)\n",
    "            print(f'lstmcrf_dropout = DO_FCN_LSTMCRF: {i}')\n",
    "            print(f'lstmcrf_hidden_size: {grucrf_hidden_size}, LR: {LR}')\n",
    "\n",
    "#             NER = CNN_GRU_CRF(BS, size_char, nums_filter, use_BN, activation_func, \\\n",
    "#                               input_channel, kernel_sizes, same_padding, num_char_encoding_size, \\\n",
    "#                               output_size, size_of_embedding, word_length, grucrf_hidden_size, i, \\\n",
    "#                               True, tags, i, pos_size, FCN)\n",
    "            NER = CNN_GRU_CRF(BS, size_char, nums_filter, use_BN, activation_func, \\\n",
    "                              input_channel, kernel_sizes, same_padding, num_char_encoding_size, \\\n",
    "                              output_size, size_of_embedding, word_length, grucrf_hidden_size, 0, \\\n",
    "                              True, tags, 0, pos_size, FCN, 0)\n",
    "\n",
    "            optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "            my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "            print(device)\n",
    "            NER.to(device)\n",
    "            best_score = 0\n",
    "            best_mat = np.zeros((len(tags)-1,3))\n",
    "            cnt_idle = 0\n",
    "            for epoch in range(num_epoch):\n",
    "                ttt = time()\n",
    "                print(f'epoch {epoch}')\n",
    "                all_loss = []\n",
    "                for ind, batch_x in enumerate(train_loader):\n",
    "                    ttt2 = time()\n",
    "                    print(f'progress: {(100*(grucrf_dropout.index(i)+1)*(max_size_char.index(size_char)+1)*(IND+1))/total_search}')\n",
    "                    if ind%5 == 0:\n",
    "                        print(ind)\n",
    "                    t2 = time()\n",
    "                    NER = NER.train()\n",
    "                    print(time() - t2)\n",
    "                    NER.zero_grad()\n",
    "                    t1 = time()\n",
    "                    loss = NER(batch_x)\n",
    "                    loss = loss*(-1)\n",
    "                    print(f'time per batch: {time() - t1}')\n",
    "                    print(loss)\n",
    "                    all_loss.append(loss)\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "                    optimizer.step()\n",
    "                    time_list3.append(time()-ttt2)\n",
    "                total_loss = sum(all_loss)/(ind + 1)\n",
    "                my_scheduler.step(total_loss)\n",
    "                \n",
    "                print(f'total loss of epoch: {total_loss.item()}')\n",
    "                print('testing')\n",
    "                per_mat = np.zeros((len(tags), 3))\n",
    "                cnt_mat = np.zeros((len(tags), 3))\n",
    "                for ind, batch_test in enumerate(test_loader):\n",
    "                    NER = NER.eval()\n",
    "                    output = NER.predict(batch_test)\n",
    "                    a, b = eval_score(tags, output, batch_test[2])\n",
    "                    per_mat += a\n",
    "                    cnt_mat += b\n",
    "                per_mat = per_mat/(ind+1)\n",
    "                per_mat = per_mat[:len(tags),:]\n",
    "                cnt_mat = cnt_mat[:len(tags),:]\n",
    "                print(cnt_mat)\n",
    "                print(per_mat)\n",
    "                score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "                if best_score < score:\n",
    "                    best_mat=per_mat\n",
    "                    best_score = score\n",
    "                    cnt_idle = 0\n",
    "                else:\n",
    "                    cnt_idle += 1\n",
    "                print(f'overall score: {score}')\n",
    "                print('--------------------')\n",
    "                if early_stop_n == cnt_idle:\n",
    "                    break\n",
    "                print(f'total epoch time: {ttt-time()}')\n",
    "            print(f'best_score: {best_score}\\n')\n",
    "            print(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "            print(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "            print(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "            print(f'----------------------------------\\n')\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(time_list1))\n",
    "print(len(time_list2))\n",
    "print(len(time_list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/abc/Downloads/min/Codes/LSTM-CRF-NER'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_exper_BS' + str(BS) +'.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('exper1, exper2, exper3\\n')\n",
    "    for i in range(len(time_list1)):\n",
    "        f.write(f'{time_list1[i]}, {time_list2[i]}, {time_list3[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter ur logname: optuna_test\n"
     ]
    }
   ],
   "source": [
    "BS = 2\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 1003\n",
    "word_length = 84\n",
    "early_stop_n = 10005\n",
    "max_size_char = 6\n",
    "same_padding = True\n",
    "use_BN = True\n",
    "activation_func = True\n",
    "input_channel = 1\n",
    "nums_filter = [1]\n",
    "output_size = 64\n",
    "size_of_embedding = 300\n",
    "pos_size = len(POSMAP)\n",
    "num_char_encoding_size = 135\n",
    "FCN = False\n",
    "file_name = input('enter ur logname: ')\n",
    "num_epoch = 30\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = MyDataloader('../clean84withpos.txt', '../label84withpos.txt', RULEs, \\\n",
    "                           word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "                           '../fasttext.th.vec', 300, device, '../pos_tag84withpos.txt',POSMAP)\n",
    "tr, te = get_indices_random_val_test_split(len(data), 1, 0.00015, True)\n",
    "\n",
    "def objective(trial):\n",
    "    kernel_sizes = [trial.suggest_categorical('kernel_sizes', [3,5])]\n",
    "    gru_fcn_dropout = trial.suggest_uniform('gru_fcn_dropout', 0, 0.7)\n",
    "    gru_dropout = trial.suggest_uniform('gru_dropout', 0, 0.7)\n",
    "    gru_out_dropout = trial.suggest_uniform('gru_out_dropout', 0, 0.7)\n",
    "    LR = trial.suggest_uniform('LR', 5, 10)*10**(-5)\n",
    "    grucrf_hidden_size = trial.suggest_categorical('grucrf_hidden_size', [64, 128])\n",
    "    w_decay = trial.suggest_categorical('w_decay', [-3,-4,-5])\n",
    "    \n",
    "    train_loader = DataLoader(data, batch_size=BS, sampler=tr)\n",
    "    test_loader = DataLoader(data, batch_size=BS, sampler=te)\n",
    "    \n",
    "    with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "        f.write(f'kernel_sizes: {kernel_sizes}, gru_fcn_dropout: {gru_fcn_dropout}\\n')\n",
    "        f.write(f'gru_dropout: {gru_dropout}, gru_out_dropout: {gru_out_dropout}\\n')\n",
    "        f.write(f'LR: {LR}, grucrf_hidden_size: {grucrf_hidden_size}\\n')\n",
    "        f.write(f'w_decay: {w_decay}\\n')\n",
    "\n",
    "    NER = CNN_GRU_char_pos(BS, max_size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "                           kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, \\\n",
    "                           grucrf_hidden_size, gru_dropout, True, tags, gru_fcn_dropout, pos_size, FCN, \\\n",
    "                           gru_out_dropout)\n",
    "    optimizer = optim.Adam(NER.parameters(), lr=LR, eps=1e-08, weight_decay=10**w_decay,amsgrad=True)\n",
    "    my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', verbose=True)\n",
    "    \n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        ttt = time()\n",
    "        print(f'epoch {epoch}')\n",
    "        all_loss = []\n",
    "        for ind, batch_x in enumerate(train_loader):\n",
    "            if ind%5 == 0:\n",
    "                print(ind)\n",
    "            t2 = time()\n",
    "            NER = NER.train()\n",
    "            print(time() - t2)\n",
    "            NER.zero_grad()\n",
    "            t1 = time()\n",
    "            loss = NER(batch_x)\n",
    "            loss = loss*(-1)\n",
    "            print(f'time per batch: {time() - t1}')\n",
    "            print(loss)\n",
    "            all_loss.append(loss)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "            optimizer.step()\n",
    "        total_loss = sum(all_loss)/(ind + 1)\n",
    "        my_scheduler.step(total_loss)\n",
    "        print(f'total loss of epoch: {total_loss.item()}')\n",
    "        print('testing')\n",
    "        per_mat = np.zeros((len(tags), 3))\n",
    "        cnt_mat = np.zeros((len(tags), 3))\n",
    "        for ind, batch_test in enumerate(test_loader):\n",
    "            NER = NER.eval()\n",
    "            output = NER.predict(batch_test)\n",
    "            a, b = eval_score(tags, output, batch_test[2])\n",
    "            per_mat += a\n",
    "            cnt_mat += b\n",
    "        per_mat = per_mat/(ind+1)\n",
    "        per_mat = per_mat[:len(tags),:]\n",
    "        cnt_mat = cnt_mat[:len(tags),:]\n",
    "        print(cnt_mat)\n",
    "        print(per_mat)\n",
    "        score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "\n",
    "        with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "            f.write(f'epoch: {epoch}, score: {score}\\n')\n",
    "        \n",
    "        if score - best_score >= 0.005:\n",
    "            best_mat=per_mat\n",
    "            best_score = score\n",
    "            cnt_idle = 0\n",
    "        else:\n",
    "            cnt_idle += 1\n",
    "        print(f'overall score: {score}')\n",
    "        print('--------------------')\n",
    "        if early_stop_n == cnt_idle:\n",
    "            break\n",
    "        print(f'total epoch time: {ttt-time()}')\n",
    "    with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "        f.write(f'cnt_mat\\n')\n",
    "        f.write(f'I => : {cnt_mat[0,0]}, : {cnt_mat[0,1]}, : {cnt_mat[0,2]}\\n')\n",
    "        f.write(f'B => : {cnt_mat[1,0]}, : {cnt_mat[1,1]}, : {cnt_mat[1,2]}\\n')\n",
    "        f.write(f'O => : {cnt_mat[2,0]}, : {cnt_mat[2,1]}, : {cnt_mat[2,2]}\\n')\n",
    "        f.write(f'best_score: {best_score}\\n')\n",
    "        f.write(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "        f.write(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "        f.write(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "        f.write(f'----------------------------------\\n')\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0\n",
      "0.00011491775512695312\n",
      "time per batch: 2.3418049812316895\n",
      "tensor(34.8441, grad_fn=<MulBackward>)\n",
      "0.00012922286987304688\n",
      "time per batch: 2.1915690898895264\n",
      "tensor(80.6080, grad_fn=<MulBackward>)\n",
      "0.0001728534698486328\n",
      "time per batch: 2.0867130756378174\n",
      "tensor(33.8390, grad_fn=<MulBackward>)\n",
      "0.00016689300537109375\n",
      "time per batch: 2.2237839698791504\n",
      "tensor(50.1646, grad_fn=<MulBackward>)\n",
      "0.00018095970153808594\n",
      "time per batch: 2.2291951179504395\n",
      "tensor(26.9115, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.000164031982421875\n",
      "time per batch: 2.351447820663452\n",
      "tensor(11.8826, grad_fn=<MulBackward>)\n",
      "0.00019788742065429688\n",
      "time per batch: 2.503523826599121\n",
      "tensor(17.7553, grad_fn=<MulBackward>)\n",
      "0.00016617774963378906\n",
      "time per batch: 2.5306408405303955\n",
      "tensor(24.1425, grad_fn=<MulBackward>)\n",
      "0.0001227855682373047\n",
      "time per batch: 4.957162857055664\n",
      "tensor(20.1968, grad_fn=<MulBackward>)\n",
      "0.000164031982421875\n",
      "time per batch: 2.9302730560302734\n",
      "tensor(18.5895, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00016498565673828125\n",
      "time per batch: 2.7285568714141846\n",
      "tensor(15.4828, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 30.401521682739258\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 20.   7.   1.]\n",
      " [222.  34.   7.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.29646465 0.17424242 0.18519814]\n",
      " [0.06759907 0.34545455 0.09640582]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09386798386798385\n",
      "--------------------\n",
      "total epoch time: -111.95125222206116\n",
      "epoch 1\n",
      "0\n",
      "0.00020194053649902344\n",
      "time per batch: 2.2625882625579834\n",
      "tensor(46.0103, grad_fn=<MulBackward>)\n",
      "0.00026106834411621094\n",
      "time per batch: 2.1433489322662354\n",
      "tensor(25.0910, grad_fn=<MulBackward>)\n",
      "0.0001659393310546875\n",
      "time per batch: 2.178135871887207\n",
      "tensor(25.9550, grad_fn=<MulBackward>)\n",
      "0.00016117095947265625\n",
      "time per batch: 2.201129913330078\n",
      "tensor(14.0956, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 2.1401519775390625\n",
      "tensor(18.9372, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.000171661376953125\n",
      "time per batch: 2.3378710746765137\n",
      "tensor(35.7406, grad_fn=<MulBackward>)\n",
      "0.00013208389282226562\n",
      "time per batch: 2.0017247200012207\n",
      "tensor(29.7711, grad_fn=<MulBackward>)\n",
      "0.00016689300537109375\n",
      "time per batch: 2.184168815612793\n",
      "tensor(60.1810, grad_fn=<MulBackward>)\n",
      "0.00016689300537109375\n",
      "time per batch: 2.337913751602173\n",
      "tensor(11.6748, grad_fn=<MulBackward>)\n",
      "0.00019097328186035156\n",
      "time per batch: 2.1117868423461914\n",
      "tensor(26.8473, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00017213821411132812\n",
      "time per batch: 1.9966328144073486\n",
      "tensor(9.0990, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 27.582075119018555\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 20.   7.   1.]\n",
      " [222.  34.   7.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.27954545 0.17424242 0.19747475]\n",
      " [0.06591557 0.34545455 0.09360639]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.09702704702704702\n",
      "--------------------\n",
      "total epoch time: -112.9610550403595\n",
      "epoch 2\n",
      "0\n",
      "0.0002779960632324219\n",
      "time per batch: 2.343740940093994\n",
      "tensor(23.8479, grad_fn=<MulBackward>)\n",
      "0.00011420249938964844\n",
      "time per batch: 2.163196086883545\n",
      "tensor(50.5220, grad_fn=<MulBackward>)\n",
      "0.00011277198791503906\n",
      "time per batch: 1.8329505920410156\n",
      "tensor(62.4946, grad_fn=<MulBackward>)\n",
      "0.0001709461212158203\n",
      "time per batch: 1.8018162250518799\n",
      "tensor(29.3386, grad_fn=<MulBackward>)\n",
      "0.0001671314239501953\n",
      "time per batch: 1.822556972503662\n",
      "tensor(23.5536, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001690387725830078\n",
      "time per batch: 1.8279271125793457\n",
      "tensor(12.6930, grad_fn=<MulBackward>)\n",
      "0.00011301040649414062\n",
      "time per batch: 1.8441338539123535\n",
      "tensor(33.6461, grad_fn=<MulBackward>)\n",
      "0.0001621246337890625\n",
      "time per batch: 1.9025299549102783\n",
      "tensor(22.2344, grad_fn=<MulBackward>)\n",
      "0.0001678466796875\n",
      "time per batch: 1.8807032108306885\n",
      "tensor(13.9530, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 1.860199213027954\n",
      "tensor(13.5434, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00016164779663085938\n",
      "time per batch: 2.0921928882598877\n",
      "tensor(13.2676, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 27.190399169921875\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 12.   6.  10.]\n",
      " [190.  25.  48.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.33402204 0.22727273 0.22783883]\n",
      " [0.30139975 0.85519481 0.37992341]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.20258741258741256\n",
      "--------------------\n",
      "total epoch time: -103.94558000564575\n",
      "epoch 3\n",
      "0\n",
      "0.0001709461212158203\n",
      "time per batch: 2.5831098556518555\n",
      "tensor(16.5752, grad_fn=<MulBackward>)\n",
      "0.0001621246337890625\n",
      "time per batch: 2.958146095275879\n",
      "tensor(24.8443, grad_fn=<MulBackward>)\n",
      "0.00016999244689941406\n",
      "time per batch: 2.1773977279663086\n",
      "tensor(16.5811, grad_fn=<MulBackward>)\n",
      "0.00011301040649414062\n",
      "time per batch: 2.5468506813049316\n",
      "tensor(34.7361, grad_fn=<MulBackward>)\n",
      "0.0001888275146484375\n",
      "time per batch: 2.406836986541748\n",
      "tensor(54.9932, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00017118453979492188\n",
      "time per batch: 1.7938427925109863\n",
      "tensor(20.8996, grad_fn=<MulBackward>)\n",
      "0.0001709461212158203\n",
      "time per batch: 1.7889330387115479\n",
      "tensor(30.4279, grad_fn=<MulBackward>)\n",
      "0.00018525123596191406\n",
      "time per batch: 1.9602317810058594\n",
      "tensor(13.5376, grad_fn=<MulBackward>)\n",
      "0.00011301040649414062\n",
      "time per batch: 2.216715097427368\n",
      "tensor(21.8905, grad_fn=<MulBackward>)\n",
      "0.00011420249938964844\n",
      "time per batch: 2.0527172088623047\n",
      "tensor(23.5671, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00015807151794433594\n",
      "time per batch: 1.8578391075134277\n",
      "tensor(35.3546, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 26.67339324951172\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  22. 241.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.20606061 0.18181818 0.17424242]\n",
      " [0.86968395 0.91839953 0.88783452]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35402564911567197\n",
      "--------------------\n",
      "total epoch time: -112.19757509231567\n",
      "epoch 4\n",
      "0\n",
      "0.00021505355834960938\n",
      "time per batch: 2.2920618057250977\n",
      "tensor(13.6452, grad_fn=<MulBackward>)\n",
      "0.00015616416931152344\n",
      "time per batch: 2.7984719276428223\n",
      "tensor(18.4324, grad_fn=<MulBackward>)\n",
      "0.00016808509826660156\n",
      "time per batch: 2.1192867755889893\n",
      "tensor(50.8677, grad_fn=<MulBackward>)\n",
      "0.00020813941955566406\n",
      "time per batch: 2.7438597679138184\n",
      "tensor(16.9936, grad_fn=<MulBackward>)\n",
      "0.0002760887145996094\n",
      "time per batch: 3.2684011459350586\n",
      "tensor(34.2499, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00016117095947265625\n",
      "time per batch: 2.065519094467163\n",
      "tensor(33.9361, grad_fn=<MulBackward>)\n",
      "0.00016999244689941406\n",
      "time per batch: 1.9978761672973633\n",
      "tensor(26.9073, grad_fn=<MulBackward>)\n",
      "0.00011420249938964844\n",
      "time per batch: 2.9082260131835938\n",
      "tensor(19.0221, grad_fn=<MulBackward>)\n",
      "0.00016927719116210938\n",
      "time per batch: 2.647486925125122\n",
      "tensor(12.1798, grad_fn=<MulBackward>)\n",
      "0.00018525123596191406\n",
      "time per batch: 2.180769205093384\n",
      "tensor(59.2363, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001709461212158203\n",
      "time per batch: 1.8039178848266602\n",
      "tensor(4.8328, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 26.391202926635742\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  20. 243.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.19242424 0.21212121 0.20021645]\n",
      " [0.89768684 0.89556644 0.89513857]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3651183410336675\n",
      "--------------------\n",
      "total epoch time: -120.26070189476013\n",
      "epoch 5\n",
      "0\n",
      "0.00019598007202148438\n",
      "time per batch: 2.317373037338257\n",
      "tensor(19.1985, grad_fn=<MulBackward>)\n",
      "0.00011706352233886719\n",
      "time per batch: 2.548859119415283\n",
      "tensor(17.9738, grad_fn=<MulBackward>)\n",
      "0.00018715858459472656\n",
      "time per batch: 1.8446531295776367\n",
      "tensor(22.2090, grad_fn=<MulBackward>)\n",
      "0.00016999244689941406\n",
      "time per batch: 1.8168230056762695\n",
      "tensor(13.3547, grad_fn=<MulBackward>)\n",
      "0.00011420249938964844\n",
      "time per batch: 2.890026092529297\n",
      "tensor(26.4240, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00015878677368164062\n",
      "time per batch: 2.0476338863372803\n",
      "tensor(59.4476, grad_fn=<MulBackward>)\n",
      "0.00016379356384277344\n",
      "time per batch: 2.0149500370025635\n",
      "tensor(49.2576, grad_fn=<MulBackward>)\n",
      "0.00011610984802246094\n",
      "time per batch: 2.024674654006958\n",
      "tensor(19.2857, grad_fn=<MulBackward>)\n",
      "0.00011992454528808594\n",
      "time per batch: 1.9355080127716064\n",
      "tensor(21.9928, grad_fn=<MulBackward>)\n",
      "0.00016379356384277344\n",
      "time per batch: 2.372882843017578\n",
      "tensor(27.6827, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00016999244689941406\n",
      "time per batch: 2.1955089569091797\n",
      "tensor(12.7666, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 26.326627731323242\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.18344156 0.24242424 0.19393939]\n",
      " [0.89671245 0.91437867 0.9028286 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3655893303134703\n",
      "--------------------\n",
      "total epoch time: -117.04032588005066\n",
      "epoch 6\n",
      "0\n",
      "0.00012302398681640625\n",
      "time per batch: 2.091367721557617\n",
      "tensor(17.8485, grad_fn=<MulBackward>)\n",
      "0.00011610984802246094\n",
      "time per batch: 2.870063066482544\n",
      "tensor(19.7974, grad_fn=<MulBackward>)\n",
      "0.00011873245239257812\n",
      "time per batch: 2.728040933609009\n",
      "tensor(20.3193, grad_fn=<MulBackward>)\n",
      "0.00012111663818359375\n",
      "time per batch: 2.1087701320648193\n",
      "tensor(12.2146, grad_fn=<MulBackward>)\n",
      "0.00014901161193847656\n",
      "time per batch: 2.345688819885254\n",
      "tensor(20.5372, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001671314239501953\n",
      "time per batch: 2.053234100341797\n",
      "tensor(23.5011, grad_fn=<MulBackward>)\n",
      "0.00018906593322753906\n",
      "time per batch: 2.489654064178467\n",
      "tensor(18.0393, grad_fn=<MulBackward>)\n",
      "0.00011110305786132812\n",
      "time per batch: 1.9253439903259277\n",
      "tensor(46.9522, grad_fn=<MulBackward>)\n",
      "0.00011610984802246094\n",
      "time per batch: 3.149541139602661\n",
      "tensor(61.3384, grad_fn=<MulBackward>)\n",
      "0.00012803077697753906\n",
      "time per batch: 2.8026299476623535\n",
      "tensor(26.0382, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001537799835205078\n",
      "time per batch: 2.6750168800354004\n",
      "tensor(20.9073, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 26.135780334472656\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.20833333 0.25       0.20454545]\n",
      " [0.86835505 0.86763595 0.86591644]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3568206315708688\n",
      "--------------------\n",
      "total epoch time: -125.21857118606567\n",
      "epoch 7\n",
      "0\n",
      "0.00016999244689941406\n",
      "time per batch: 1.9438049793243408\n",
      "tensor(25.1358, grad_fn=<MulBackward>)\n",
      "0.00017595291137695312\n",
      "time per batch: 1.8292453289031982\n",
      "tensor(21.6969, grad_fn=<MulBackward>)\n",
      "0.00012183189392089844\n",
      "time per batch: 1.9973959922790527\n",
      "tensor(42.1981, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 1.8681368827819824\n",
      "tensor(16.6855, grad_fn=<MulBackward>)\n",
      "0.00016307830810546875\n",
      "time per batch: 1.8730852603912354\n",
      "tensor(23.1503, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0002460479736328125\n",
      "time per batch: 1.9665398597717285\n",
      "tensor(13.3008, grad_fn=<MulBackward>)\n",
      "0.0001380443572998047\n",
      "time per batch: 2.855175256729126\n",
      "tensor(26.5808, grad_fn=<MulBackward>)\n",
      "0.00011396408081054688\n",
      "time per batch: 2.2933881282806396\n",
      "tensor(68.3181, grad_fn=<MulBackward>)\n",
      "0.00017189979553222656\n",
      "time per batch: 2.222656011581421\n",
      "tensor(18.9979, grad_fn=<MulBackward>)\n",
      "0.00011396408081054688\n",
      "time per batch: 2.208818197250366\n",
      "tensor(21.0075, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00015616416931152344\n",
      "time per batch: 1.747661828994751\n",
      "tensor(8.8478, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.992687225341797\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.2478355  0.25757576 0.23405483]\n",
      " [0.88721731 0.91334918 0.89609846]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3767177645093474\n",
      "--------------------\n",
      "total epoch time: -108.79737687110901\n",
      "epoch 8\n",
      "0\n",
      "0.0002422332763671875\n",
      "time per batch: 2.3495938777923584\n",
      "tensor(15.6150, grad_fn=<MulBackward>)\n",
      "0.00013113021850585938\n",
      "time per batch: 2.0452842712402344\n",
      "tensor(18.2544, grad_fn=<MulBackward>)\n",
      "0.00016736984252929688\n",
      "time per batch: 1.8679049015045166\n",
      "tensor(17.9581, grad_fn=<MulBackward>)\n",
      "0.00017690658569335938\n",
      "time per batch: 1.8742542266845703\n",
      "tensor(16.1162, grad_fn=<MulBackward>)\n",
      "0.00011396408081054688\n",
      "time per batch: 2.7699460983276367\n",
      "tensor(56.3766, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00016117095947265625\n",
      "time per batch: 1.8614740371704102\n",
      "tensor(17.6909, grad_fn=<MulBackward>)\n",
      "0.00011277198791503906\n",
      "time per batch: 2.2264420986175537\n",
      "tensor(29.8789, grad_fn=<MulBackward>)\n",
      "0.00011897087097167969\n",
      "time per batch: 1.9166259765625\n",
      "tensor(26.0808, grad_fn=<MulBackward>)\n",
      "0.00011897087097167969\n",
      "time per batch: 2.177495002746582\n",
      "tensor(41.3134, grad_fn=<MulBackward>)\n",
      "0.00016880035400390625\n",
      "time per batch: 2.1132640838623047\n",
      "tensor(34.0481, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00016689300537109375\n",
      "time per batch: 2.3330917358398438\n",
      "tensor(12.6511, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.998493194580078\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.27121212 0.24242424 0.23333333]\n",
      " [0.82500799 0.85726109 0.82833985]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3538910600492921\n",
      "--------------------\n",
      "total epoch time: -116.54733490943909\n",
      "epoch 9\n",
      "0\n",
      "0.00015687942504882812\n",
      "time per batch: 2.007650136947632\n",
      "tensor(55.2036, grad_fn=<MulBackward>)\n",
      "0.00023293495178222656\n",
      "time per batch: 2.2219841480255127\n",
      "tensor(33.1758, grad_fn=<MulBackward>)\n",
      "0.00016307830810546875\n",
      "time per batch: 2.587847948074341\n",
      "tensor(20.4704, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 2.2919540405273438\n",
      "tensor(17.7307, grad_fn=<MulBackward>)\n",
      "0.00011873245239257812\n",
      "time per batch: 2.4054131507873535\n",
      "tensor(26.9647, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001709461212158203\n",
      "time per batch: 2.596266984939575\n",
      "tensor(14.3594, grad_fn=<MulBackward>)\n",
      "0.00011992454528808594\n",
      "time per batch: 2.2901389598846436\n",
      "tensor(32.5058, grad_fn=<MulBackward>)\n",
      "0.0001251697540283203\n",
      "time per batch: 2.2996859550476074\n",
      "tensor(20.0323, grad_fn=<MulBackward>)\n",
      "0.00011301040649414062\n",
      "time per batch: 2.3172221183776855\n",
      "tensor(11.2071, grad_fn=<MulBackward>)\n",
      "0.00026917457580566406\n",
      "time per batch: 2.356051206588745\n",
      "tensor(18.8602, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00010991096496582031\n",
      "time per batch: 2.433833122253418\n",
      "tensor(34.4997, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.90996551513672\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.28636364 0.25757576 0.24458874]\n",
      " [0.86038363 0.87875714 0.8664449 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3703445479783815\n",
      "--------------------\n",
      "total epoch time: -142.3913140296936\n",
      "epoch 10\n",
      "0\n",
      "0.0002598762512207031\n",
      "time per batch: 1.871377944946289\n",
      "tensor(32.0448, grad_fn=<MulBackward>)\n",
      "0.0001227855682373047\n",
      "time per batch: 1.8431870937347412\n",
      "tensor(21.1295, grad_fn=<MulBackward>)\n",
      "0.0001220703125\n",
      "time per batch: 1.8453559875488281\n",
      "tensor(14.4795, grad_fn=<MulBackward>)\n",
      "0.00012111663818359375\n",
      "time per batch: 2.0543460845947266\n",
      "tensor(29.6818, grad_fn=<MulBackward>)\n",
      "0.00021886825561523438\n",
      "time per batch: 2.2312002182006836\n",
      "tensor(61.9354, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001800060272216797\n",
      "time per batch: 2.1228270530700684\n",
      "tensor(13.5257, grad_fn=<MulBackward>)\n",
      "0.00011372566223144531\n",
      "time per batch: 2.0411579608917236\n",
      "tensor(18.2465, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 1.962265968322754\n",
      "tensor(20.5276, grad_fn=<MulBackward>)\n",
      "0.00016307830810546875\n",
      "time per batch: 2.140740156173706\n",
      "tensor(25.2230, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 2.2282729148864746\n",
      "tensor(39.9510, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00015282630920410156\n",
      "time per batch: 1.9155871868133545\n",
      "tensor(7.7834, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.8662052154541\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.23268398 0.27272727 0.22929293]\n",
      " [0.8314748  0.86253104 0.8322327 ]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35384187626598856\n",
      "--------------------\n",
      "total epoch time: -112.26399111747742\n",
      "epoch 11\n",
      "0\n",
      "0.00020694732666015625\n",
      "time per batch: 2.841010093688965\n",
      "tensor(23.9131, grad_fn=<MulBackward>)\n",
      "0.00018286705017089844\n",
      "time per batch: 2.2410051822662354\n",
      "tensor(29.7381, grad_fn=<MulBackward>)\n",
      "0.0001571178436279297\n",
      "time per batch: 2.5738439559936523\n",
      "tensor(24.3436, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 1.9061710834503174\n",
      "tensor(13.2006, grad_fn=<MulBackward>)\n",
      "0.00016808509826660156\n",
      "time per batch: 2.1986610889434814\n",
      "tensor(59.8987, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001678466796875\n",
      "time per batch: 2.3275580406188965\n",
      "tensor(13.6305, grad_fn=<MulBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011992454528808594\n",
      "time per batch: 1.9130549430847168\n",
      "tensor(20.9848, grad_fn=<MulBackward>)\n",
      "0.00017595291137695312\n",
      "time per batch: 2.2734529972076416\n",
      "tensor(14.5507, grad_fn=<MulBackward>)\n",
      "0.0001709461212158203\n",
      "time per batch: 2.3001480102539062\n",
      "tensor(46.7139, grad_fn=<MulBackward>)\n",
      "0.00016999244689941406\n",
      "time per batch: 2.0149738788604736\n",
      "tensor(32.0082, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001690387725830078\n",
      "time per batch: 1.7409262657165527\n",
      "tensor(4.3721, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.759477615356445\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.23863636 0.24242424 0.22164502]\n",
      " [0.90598753 0.90408587 0.90344813]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.37503105010651\n",
      "--------------------\n",
      "total epoch time: -114.85900282859802\n",
      "epoch 12\n",
      "0\n",
      "0.0003199577331542969\n",
      "time per batch: 1.8766100406646729\n",
      "tensor(13.1292, grad_fn=<MulBackward>)\n",
      "0.00018095970153808594\n",
      "time per batch: 1.9215056896209717\n",
      "tensor(19.1912, grad_fn=<MulBackward>)\n",
      "0.0002238750457763672\n",
      "time per batch: 2.4046430587768555\n",
      "tensor(18.8208, grad_fn=<MulBackward>)\n",
      "0.00016379356384277344\n",
      "time per batch: 4.265607118606567\n",
      "tensor(15.4766, grad_fn=<MulBackward>)\n",
      "0.00012183189392089844\n",
      "time per batch: 1.873499870300293\n",
      "tensor(55.0106, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00017690658569335938\n",
      "time per batch: 2.358811855316162\n",
      "tensor(25.5627, grad_fn=<MulBackward>)\n",
      "0.00011992454528808594\n",
      "time per batch: 1.9140605926513672\n",
      "tensor(33.0826, grad_fn=<MulBackward>)\n",
      "0.00017380714416503906\n",
      "time per batch: 1.9620389938354492\n",
      "tensor(39.3478, grad_fn=<MulBackward>)\n",
      "0.0001709461212158203\n",
      "time per batch: 1.914504051208496\n",
      "tensor(25.0107, grad_fn=<MulBackward>)\n",
      "0.00016999244689941406\n",
      "time per batch: 862.014671087265\n",
      "tensor(28.5636, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0002231597900390625\n",
      "time per batch: 2.801568031311035\n",
      "tensor(9.7605, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.72331428527832\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  18. 245.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.16818182 0.22727273 0.18354978]\n",
      " [0.86693165 0.89446008 0.87490195]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.35281724323306474\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-06 22:39:52,879] Finished trial#106 resulted in value: 0.3767177645093474. Current best value is 0.3767177645093474 with parameters: {'LR': 5.826992948964408, 'gru_dropout': 0.6023800703615053, 'gru_fcn_dropout': 0.026658703460356214, 'gru_out_dropout': 0.25442982964747174, 'grucrf_hidden_size': 64, 'kernel_sizes': 5, 'w_decay': -3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0\n",
      "0.00019407272338867188\n",
      "time per batch: 6.435258865356445\n",
      "tensor(10.3699, grad_fn=<MulBackward>)\n",
      "0.000125885009765625\n",
      "time per batch: 3.1884660720825195\n",
      "tensor(20.6080, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 4.82292103767395\n",
      "tensor(16.3300, grad_fn=<MulBackward>)\n",
      "0.00011968612670898438\n",
      "time per batch: 3.0032050609588623\n",
      "tensor(17.8857, grad_fn=<MulBackward>)\n",
      "0.00012183189392089844\n",
      "time per batch: 3.218485116958618\n",
      "tensor(64.2073, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001678466796875\n",
      "time per batch: 3.7899110317230225\n",
      "tensor(25.4161, grad_fn=<MulBackward>)\n",
      "0.00012421607971191406\n",
      "time per batch: 4.840949058532715\n",
      "tensor(59.6643, grad_fn=<MulBackward>)\n",
      "0.0001201629638671875\n",
      "time per batch: 4.619460105895996\n",
      "tensor(18.3695, grad_fn=<MulBackward>)\n",
      "0.00011897087097167969\n",
      "time per batch: 5.243571043014526\n",
      "tensor(19.8214, grad_fn=<MulBackward>)\n",
      "0.0004420280456542969\n",
      "time per batch: 6.41439414024353\n",
      "tensor(19.2011, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00015807151794433594\n",
      "time per batch: 5.9020280838012695\n",
      "tensor(14.1987, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 26.006547927856445\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 13.   2.  13.]\n",
      " [201.   7.  55.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.03636364 0.09090909 0.05194805]\n",
      " [0.44133847 0.78838384 0.44008721]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.16401175364023662\n",
      "--------------------\n",
      "total epoch time: -236.79990577697754\n",
      "epoch 1\n",
      "0\n",
      "0.0002090930938720703\n",
      "time per batch: 3.5337631702423096\n",
      "tensor(9.5474, grad_fn=<MulBackward>)\n",
      "0.00011873245239257812\n",
      "time per batch: 5.198749780654907\n",
      "tensor(7.5931, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 4.285388231277466\n",
      "tensor(14.4532, grad_fn=<MulBackward>)\n",
      "0.0001270771026611328\n",
      "time per batch: 4.257362127304077\n",
      "tensor(20.5022, grad_fn=<MulBackward>)\n",
      "0.00013303756713867188\n",
      "time per batch: 2.775218963623047\n",
      "tensor(36.4471, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001590251922607422\n",
      "time per batch: 2.752642869949341\n",
      "tensor(58.8259, grad_fn=<MulBackward>)\n",
      "0.00012087821960449219\n",
      "time per batch: 2.6002233028411865\n",
      "tensor(68.9915, grad_fn=<MulBackward>)\n",
      "0.0002319812774658203\n",
      "time per batch: 3.264130115509033\n",
      "tensor(8.6960, grad_fn=<MulBackward>)\n",
      "0.00033473968505859375\n",
      "time per batch: 4.264814853668213\n",
      "tensor(20.0463, grad_fn=<MulBackward>)\n",
      "0.0001163482666015625\n",
      "time per batch: 3.3093347549438477\n",
      "tensor(22.1029, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00016069412231445312\n",
      "time per batch: 3.75252103805542\n",
      "tensor(12.2825, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.40801239013672\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.8711793  0.92563594]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3085453124923813\n",
      "--------------------\n",
      "total epoch time: -244.24800992012024\n",
      "epoch 2\n",
      "0\n",
      "0.00018405914306640625\n",
      "time per batch: 3.303091049194336\n",
      "tensor(20.9793, grad_fn=<MulBackward>)\n",
      "0.00016689300537109375\n",
      "time per batch: 3.8686130046844482\n",
      "tensor(23.3794, grad_fn=<MulBackward>)\n",
      "0.00011181831359863281\n",
      "time per batch: 5.055170774459839\n",
      "tensor(60.7486, grad_fn=<MulBackward>)\n",
      "0.00011610984802246094\n",
      "time per batch: 9.400724172592163\n",
      "tensor(26.1313, grad_fn=<MulBackward>)\n",
      "0.0002338886260986328\n",
      "time per batch: 10.50766897201538\n",
      "tensor(52.7077, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001800060272216797\n",
      "time per batch: 8.440577030181885\n",
      "tensor(13.4327, grad_fn=<MulBackward>)\n",
      "0.0002307891845703125\n",
      "time per batch: 6.7211010456085205\n",
      "tensor(11.2374, grad_fn=<MulBackward>)\n",
      "0.00022077560424804688\n",
      "time per batch: 7.695574998855591\n",
      "tensor(8.5237, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 8.24535083770752\n",
      "tensor(20.0794, grad_fn=<MulBackward>)\n",
      "0.0001308917999267578\n",
      "time per batch: 4.422145128250122\n",
      "tensor(19.0986, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001742839813232422\n",
      "time per batch: 3.5683159828186035\n",
      "tensor(22.4603, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.343503952026367\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.90848849 0.95097563]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.31699187810287116\n",
      "--------------------\n",
      "total epoch time: -310.37673711776733\n",
      "epoch 3\n",
      "0\n",
      "0.00013518333435058594\n",
      "time per batch: 3.466884136199951\n",
      "tensor(36.1058, grad_fn=<MulBackward>)\n",
      "0.0001270771026611328\n",
      "time per batch: 3.347856044769287\n",
      "tensor(52.9377, grad_fn=<MulBackward>)\n",
      "0.00013494491577148438\n",
      "time per batch: 4.092397689819336\n",
      "tensor(7.5897, grad_fn=<MulBackward>)\n",
      "0.00016617774963378906\n",
      "time per batch: 2.982361078262329\n",
      "tensor(12.7089, grad_fn=<MulBackward>)\n",
      "0.0001881122589111328\n",
      "time per batch: 3.6583080291748047\n",
      "tensor(9.5161, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00019669532775878906\n",
      "time per batch: 3.8105249404907227\n",
      "tensor(11.2097, grad_fn=<MulBackward>)\n",
      "0.00011515617370605469\n",
      "time per batch: 3.2234833240509033\n",
      "tensor(18.0929, grad_fn=<MulBackward>)\n",
      "0.0001220703125\n",
      "time per batch: 4.826373815536499\n",
      "tensor(17.2632, grad_fn=<MulBackward>)\n",
      "0.0001800060272216797\n",
      "time per batch: 3.3795106410980225\n",
      "tensor(24.4530, grad_fn=<MulBackward>)\n",
      "0.0001227855682373047\n",
      "time per batch: 4.50267219543457\n",
      "tensor(70.7504, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00014019012451171875\n",
      "time per batch: 3.172400951385498\n",
      "tensor(18.1411, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.34259033203125\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.89839507 0.94525868]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.31508622637714734\n",
      "--------------------\n",
      "total epoch time: -189.12939286231995\n",
      "epoch 4\n",
      "0\n",
      "0.0001800060272216797\n",
      "time per batch: 2.7858898639678955\n",
      "tensor(52.8364, grad_fn=<MulBackward>)\n",
      "0.00012063980102539062\n",
      "time per batch: 3.3692119121551514\n",
      "tensor(16.4090, grad_fn=<MulBackward>)\n",
      "0.00023293495178222656\n",
      "time per batch: 3.060664176940918\n",
      "tensor(12.7584, grad_fn=<MulBackward>)\n",
      "0.00011515617370605469\n",
      "time per batch: 4.123517751693726\n",
      "tensor(25.9538, grad_fn=<MulBackward>)\n",
      "0.00011587142944335938\n",
      "time per batch: 7.875448226928711\n",
      "tensor(11.7722, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00020194053649902344\n",
      "time per batch: 3.366075038909912\n",
      "tensor(19.7848, grad_fn=<MulBackward>)\n",
      "0.00013494491577148438\n",
      "time per batch: 2.9253580570220947\n",
      "tensor(12.6879, grad_fn=<MulBackward>)\n",
      "0.00018906593322753906\n",
      "time per batch: 3.519602060317993\n",
      "tensor(66.1630, grad_fn=<MulBackward>)\n",
      "0.00012302398681640625\n",
      "time per batch: 3.3296778202056885\n",
      "tensor(25.0112, grad_fn=<MulBackward>)\n",
      "0.00012373924255371094\n",
      "time per batch: 2.768544912338257\n",
      "tensor(27.6029, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00020003318786621094\n",
      "time per batch: 3.2416460514068604\n",
      "tensor(6.7753, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.250457763671875\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.88010868 0.93060609]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.310202030574935\n",
      "--------------------\n",
      "total epoch time: -299.1418831348419\n",
      "epoch 5\n",
      "0\n",
      "0.0001270771026611328\n",
      "time per batch: 2.6451621055603027\n",
      "tensor(9.4163, grad_fn=<MulBackward>)\n",
      "0.0001239776611328125\n",
      "time per batch: 3.951555013656616\n",
      "tensor(11.7511, grad_fn=<MulBackward>)\n",
      "0.00020575523376464844\n",
      "time per batch: 3.446021795272827\n",
      "tensor(68.3224, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 3.289094924926758\n",
      "tensor(17.4634, grad_fn=<MulBackward>)\n",
      "0.0001220703125\n",
      "time per batch: 2.9865219593048096\n",
      "tensor(26.5857, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0001609325408935547\n",
      "time per batch: 3.7924091815948486\n",
      "tensor(19.5906, grad_fn=<MulBackward>)\n",
      "0.0001327991485595703\n",
      "time per batch: 4.296236038208008\n",
      "tensor(15.4896, grad_fn=<MulBackward>)\n",
      "0.0001270771026611328\n",
      "time per batch: 3.486403226852417\n",
      "tensor(25.7249, grad_fn=<MulBackward>)\n",
      "0.0001239776611328125\n",
      "time per batch: 3.11382794380188\n",
      "tensor(47.3672, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 3.5341529846191406\n",
      "tensor(17.1972, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001709461212158203\n",
      "time per batch: 3.2341830730438232\n",
      "tensor(18.1006, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.182636260986328\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.91358844 0.95389516]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3179650544342368\n",
      "--------------------\n",
      "total epoch time: -204.14462900161743\n",
      "epoch 6\n",
      "0\n",
      "0.0002741813659667969\n",
      "time per batch: 3.483484983444214\n",
      "tensor(30.2040, grad_fn=<MulBackward>)\n",
      "0.00012111663818359375\n",
      "time per batch: 2.499074935913086\n",
      "tensor(70.2251, grad_fn=<MulBackward>)\n",
      "0.00011515617370605469\n",
      "time per batch: 2.2515032291412354\n",
      "tensor(19.6572, grad_fn=<MulBackward>)\n",
      "0.0001201629638671875\n",
      "time per batch: 3.2130091190338135\n",
      "tensor(10.9784, grad_fn=<MulBackward>)\n",
      "0.00011396408081054688\n",
      "time per batch: 3.340139865875244\n",
      "tensor(15.5994, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.0002269744873046875\n",
      "time per batch: 3.174293041229248\n",
      "tensor(6.9760, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 3.396857976913452\n",
      "tensor(24.3186, grad_fn=<MulBackward>)\n",
      "0.00017189979553222656\n",
      "time per batch: 4.165647983551025\n",
      "tensor(35.7579, grad_fn=<MulBackward>)\n",
      "0.00013017654418945312\n",
      "time per batch: 4.004518985748291\n",
      "tensor(12.6235, grad_fn=<MulBackward>)\n",
      "0.00011897087097167969\n",
      "time per batch: 8.278184175491333\n",
      "tensor(43.2385, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0003008842468261719\n",
      "time per batch: 5.223528861999512\n",
      "tensor(7.4418, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.183677673339844\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.83068409 0.89129254]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.29709751398421264\n",
      "--------------------\n",
      "total epoch time: -206.89271998405457\n",
      "epoch 7\n",
      "0\n",
      "0.00011801719665527344\n",
      "time per batch: 2.8479411602020264\n",
      "tensor(13.4015, grad_fn=<MulBackward>)\n",
      "0.00011587142944335938\n",
      "time per batch: 3.7143540382385254\n",
      "tensor(53.7739, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 4.274854898452759\n",
      "tensor(69.9286, grad_fn=<MulBackward>)\n",
      "0.0001900196075439453\n",
      "time per batch: 3.270581007003784\n",
      "tensor(26.1539, grad_fn=<MulBackward>)\n",
      "0.00012111663818359375\n",
      "time per batch: 3.20361590385437\n",
      "tensor(28.1353, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00015687942504882812\n",
      "time per batch: 3.0993008613586426\n",
      "tensor(13.7747, grad_fn=<MulBackward>)\n",
      "0.00011682510375976562\n",
      "time per batch: 3.426536798477173\n",
      "tensor(11.9872, grad_fn=<MulBackward>)\n",
      "0.00011277198791503906\n",
      "time per batch: 3.4169509410858154\n",
      "tensor(21.8054, grad_fn=<MulBackward>)\n",
      "0.00011420249938964844\n",
      "time per batch: 4.733046054840088\n",
      "tensor(23.9380, grad_fn=<MulBackward>)\n",
      "0.00017976760864257812\n",
      "time per batch: 2.8229880332946777\n",
      "tensor(9.3437, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00010919570922851562\n",
      "time per batch: 3.5005850791931152\n",
      "tensor(4.1400, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 25.125640869140625\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   0.  28.]\n",
      " [  0.   0. 263.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [1.         0.89377811 0.94215592]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.31405197273205004\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-06 23:14:50,977] Finished trial#107 resulted in value: 0.31699187810287116. Current best value is 0.3767177645093474 with parameters: {'LR': 5.826992948964408, 'gru_dropout': 0.6023800703615053, 'gru_fcn_dropout': 0.026658703460356214, 'gru_out_dropout': 0.25442982964747174, 'grucrf_hidden_size': 64, 'kernel_sizes': 5, 'w_decay': -3}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0\n",
      "0.00019097328186035156\n",
      "time per batch: 6.1610801219940186\n",
      "tensor(26.5541, grad_fn=<MulBackward>)\n",
      "0.0001900196075439453\n",
      "time per batch: 4.142956018447876\n",
      "tensor(17.5993, grad_fn=<MulBackward>)\n",
      "0.0001201629638671875\n",
      "time per batch: 3.2134928703308105\n",
      "tensor(24.0803, grad_fn=<MulBackward>)\n",
      "0.0001850128173828125\n",
      "time per batch: 2.6568210124969482\n",
      "tensor(106.2484, grad_fn=<MulBackward>)\n",
      "0.0001506805419921875\n",
      "time per batch: 2.6093101501464844\n",
      "tensor(24.5067, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00017404556274414062\n",
      "time per batch: 2.4154341220855713\n",
      "tensor(31.5961, grad_fn=<MulBackward>)\n",
      "0.00012111663818359375\n",
      "time per batch: 2.852065086364746\n",
      "tensor(15.0602, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 2.4248390197753906\n",
      "tensor(20.3710, grad_fn=<MulBackward>)\n",
      "0.0004951953887939453\n",
      "time per batch: 2.7142980098724365\n",
      "tensor(16.4489, grad_fn=<MulBackward>)\n",
      "0.00018906593322753906\n",
      "time per batch: 2.513058662414551\n",
      "tensor(46.1006, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.00018405914306640625\n",
      "time per batch: 3.179694890975952\n",
      "tensor(4.6618, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 30.29339599609375\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.  22.   6.]\n",
      " [  0. 230.  33.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.55681818 0.08874507 0.14982423]\n",
      " [0.12604928 0.7711039  0.21540287]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.12174236643561598\n",
      "--------------------\n",
      "total epoch time: -135.6154112815857\n",
      "epoch 1\n",
      "0\n",
      "0.00011086463928222656\n",
      "time per batch: 2.2214510440826416\n",
      "tensor(16.7636, grad_fn=<MulBackward>)\n",
      "0.00017881393432617188\n",
      "time per batch: 2.3040459156036377\n",
      "tensor(21.1540, grad_fn=<MulBackward>)\n",
      "0.00011682510375976562\n",
      "time per batch: 2.453544855117798\n",
      "tensor(37.9710, grad_fn=<MulBackward>)\n",
      "0.00016880035400390625\n",
      "time per batch: 2.3691349029541016\n",
      "tensor(57.1030, grad_fn=<MulBackward>)\n",
      "0.00011992454528808594\n",
      "time per batch: 2.6181130409240723\n",
      "tensor(11.3462, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00028705596923828125\n",
      "time per batch: 2.605570077896118\n",
      "tensor(10.0041, grad_fn=<MulBackward>)\n",
      "0.00012731552124023438\n",
      "time per batch: 2.266045093536377\n",
      "tensor(25.2175, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 2.708430767059326\n",
      "tensor(10.1664, grad_fn=<MulBackward>)\n",
      "0.00017690658569335938\n",
      "time per batch: 2.6585021018981934\n",
      "tensor(10.5984, grad_fn=<MulBackward>)\n",
      "0.0001289844512939453\n",
      "time per batch: 2.162233829498291\n",
      "tensor(19.5145, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001850128173828125\n",
      "time per batch: 2.962510824203491\n",
      "tensor(5.3978, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 20.476045608520508\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.  12.  16.]\n",
      " [  0.  92. 171.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.32727273 0.1360894  0.17710721]\n",
      " [0.56991049 0.8350704  0.67199268]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.28303329430513796\n",
      "--------------------\n",
      "total epoch time: -132.02174305915833\n",
      "epoch 2\n",
      "0\n",
      "0.00017499923706054688\n",
      "time per batch: 3.377817153930664\n",
      "tensor(6.9072, grad_fn=<MulBackward>)\n",
      "0.00019502639770507812\n",
      "time per batch: 2.0912561416625977\n",
      "tensor(8.6745, grad_fn=<MulBackward>)\n",
      "0.00013518333435058594\n",
      "time per batch: 1.98759126663208\n",
      "tensor(8.5756, grad_fn=<MulBackward>)\n",
      "0.00012683868408203125\n",
      "time per batch: 2.076616048812866\n",
      "tensor(19.9089, grad_fn=<MulBackward>)\n",
      "0.00011801719665527344\n",
      "time per batch: 2.0478198528289795\n",
      "tensor(17.1812, grad_fn=<MulBackward>)\n",
      "5\n",
      "0.00016999244689941406\n",
      "time per batch: 2.7127883434295654\n",
      "tensor(21.5095, grad_fn=<MulBackward>)\n",
      "0.00012731552124023438\n",
      "time per batch: 2.1747560501098633\n",
      "tensor(17.1377, grad_fn=<MulBackward>)\n",
      "0.00018930435180664062\n",
      "time per batch: 2.1337201595306396\n",
      "tensor(14.5193, grad_fn=<MulBackward>)\n",
      "0.00021576881408691406\n",
      "time per batch: 2.4171462059020996\n",
      "tensor(73.5173, grad_fn=<MulBackward>)\n",
      "0.00014281272888183594\n",
      "time per batch: 1.8868680000305176\n",
      "tensor(19.1004, grad_fn=<MulBackward>)\n",
      "10\n",
      "0.0001900196075439453\n",
      "time per batch: 3.165539026260376\n",
      "tensor(9.0365, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 19.642555236816406\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [  0.   6.  22.]\n",
      " [  0.  37. 226.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.15707071 0.15584416 0.11944444]\n",
      " [0.82121099 0.83712159 0.81469387]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3113794383972396\n",
      "--------------------\n",
      "total epoch time: -134.84521794319153\n",
      "epoch 3\n",
      "0\n",
      "0.00021696090698242188\n",
      "time per batch: 2.269212007522583\n",
      "tensor(10.3335, grad_fn=<MulBackward>)\n",
      "0.00012302398681640625\n",
      "time per batch: 2.860908031463623\n",
      "tensor(11.5392, grad_fn=<MulBackward>)\n",
      "0.00018024444580078125\n",
      "time per batch: 2.5476815700531006\n",
      "tensor(43.7410, grad_fn=<MulBackward>)\n",
      "0.00020313262939453125\n",
      "time per batch: 2.640000820159912\n",
      "tensor(11.6618, grad_fn=<MulBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-852ad59538f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqlite:///test_optuna.db'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test optuna'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks)\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[0;32m<ipython-input-43-a0c1460a0df5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mall_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.study.load_study(storage='sqlite:///test_optuna.db', study_name='test optuna')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT name FROM * WHERE type='table';': near \"*\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"*\": syntax error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-40d7d8ea3ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_optuna.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT name FROM * WHERE type='table';\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m                 \u001b[0;34m\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[0;32m-> 1610\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT name FROM * WHERE type='table';': near \"*\": syntax error"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "cnx = sqlite3.connect('test_optuna.db')\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT name FROM * WHERE type='table';\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.load_study(storage='sqlite:///test_optuna.db', study_name='test optuna')\n",
    "df = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>state</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th colspan=\"7\" halign=\"left\">params</th>\n",
       "      <th colspan=\"2\" halign=\"left\">system_attrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>gru_dropout</th>\n",
       "      <th>gru_fcn_dropout</th>\n",
       "      <th>gru_out_dropout</th>\n",
       "      <th>grucrf_hidden_size</th>\n",
       "      <th>kernel_sizes</th>\n",
       "      <th>w_decay</th>\n",
       "      <th>_number</th>\n",
       "      <th>fail_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>TrialState.RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 21:40:01.802894</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.998950</td>\n",
       "      <td>0.075830</td>\n",
       "      <td>0.044007</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>TrialState.RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 21:41:37.515459</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.578753</td>\n",
       "      <td>0.270617</td>\n",
       "      <td>0.432835</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>0.376718</td>\n",
       "      <td>2019-11-06 21:42:43.610794</td>\n",
       "      <td>2019-11-06 22:39:52.725988</td>\n",
       "      <td>5.826993</td>\n",
       "      <td>0.602380</td>\n",
       "      <td>0.026659</td>\n",
       "      <td>0.254430</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>TrialState.COMPLETE</td>\n",
       "      <td>0.316992</td>\n",
       "      <td>2019-11-06 22:39:52.884477</td>\n",
       "      <td>2019-11-06 23:14:50.689517</td>\n",
       "      <td>6.558108</td>\n",
       "      <td>0.163159</td>\n",
       "      <td>0.485613</td>\n",
       "      <td>0.526041</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>TrialState.RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06 23:14:51.032208</td>\n",
       "      <td>NaT</td>\n",
       "      <td>8.818262</td>\n",
       "      <td>0.182233</td>\n",
       "      <td>0.396082</td>\n",
       "      <td>0.471763</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number                state     value             datetime_start  \\\n",
       "                                                                       \n",
       "104    104   TrialState.RUNNING       NaN 2019-11-06 21:40:01.802894   \n",
       "105    105   TrialState.RUNNING       NaN 2019-11-06 21:41:37.515459   \n",
       "106    106  TrialState.COMPLETE  0.376718 2019-11-06 21:42:43.610794   \n",
       "107    107  TrialState.COMPLETE  0.316992 2019-11-06 22:39:52.884477   \n",
       "108    108   TrialState.RUNNING       NaN 2019-11-06 23:14:51.032208   \n",
       "\n",
       "             datetime_complete    params                              \\\n",
       "                                      LR gru_dropout gru_fcn_dropout   \n",
       "104                        NaT  8.998950    0.075830        0.044007   \n",
       "105                        NaT  7.578753    0.270617        0.432835   \n",
       "106 2019-11-06 22:39:52.725988  5.826993    0.602380        0.026659   \n",
       "107 2019-11-06 23:14:50.689517  6.558108    0.163159        0.485613   \n",
       "108                        NaT  8.818262    0.182233        0.396082   \n",
       "\n",
       "                                                            system_attrs  \\\n",
       "    gru_out_dropout grucrf_hidden_size kernel_sizes w_decay      _number   \n",
       "104        0.506712               64.0          3.0    -5.0          104   \n",
       "105        0.123188              128.0          3.0    -5.0          105   \n",
       "106        0.254430               64.0          5.0    -3.0          106   \n",
       "107        0.526041              128.0          5.0    -5.0          107   \n",
       "108        0.471763               64.0          3.0    -4.0          108   \n",
       "\n",
       "                 \n",
       "    fail_reason  \n",
       "104         NaN  \n",
       "105         NaN  \n",
       "106         NaN  \n",
       "107         NaN  \n",
       "108         NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((1))\n",
    "b = torch.randn((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrd\n"
     ]
    }
   ],
   "source": [
    "if a-b<5:\n",
    "    print('wrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter ur logname: sss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-08 14:54:48,542] A new study created with name: test_optuna_sss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "epoch 0\n",
      "0\n",
      "cur_trial: 2\n",
      "0.00024700164794921875\n",
      "time per batch: 4.190179824829102\n",
      "tensor(164.4053, grad_fn=<MulBackward>)\n",
      "0.00010800361633300781\n",
      "time per batch: 2.489389181137085\n",
      "tensor(79.4787, grad_fn=<MulBackward>)\n",
      "0.00011706352233886719\n",
      "time per batch: 3.622425079345703\n",
      "tensor(68.4122, grad_fn=<MulBackward>)\n",
      "0.0001590251922607422\n",
      "time per batch: 2.1142139434814453\n",
      "tensor(20.1260, grad_fn=<MulBackward>)\n",
      "0.00011110305786132812\n",
      "time per batch: 2.023732900619507\n",
      "tensor(38.8639, grad_fn=<MulBackward>)\n",
      "5\n",
      "cur_trial: 2\n",
      "0.0001857280731201172\n",
      "time per batch: 3.5059359073638916\n",
      "tensor(39.5278, grad_fn=<MulBackward>)\n",
      "0.00011491775512695312\n",
      "time per batch: 2.8796801567077637\n",
      "tensor(24.6600, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 62.210548400878906\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 38.   7.   3.]\n",
      " [268.  19.  22.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.17568543 0.32142857 0.20466914]\n",
      " [0.07894159 0.39072039 0.12475934]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.10980949269358974\n",
      "--------------------\n",
      "total epoch time: -75.46514987945557\n",
      "epoch 1\n",
      "0\n",
      "cur_trial: 2\n",
      "0.00027632713317871094\n",
      "time per batch: 2.160202980041504\n",
      "tensor(19.8660, grad_fn=<MulBackward>)\n",
      "0.00011324882507324219\n",
      "time per batch: 1.9205701351165771\n",
      "tensor(153.7606, grad_fn=<MulBackward>)\n",
      "0.00016307830810546875\n",
      "time per batch: 2.411862850189209\n",
      "tensor(41.6489, grad_fn=<MulBackward>)\n",
      "0.00011301040649414062\n",
      "time per batch: 2.277531147003174\n",
      "tensor(67.4836, grad_fn=<MulBackward>)\n",
      "0.0001678466796875\n",
      "time per batch: 2.460491180419922\n",
      "tensor(39.7638, grad_fn=<MulBackward>)\n",
      "5\n",
      "cur_trial: 2\n",
      "0.00021886825561523438\n",
      "time per batch: 2.2450270652770996\n",
      "tensor(72.6885, grad_fn=<MulBackward>)\n",
      "0.00011920928955078125\n",
      "time per batch: 2.674069881439209\n",
      "tensor(22.7405, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 59.7074089050293\n",
      "testing\n",
      "[[  0.   0.   0.]\n",
      " [ 41.   7.   0.]\n",
      " [289.  19.   1.]\n",
      " [  0.   0.   0.]]\n",
      "[[0.         0.         0.        ]\n",
      " [0.17857143 0.25       0.19642857]\n",
      " [0.00303951 0.14285714 0.00595238]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.06746031746031746\n",
      "--------------------\n",
      "total epoch time: -71.3506510257721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-08 14:57:20,621] Finished trial#0 resulted in value: 0.06746031746031746. Current best value is 0.06746031746031746 with parameters: {'LR': 9.311652578438999, 'gru_dropout': 0.5494176585798091, 'gru_fcn_dropout': 0.2272287674142849, 'gru_out_dropout': 0.45003621827429685, 'grucrf_hidden_size': 64, 'kernel_sizes': 3, 'w_decay': -4}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "epoch 0\n",
      "0\n",
      "cur_trial: 3\n",
      "0.0001239776611328125\n",
      "time per batch: 4.3107030391693115\n",
      "tensor(26.4435, grad_fn=<MulBackward>)\n",
      "0.00019812583923339844\n",
      "time per batch: 3.8920347690582275\n",
      "tensor(102.5037, grad_fn=<MulBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f33294121e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqlite:///'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.db'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_optuna_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks)\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[0;32m<ipython-input-39-f33294121e6d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mall_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import regex as re\n",
    "from time import time\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from allennlp.modules.conditional_random_field import ConditionalRandomField\n",
    "from allennlp.modules.conditional_random_field import allowed_transitions\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchcrf import CRF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "from typing import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from functools import wraps\n",
    "from RULE import RULEs\n",
    "from POSMap import POSMAP\n",
    "from my_stuff_opt import *\n",
    "\n",
    "num_trial = 50\n",
    "cur_trial = 1\n",
    "BS = 2\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 3\n",
    "word_length = 84\n",
    "early_stop_n = 5\n",
    "max_size_char = 6\n",
    "same_padding = True\n",
    "use_BN = True\n",
    "activation_func = True\n",
    "input_channel = 1\n",
    "nums_filter = [1]\n",
    "output_size = 64\n",
    "size_of_embedding = 300\n",
    "pos_size = len(POSMAP)\n",
    "num_char_encoding_size = 135\n",
    "FCN = False\n",
    "file_name = input('enter ur logname: ')\n",
    "num_epoch = 2\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "Train = MyDataloader('../clean84withpos_ne.txt', '../label84withpos_ne.txt', RULEs, \\\n",
    "                           word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "                           '../fasttext.th.vec', 300, device, '../pos_tag84withpos_ne.txt',POSMAP)\n",
    "# Test = MyDataloader('clean84withpos_ne_te0.txt', 'label84withpos_ne_te0.txt', RULEs, \\\n",
    "#                            word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "#                            'fasttext.th.vec', 300, device, 'pos_tag84withpos_ne_te0.txt',POSMAP)\n",
    "tr, te = get_indices_random_val_test_split(len(Train), 1, 0.0002, True)\n",
    "def objective(trial):\n",
    "    global cur_trial\n",
    "    cur_trial += 1\n",
    "    cnt_idle = 0\n",
    "    kernel_sizes = [trial.suggest_categorical('kernel_sizes', [3,5])]\n",
    "    gru_fcn_dropout = trial.suggest_uniform('gru_fcn_dropout', 0, 0.6)\n",
    "    gru_dropout = trial.suggest_uniform('gru_dropout', 0, 0.6)\n",
    "    gru_out_dropout = trial.suggest_uniform('gru_out_dropout', 0, 0.6)\n",
    "    LR = trial.suggest_uniform('LR', 5, 10)*10**(-4)\n",
    "    grucrf_hidden_size = trial.suggest_categorical('grucrf_hidden_size', [64, 128])\n",
    "    w_decay = trial.suggest_categorical('w_decay', [-4,0])\n",
    "    \n",
    "#     train_loader = DataLoader(Train, batch_size=BS, shuffle=True)\n",
    "#     test_loader = DataLoader(Test, batch_size=BS, shuffle=True)\n",
    "\n",
    "    train_loader = DataLoader(Train, batch_size=BS, sampler=tr)\n",
    "    test_loader = DataLoader(Train, batch_size=BS, sampler=te)\n",
    "    \n",
    "    with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "        f.write(f'kernel_sizes: {kernel_sizes}, gru_fcn_dropout: {gru_fcn_dropout}\\n')\n",
    "        f.write(f'gru_dropout: {gru_dropout}, gru_out_dropout: {gru_out_dropout}\\n')\n",
    "        f.write(f'LR: {LR}, grucrf_hidden_size: {grucrf_hidden_size}\\n')\n",
    "        f.write(f'w_decay: {w_decay}\\n')\n",
    "\n",
    "    NER = CNN_GRU_char_pos(BS, max_size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "                           kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, \\\n",
    "                           grucrf_hidden_size, gru_dropout, True, tags, gru_fcn_dropout, pos_size, FCN, \\\n",
    "                           gru_out_dropout)\n",
    "    optimizer = optim.Adam(NER.parameters(), lr=LR, eps=1e-08, weight_decay=10**w_decay,amsgrad=True)\n",
    "    my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', verbose=True)\n",
    "    print(device)\n",
    "    NER.to(device)\n",
    "    best_score = 0\n",
    "    last_loss = 100000000\n",
    "    for epoch in range(num_epoch):\n",
    "        ttt = time()\n",
    "        print(f'epoch {epoch}')\n",
    "        all_loss = []\n",
    "        for ind, batch_x in enumerate(train_loader):\n",
    "            if ind%5 == 0:\n",
    "                print(ind)\n",
    "                print(f'cur_trial: {cur_trial}')\n",
    "            t2 = time()\n",
    "            NER = NER.train()\n",
    "            print(time() - t2)\n",
    "            NER.zero_grad()\n",
    "            t1 = time()\n",
    "            loss = NER(batch_x)\n",
    "            loss = loss*(-1)\n",
    "            print(f'time per batch: {time() - t1}')\n",
    "            print(loss)\n",
    "            all_loss.append(loss)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "            optimizer.step()\n",
    "        total_loss = sum(all_loss)/(ind + 1)\n",
    "        my_scheduler.step(total_loss)\n",
    "        print(f'total loss of epoch: {total_loss.item()}')\n",
    "        print('testing')\n",
    "        per_mat = np.zeros((len(tags), 3))\n",
    "        cnt_mat = np.zeros((len(tags), 3))\n",
    "        for ind, batch_test in enumerate(test_loader):\n",
    "            NER = NER.eval()\n",
    "            output = NER.predict(batch_test)\n",
    "            a, b = eval_score(tags, output, batch_test[2])\n",
    "            per_mat += a\n",
    "            cnt_mat += b\n",
    "        per_mat = per_mat/(ind+1)\n",
    "        per_mat = per_mat[:len(tags),:]\n",
    "        cnt_mat = cnt_mat[:len(tags),:]\n",
    "        print(cnt_mat)\n",
    "        print(per_mat)\n",
    "        score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "\n",
    "        with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "            f.write(f'epoch: {epoch}, score: {score}\\n')\n",
    "        \n",
    "        if last_loss - total_loss.item() >= 0.1:\n",
    "            best_mat=per_mat\n",
    "            best_score = score\n",
    "            cnt_idle = 0\n",
    "        else:\n",
    "            cnt_idle += 1\n",
    "        last_loss = total_loss.item()\n",
    "        print(f'overall score: {score}')\n",
    "        print('--------------------')\n",
    "        if early_stop_n == cnt_idle:\n",
    "            break\n",
    "        print(f'total epoch time: {ttt-time()}')\n",
    "    with open(file_name + '.txt', 'a', encoding='utf8') as f:\n",
    "        f.write(f'cur_trial: {cur_trial}')\n",
    "        f.write(f'cnt_mat\\n')\n",
    "        f.write(f'I => : {cnt_mat[0,0]}, : {cnt_mat[0,1]}, : {cnt_mat[0,2]}\\n')\n",
    "        f.write(f'B => : {cnt_mat[1,0]}, : {cnt_mat[1,1]}, : {cnt_mat[1,2]}\\n')\n",
    "        f.write(f'O => : {cnt_mat[2,0]}, : {cnt_mat[2,1]}, : {cnt_mat[2,2]}\\n')\n",
    "        f.write(f'best_score: {best_score}\\n')\n",
    "        f.write(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "        f.write(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "        f.write(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "        f.write(f'----------------------------------\\n')\n",
    "    return best_score\n",
    "\n",
    "study = optuna.study.create_study(storage='sqlite:///'+ file_name +'.db', study_name='test_optuna_' + file_name, direction='maximize')\n",
    "study.optimize(objective, n_trials=num_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# char-RNN vs char-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "lstmcrf_dropout = DO_FCN_LSTMCRF: 0\n",
      "lstmcrf_hidden_size: 128, LR: 0.001\n",
      "cpu\n",
      "epoch 0\n",
      "NER1 with BS: 4\n",
      "0\n",
      "0.00011897087097167969\n",
      "time per batch: 3.700333833694458\n",
      "tensor(242.6188, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "0.00011897087097167969\n",
      "time per batch: 4.085191011428833\n",
      "tensor(122.6828, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "0.00010895729064941406\n",
      "time per batch: 3.710599184036255\n",
      "tensor(111.6462, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "0.00011491775512695312\n",
      "time per batch: 3.8553411960601807\n",
      "tensor(104.4827, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "0.00011706352233886719\n",
      "time per batch: 3.7547922134399414\n",
      "tensor(92.9099, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "5\n",
      "0.00011873245239257812\n",
      "time per batch: 3.8132340908050537\n",
      "tensor(62.8398, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 4\n",
      "0.00012087821960449219\n",
      "time per batch: 3.9524810314178467\n",
      "tensor(72.6978, grad_fn=<MulBackward>)\n",
      "cpu\n",
      "epoch 0\n",
      "NER2 with BS: 4\n",
      "0\n",
      "0.00011920928955078125\n",
      "time per batch: 5.445732116699219\n",
      "tensor(124.3198, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "0.00010085105895996094\n",
      "time per batch: 5.3802690505981445\n",
      "tensor(208.6031, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "0.00010776519775390625\n",
      "time per batch: 6.981726884841919\n",
      "tensor(204.1014, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "0.00010395050048828125\n",
      "time per batch: 5.046168088912964\n",
      "tensor(127.0232, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "0.00010967254638671875\n",
      "time per batch: 8.315469026565552\n",
      "tensor(166.4632, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "5\n",
      "0.00010967254638671875\n",
      "time per batch: 5.331172943115234\n",
      "tensor(68.6495, grad_fn=<MulBackward>)\n",
      "NER2 with BS: 4\n",
      "0.00018095970153808594\n",
      "time per batch: 4.799216270446777\n",
      "tensor(44.3049, grad_fn=<MulBackward>)\n",
      "lstmcrf_dropout = DO_FCN_LSTMCRF: 0\n",
      "lstmcrf_hidden_size: 128, LR: 0.001\n",
      "cpu\n",
      "epoch 0\n",
      "NER1 with BS: 8\n",
      "0\n",
      "0.00012683868408203125\n",
      "time per batch: 6.851819038391113\n",
      "tensor(205.7026, grad_fn=<MulBackward>)\n",
      "NER1 with BS: 8\n",
      "0.00011396408081054688\n",
      "time per batch: 5.447613000869751\n",
      "tensor(192.6643, grad_fn=<MulBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f685796f1ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mall_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                     \u001b[0;31m#nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/allennlp2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "time_RNN = []\n",
    "time_CNN = []\n",
    "word_length = 84\n",
    "size_char = 6\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "data_tr = MyDataloader('../Data/clean84withpos_ne_tr0.txt', '../Data/label84withpos_ne_tr0.txt',\\\n",
    "                               RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "                               '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr0.txt',POSMAP)\n",
    "data_te = MyDataloader('../Data/clean84withpos_ne_te0.txt', '../Data/label84withpos_ne_te0.txt', \\\n",
    "                       RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "                       '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te0.txt',POSMAP)\n",
    "\n",
    "#         train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "#         test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "tr, te = get_indices_random_val_test_split(len(data_tr), 1, 0.0005, True)\n",
    "\n",
    "list_BS = [4,8,16,32,64,128]\n",
    "for BS in list_BS:\n",
    "    train_loader = DataLoader(data_tr, batch_size=BS, sampler=tr)\n",
    "    test_loader = DataLoader(data_tr, batch_size=BS, sampler=te)\n",
    "    #BS = 8\n",
    "    tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "    scheduler_n = 10002\n",
    "    word_length = 84\n",
    "    early_stop_n = 10003\n",
    "    max_size_char = [6]#[5, 10, 20]\n",
    "    nums_filter = [1]\n",
    "    use_BN = True\n",
    "    activation_func = True\n",
    "    input_channel = 1\n",
    "    kernel_sizes = [3]\n",
    "    same_padding = True\n",
    "    num_char_encoding_size = 135\n",
    "    output_size = 64\n",
    "    size_of_embedding = 300\n",
    "    pos_size = len(POSMAP)\n",
    "    FCN = False\n",
    "    grucrf_dropout = [0]#[0, 0.15, 0.30, 0.45, 0.60]\n",
    "    total_search = len(max_size_char)*len(grucrf_dropout)*2\n",
    "    for size_char in max_size_char:\n",
    "\n",
    "#         data_tr = MyDataloader('../Data/clean84withpos_ne_tr'+ str(IND) +'.txt', '../Data/label84withpos_ne_tr'+ str(IND) +'.txt',\\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_tr'+ str(IND) +'.txt',POSMAP)\n",
    "#         data_te = MyDataloader('../Data/clean84withpos_ne_te'+ str(IND) +'.txt', '../Data/label84withpos_ne_te'+ str(IND) +'.txt', \\\n",
    "#                                RULEs, word_length, '|', 'char_vec_dictionary.txt', size_char, \\\n",
    "#                                '../fasttext.th.vec', 300, device, '../Data/pos_tag84withpos_ne_te'+ str(IND) +'.txt',POSMAP)\n",
    "\n",
    "# #         train_loader = DataLoader(data_tr, batch_size=BS, shuffle= True)\n",
    "# #         test_loader = DataLoader(data_te, batch_size=BS, shuffle= True)\n",
    "#         tr, te = get_indices_random_val_test_split(len(data_tr), 1, 0.0005, True)\n",
    "#         train_loader = DataLoader(data_tr, batch_size=BS, sampler=tr)\n",
    "#         test_loader = DataLoader(data_tr, batch_size=BS, sampler=te)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        for i in grucrf_dropout:\n",
    "            \n",
    "            grucrf_hidden_size = 128\n",
    "            LR = 10**(-3)\n",
    "            print(f'lstmcrf_dropout = DO_FCN_LSTMCRF: {i}')\n",
    "            print(f'lstmcrf_hidden_size: {grucrf_hidden_size}, LR: {LR}')\n",
    "            NER = CNN_GRU_char_pos(BS, size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "                 kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, grucrf_hidden_size, \\\n",
    "                 0, True, tags, 0, pos_size, FCN, 0)\n",
    "#             NER = CNN_GRU_char_pos(BS, size_char, nums_filter, use_BN, activation_func, input_channel, \\\n",
    "#                  kernel_sizes, same_padding, num_char_encoding_size, output_size, word_length, grucrf_hidden_size, \\\n",
    "#                  i, True, tags, i, pos_size, FCN, 0.5)\n",
    "\n",
    "            optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "            my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "            print(device)\n",
    "            NER.to(device)\n",
    "            best_score = 0\n",
    "            best_mat = np.zeros((len(tags)-1,3))\n",
    "            cnt_idle = 0\n",
    "            for epoch in range(num_epoch):\n",
    "                ttt = time()\n",
    "                print(f'epoch {epoch}')\n",
    "                all_loss = []\n",
    "                for ind, batch_x in enumerate(train_loader):\n",
    "                    print(f'NER1 with BS: {BS}')\n",
    "                    ttt2 = time()\n",
    "                    if ind%5 == 0:\n",
    "                        print(ind)\n",
    "                    t2 = time()\n",
    "                    NER = NER.train()\n",
    "                    print(time() - t2)\n",
    "                    NER.zero_grad()\n",
    "                    t1 = time()\n",
    "                    loss = NER(batch_x)\n",
    "                    loss = loss*(-1)\n",
    "                    print(f'time per batch: {time() - t1}')\n",
    "                    print(loss)\n",
    "                    all_loss.append(loss)\n",
    "                    loss.backward()\n",
    "                    #nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "                    optimizer.step()\n",
    "                    time_CNN.append(time()-ttt2)\n",
    "                total_loss = sum(all_loss)/(ind + 1)\n",
    "                my_scheduler.step(total_loss)\n",
    "                \n",
    "            NER = over_all_NER2(BS,135,5,size_char,0,True, 5,size_of_embedding,word_length,128,0,True,tags, \\\n",
    "                                0, 0,pos_size, 0)\n",
    "            optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "            my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "            print(device)\n",
    "            NER.to(device)\n",
    "            best_score = 0\n",
    "            best_mat = np.zeros((len(tags)-1,3))\n",
    "            cnt_idle = 0\n",
    "            for epoch in range(num_epoch):\n",
    "                ttt = time()\n",
    "                print(f'epoch {epoch}')\n",
    "                all_loss = []\n",
    "                for ind, batch_x in enumerate(train_loader):\n",
    "                    print(f'NER2 with BS: {BS}')\n",
    "                    ttt2 = time()\n",
    "                    if ind%5 == 0:\n",
    "                        print(ind)\n",
    "                    t2 = time()\n",
    "                    NER = NER.train()\n",
    "                    print(time() - t2)\n",
    "                    NER.zero_grad()\n",
    "                    t1 = time()\n",
    "                    loss = NER(batch_x)\n",
    "                    loss = loss*(-1)\n",
    "                    print(f'time per batch: {time() - t1}')\n",
    "                    print(loss)\n",
    "                    all_loss.append(loss)\n",
    "                    loss.backward()\n",
    "                    #nn.utils.clip_grad_norm_(NER.parameters(), 5, norm_type=2)\n",
    "                    optimizer.step()\n",
    "                    time_RNN.append(time()-ttt2)\n",
    "                total_loss = sum(all_loss)/(ind + 1)\n",
    "                my_scheduler.step(total_loss)\n",
    "            with open(f'log_time_cnn_rnn_char_BS_{BS}.txt', 'w', encoding = 'utf8') as f:\n",
    "                f.write('CNN, RNN\\n')\n",
    "                for i in range(len(time_RNN)):\n",
    "                    f.write(f'{time_CNN[i]}, {time_RNN[i]}\\n')\n",
    "            \n",
    "#                 print(f'total loss of epoch: {total_loss.item()}')\n",
    "#                 print('testing')\n",
    "#                 per_mat = np.zeros((len(tags), 3))\n",
    "#                 cnt_mat = np.zeros((len(tags), 3))\n",
    "#                 for ind, batch_test in enumerate(test_loader):\n",
    "#                     NER = NER.eval()\n",
    "#                     output = NER.predict(batch_test)\n",
    "#                     a, b = eval_score(tags, output, batch_test[2])\n",
    "#                     per_mat += a\n",
    "#                     cnt_mat += b\n",
    "#                 per_mat = per_mat/(ind+1)\n",
    "#                 per_mat = per_mat[:len(tags),:]\n",
    "#                 cnt_mat = cnt_mat[:len(tags),:]\n",
    "#                 print(cnt_mat)\n",
    "#                 print(per_mat)\n",
    "#                 score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "#                 if best_score < score:\n",
    "#                     best_mat=per_mat\n",
    "#                     best_score = score\n",
    "#                     cnt_idle = 0\n",
    "#                 else:\n",
    "#                     cnt_idle += 1\n",
    "#                 print(f'overall score: {score}')\n",
    "#                 print('--------------------')\n",
    "#                 if early_stop_n == cnt_idle:\n",
    "#                     break\n",
    "#                 print(f'total epoch time: {ttt-time()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/abc/Downloads/min/Codes/LSTM-CRF-NER'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "allennlp2",
   "language": "python",
   "name": "allennlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
