{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import regex as re\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from allennlp.modules.conditional_random_field import ConditionalRandomField\n",
    "from allennlp.modules.conditional_random_field import allowed_transitions\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#from torchcrf import CRF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn_crfsuite import metrics\n",
    "\n",
    "from RULE import RULEs\n",
    "from POSMap import POSMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "class MyDataloader(Dataset):\n",
    "    def __init__(self, TextDir: '.txt extension of samples', LabelDir: '.txt extension of labels',rules:\\\n",
    "                 'the rules to be replaced => see in RULE.py', Len_word_vec: 'size of word vector', \\\n",
    "                delimiter: '(str) delimiter used to separate data', dir_char_dictionary: \\\n",
    "                '(str) see in CharEmbedding', max_len_char: '(int) see in CharEmbedding', \\\n",
    "                fasttext_dictionary_dir: '(str) see in WordEmbedding',\\\n",
    "                Len_embedded_vector: '(int) see in WordEmbedding', device, POSDir: '(str) .txt extension of POS',\\\n",
    "                POSMapping: 'see in POSMap.py') -> None:\n",
    "        super().__init__()\n",
    "        self.DF = pd.read_csv(TextDir, names=['text'])\n",
    "        self.Label_DF = pd.read_csv(LabelDir, names=['text'])\n",
    "        self.pos_DF = pd.read_csv(POSDir, names=['text'])\n",
    "        self.rules = rules\n",
    "        self.Len_word_vec = Len_word_vec\n",
    "        self.delimiter = delimiter\n",
    "        self.char_embedder = CharEmbedding(dir_char_dictionary, max_len_char)\n",
    "        self.word_embedder = WordEmbedding(fasttext_dictionary_dir, Len_embedded_vector)\n",
    "        self.device = device\n",
    "        self.pos_embedder = POSEmbedding(POSMapping)\n",
    "    def __len__(self):\n",
    "        return len(self.DF)\n",
    "    def __getitem__(self, Index) -> '(sample: (torch.tensor), label: (torch.tensor))':\n",
    "        all_words = [word.strip() for word in self.DF['text'][Index].strip().split(self.delimiter)]\n",
    "        for i in range(len(all_words)):\n",
    "            for rule in self.rules:\n",
    "                all_words[i] = re.sub(*rule, all_words[i])\n",
    "        Label = [float(word.strip()) for word in self.Label_DF['text'][Index].strip().split(self.delimiter)]\n",
    "        mask = [1.0]*len(all_words)\n",
    "        POS = [pos.strip() for pos in self.pos_DF['text'][Index].strip().split(self.delimiter)]\n",
    "        if len(all_words) < self.Len_word_vec:\n",
    "            Label = Label + [3.0]*(self.Len_word_vec - len(all_words))\n",
    "            mask = mask + [0.0]*(self.Len_word_vec - len(all_words))\n",
    "            POS = POS + ['<pad>']*(self.Len_word_vec - len(all_words))\n",
    "            all_words = all_words + ['<pad>']*(self.Len_word_vec - len(all_words))\n",
    "        char_embed = self.char_embedder.embed(all_words)\n",
    "        word_embed = self.word_embedder.embed(all_words)\n",
    "        pos_embed = self.pos_embedder.embed(POS)\n",
    "        # print(len(all_words))\n",
    "        # print(len(Label))\n",
    "        # print(len(mask))\n",
    "        # print('----------')\n",
    "        return (char_embed.to(self.device), word_embed.to(self.device), \\\n",
    "                torch.tensor(Label).to(self.device), torch.tensor(mask).to(self.device), \\\n",
    "                len(all_words), pos_embed.float().to(device))\n",
    "    \n",
    "\n",
    "class CharEmbedding():\n",
    "    def __init__(self,\\\n",
    "    dir_char_dictionary: '(str) .txt',\\\n",
    "    max_len_char: '(int) max size of char representation, for example: given max_len_char=3 and word= \"abcde\" => only \"abc\" is used'):\n",
    "    #Example: given embed_capital=True and 'a' is embedded as array([1.,0.,0.,0.,0]). 'A' is then embedded as array([1.,0.,0.,0.,1.])\n",
    "        self.dictionary = {}\n",
    "        self.max_len_char = max_len_char\n",
    "        with open(dir_char_dictionary, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                tmp_data = line.strip().split()\n",
    "                self.dictionary[tmp_data[0]] = np.array([float(Char) for Char in tmp_data[1:]])\n",
    "    def embed(self, list_of_words: '(list[str]) example: [\"ฉัน\",\"กิน\",\"ข้าว\"]'):\n",
    "        #Note: 1 outer list is for 1 word.\n",
    "        output = []\n",
    "        for word in list_of_words:\n",
    "            embedded_word = []\n",
    "            tmp_word = word\n",
    "            if len(word) > self.max_len_char:\n",
    "                tmp_word = tmp_word[:self.max_len_char]\n",
    "            for Char in tmp_word:\n",
    "                if Char in self.dictionary:\n",
    "                    tmp_vector = self.dictionary[Char]\n",
    "                else:\n",
    "                    tmp_vector = np.zeros(self.dictionary['a'].shape)\n",
    "                embedded_word.append(tmp_vector)\n",
    "            if len(embedded_word) < self.max_len_char:\n",
    "                for i in range(self.max_len_char - len(embedded_word)):\n",
    "                    embedded_word.append(np.zeros(self.dictionary['a'].shape))\n",
    "            output.append(torch.tensor(embedded_word))\n",
    "        return torch.stack(output)\n",
    "\n",
    "class WordEmbedding():\n",
    "    #use fasttext embedding ==> read from a file\n",
    "    def __init__(self, fasttext_dictionary_dir: '(str) .vec extension of words and embedded_vectors',\\\n",
    "     Len_embedded_vector: '(int) size of embedded each vector (300 for fasttext) **Count only numbers not words'\\\n",
    "     ) -> None:\n",
    "        #example of format in fasttext_dictionary_dir\n",
    "        #กิน 1.0 -2.666 -3 22.5 .... \\n\n",
    "        #นอน 1.5 -5.666 3 9.5 .... \\n\n",
    "        #...\n",
    "        #...\n",
    "        self.dictionary = {}\n",
    "        self.Len_embedded_vector = Len_embedded_vector\n",
    "        with open(fasttext_dictionary_dir, 'r', encoding = 'utf8') as f:\n",
    "            for line in f:\n",
    "                tmp_line = line.strip()\n",
    "                tmp_words = tmp_line.split()\n",
    "                if tmp_line != '' and len(tmp_words) == self.Len_embedded_vector + 1:\n",
    "                    self.dictionary[tmp_words[0]] = np.array([float(element) for element in tmp_words[1:]])\n",
    "                else:\n",
    "                    continue\n",
    "    def embed(self, list_of_words: '(List[str]) for example: [\"ฉัน\",\"กิน\",\"ข้าว\"]'):\n",
    "        tmp_list = []\n",
    "        for word in list_of_words:\n",
    "            if word in self.dictionary:\n",
    "                tmp_list.append(self.dictionary[word])\n",
    "            else:\n",
    "                #in case of OOV: Zero-vector is used.\n",
    "                tmp_list.append(np.zeros(self.Len_embedded_vector))\n",
    "        return torch.tensor(tmp_list)\n",
    "\n",
    "class POSEmbedding():\n",
    "    def __init__(self, POSMapping: 'see in POSMap.py'):\n",
    "        self.dictionary = POSMapping\n",
    "        self.size = len(self.dictionary)\n",
    "    def embed(self, list_of_POSs:'(list[str]) example: [\"NOUN\",\"VERB\",\"NOUN\"]'):\n",
    "        tmp_list = []\n",
    "        for POS in list_of_POSs:\n",
    "            POS = POS.strip()\n",
    "            if POS == '<pad>':\n",
    "                tmp_list.append(np.zeros(self.size))\n",
    "            else:\n",
    "                tmp_data = np.zeros(self.size)\n",
    "                tmp_data[self.dictionary[POS]] = 1\n",
    "                tmp_list.append(tmp_data)\n",
    "        return torch.tensor(tmp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length=4\n",
    "batch_size=3\n",
    "\n",
    "data = torch.randn(seq_length, batch_size, num_tags)#shape(seq_length, batch_size, num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[0,0,0],[0,0,0],[2,2,2],[0,3,3]])#shape = (seq_length, batch_size)\n",
    "print(target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1,1,1],[1,1,1], [1,1,1],[0,1,0]])\n",
    "#(seq_length, batch_size)\n",
    "#mask = torch.tensor([[1,0,0],[0,1,0],[0,0,1]])\n",
    "print(mask.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "############### RNN encoding ######################\n",
    "class RNN_char(nn.Module):\n",
    "    def __init__(self, num_char_vec_features, hidden_size, num_layers, dropout_gru, bidirectional, \\\n",
    "                output_size, dropout_FCN, num_word):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=num_char_vec_features, hidden_size=hidden_size, num_layers=num_layers,\\\n",
    "                          batch_first = True, dropout=dropout_gru, bidirectional=bidirectional)\n",
    "        self.linear = nn.Linear(hidden_size*2*num_layers, output_size)\n",
    "        self.BN = nn.BatchNorm1d(num_word)\n",
    "        self.dropout = nn.Dropout(dropout_FCN)\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self, x):\n",
    "        batch_size, word_seq, char_seq, char_vec = x.size()\n",
    "        tmp_list = []\n",
    "        for i in range(word_seq):\n",
    "            tmp_compute , _ = self.gru(x[:,i,:,:].float())\n",
    "            tmp_list.append(tmp_compute.contiguous().view(batch_size,-1))\n",
    "        tmp_compute = torch.stack(tmp_list,1)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_compute = self.dropout(tmp_compute)\n",
    "        tmp_compute = self.linear(tmp_compute)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_compute = F.relu(self.BN(tmp_compute))#>>linear >> BachNorm >> relu\n",
    "        return tmp_compute\n",
    "    \n",
    "class over_all_NER2(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 num_char_vec_features: '(int)',\\\n",
    "                 hidden_size: '(int)',\\\n",
    "                 max_num_char: '(int)',\\\n",
    "                 dropout_gru_char: '(double)',\\\n",
    "                 bidirectional_char: '(bool)',\\\n",
    "                 output_char_embed_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', \\\n",
    "                 bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)',\\\n",
    "                 pos_size: '(int) size of pos embedding'):\n",
    "        super().__init__()\n",
    "        self.gru_char = RNN_char(num_char_vec_features, hidden_size, max_num_char, dropout_gru_char, \\\n",
    "                                 bidirectional_char, output_char_embed_size, DOchar_FCN, num_words)\n",
    "        self.gru_crf_layer = gru_crf(size_of_embedding + output_char_embed_size + pos_size, \\\n",
    "                                     gru_hidden_size, num_words, dropout_gru, bidirectional, tags, DO_FCN_GRUCRF)\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.gru_char(x[0])\n",
    "        #print(tmp_compute.size())\n",
    "        #print(x[1].size())\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_gru_crf = self.gru_crf_layer((tmp_compute, x[4]), x[2], x[3].long())\n",
    "        return tmp_gru_crf\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.gru_char(x[0])\n",
    "        tmp_compute = torch.cat([tmp_compute, x[1].float(), x[5]], 2)\n",
    "        tmp_gru_crf = self.gru_crf_layer.predict((tmp_compute, x[4]), x[3].long())\n",
    "        return tmp_gru_crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "def get_index(len_row, len_col)->'(iterator of all ((int)row, (int)col))':\n",
    "    for i in range(len_row):\n",
    "        for j in range(len_col):\n",
    "            yield(i,j)\n",
    "\n",
    "def get_longest_seq_len(MASK: '(torch.tensor: shape=(batch_size, num_words)) \\\n",
    "    of mask 1 for non padding, 0 for otherwise')->'(int) col index of first zero in\\\n",
    "    of the longest sequence example: x=torch.tensor([[1,1,0],[1,0,0]]) -> return 2':\n",
    "    tmp_mask = MASK.numpy()\n",
    "    if len(tmp_mask.shape) != 1:\n",
    "        tmp_mask = np.sum(tmp_mask,0)\n",
    "    col = 0\n",
    "    for i in range(tmp_mask.shape[0]):\n",
    "        if tmp_mask[i]==0:\n",
    "            col = i\n",
    "            break\n",
    "    if col == 0:\n",
    "        col = tmp_mask.shape[0]\n",
    "    return col\n",
    "\n",
    "class overall_char_embedding(nn.Module):\n",
    "    def __init__(self, output_size: '(tuple of ints): (batch_size, embedding_size_per_word)',\n",
    "    max_len_char: '(int) see in CharEmbedding',\\\n",
    "    nums_filter: '(list) list of number of filters according to each kernel_sizes (respectively)',\n",
    "    use_BN: 'see in My2DConv',\n",
    "    activation_func: 'see in My2DConv',\n",
    "    input_channel: 'see in My2DConv',\n",
    "    kernel_sizes: '(list[int]) list of size of kernels used, and they will be computed concurrently',\n",
    "    same_padding: 'see in My2DConv',\n",
    "    num_words: 'number of words used in 1 sample',\n",
    "    num_char_encoding_size: 'size of encoding for each char'):\n",
    "        super().__init__()\n",
    "        self.batch_size, self.embedding_size_per_word = output_size\n",
    "        tmp_cnn_models = []\n",
    "        for ind_cnn, kernel_size in enumerate(kernel_sizes):\n",
    "            tmp_cnn_models.append(\\\n",
    "            My2DConv(nums_filter[ind_cnn], use_BN, activation_func, input_channel,\\\n",
    "            (kernel_size, num_char_encoding_size), same_padding)\n",
    "            )\n",
    "        self.num_words = num_words\n",
    "        self.CNNs = nn.ModuleList(tmp_cnn_models)\n",
    "        self.MyMaxPool = nn.MaxPool2d((1, num_char_encoding_size), stride= (1,1))\n",
    "        self.MyFCN = nn.Linear(sum(nums_filter)*max_len_char, output_size[1])\n",
    "    def forward(self, x):\n",
    "        batch_size, num_word, num_char, embedding_size = x.size()\n",
    "        #print(x.size())\n",
    "        tmp_compute = x.view(batch_size, num_word, 1, num_char, \\\n",
    "        embedding_size)\n",
    "        all_output_list = []\n",
    "        for num_word in range(self.num_words):\n",
    "            tmp_output_cnn = []\n",
    "            for tmp_cnn in self.CNNs:\n",
    "                tmp_output_cnn.append(self.MyMaxPool(tmp_cnn(tmp_compute[:,\\\n",
    "                num_word,:,:,:])).view((batch_size, -1)))\n",
    "            all_output_list.append(F.relu(self.MyFCN(torch.cat(tmp_output_cnn, 1))))\n",
    "        #print(all_output_list[0].size())\n",
    "        #print(len(all_output_list))\n",
    "        all_output_list = torch.stack(all_output_list, dim=1)\n",
    "        return all_output_list\n",
    "                \n",
    "class gru_crf(nn.Module):\n",
    "    def __init__(self, num_input_features: '(int) number of input features', hidden_size: '(int) number of\\\n",
    "    hidden features the outputs will also have hidden_size features', num_layers: '(int) number of \\\n",
    "    recursion', dropout_gru, bidirectional: '(bool) if True, use bidirectional GRU',\\\n",
    "    tags: \"(dict[int: str])example: {0:'I', 1:'B', 2:'O', 3:'<PAD>'}\", dropout_FCN: '(double)'):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=num_input_features, hidden_size=hidden_size, num_layers=num_layers,\\\n",
    "        batch_first = True, dropout=dropout_gru, bidirectional=bidirectional)\n",
    "        #all_transition=allowed_transitions('IOB1', tags)\n",
    "        #self.crf = CRF(num_tags=len(tags), batch_first= True)\n",
    "        self.linear = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, len(tags))\n",
    "        self.crf = ConditionalRandomField(len(tags))\n",
    "        self.dropout = nn.Dropout(dropout_FCN)\n",
    "        \n",
    "    def forward(self, samples, target: '(torch.tensor) shape=(...............,)the target tags to be used',\\\n",
    "                mask: 'True for non-pad elements'):\n",
    "        length = samples[1]\n",
    "        samples = samples[0]\n",
    "        batch_size, words, _ = samples.size()\n",
    "        tmp_t = time()\n",
    "        tmp_compute = self.gru(samples)[0].view(batch_size, words, -1)\n",
    "#         print(f'total GRU time: {time() - tmp_t}')\n",
    "        index_to_cut = max(length).item()#get_longest_seq_len(mask)\n",
    "        #length = torch.mean(length.float()).item()\n",
    "        ##############################################\n",
    "        ###cut padding some parts out#################\n",
    "        tmp_compute = tmp_compute[:, :index_to_cut,:]\n",
    "        target = target[:, :index_to_cut]\n",
    "        mask = mask[:, :index_to_cut]\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_compute = self.dropout(tmp_compute)\n",
    "        tmp_compute = F.relu(self.linear(tmp_compute))\n",
    "        tmp_compute = self.dropout(tmp_compute)\n",
    "        tmp_compute = F.relu(self.linear2(tmp_compute))\n",
    "        #print(tmp_compute.size())\n",
    "        nll_loss = self.crf(tmp_compute,target.long(),mask)\n",
    "#         print(f'total CRF time: {time() - tmp_t}')\n",
    "        return nll_loss#/length\n",
    "    def predict(self, samples, mask):\n",
    "        length = samples[1]\n",
    "        samples = samples[0]\n",
    "        batch_size, words, _ = samples.size()\n",
    "        tmp_t = time()\n",
    "        tmp_compute = self.gru(samples)[0].view(batch_size, words, -1)\n",
    "#         print(f'total GRU time: {time() - tmp_t}')\n",
    "        index_to_cut = max(length).item()#get_longest_seq_len(mask)\n",
    "        ##############################################\n",
    "        ###cut padding some parts out#################\n",
    "        tmp_compute = tmp_compute[:, :index_to_cut,:]\n",
    "        mask = mask[:, :index_to_cut]\n",
    "        #print(tmp_compute.size())\n",
    "        \n",
    "        tmp_compute = F.relu(self.linear(tmp_compute))\n",
    "        tmp_compute = F.relu(self.linear2(tmp_compute))\n",
    "        #print(tmp_compute.size())\n",
    "        tmp_t = time()\n",
    "        tmp_tags = self.crf.viterbi_tags(tmp_compute,mask)\n",
    "#         print(f'total CRF prediction time: {time() - tmp_t}')\n",
    "        return tmp_tags\n",
    "    \n",
    "class My2DConv(nn.Module):\n",
    "    def __init__(self, num_filter: '(int) number of filters', use_BN: '(bool) if True, use 2d-batchnorm after linear conv',\\\n",
    "    activation_func: '(bool) if True, use RELU after BN', input_channel: '(int) number of input channels', \\\n",
    "    kernel_size: '(tuple): (width, height) size of the kernels', same_padding: '(bool) if True, input_w,input_h=output_w,output_h'):\n",
    "        super().__init__()\n",
    "        if same_padding:\n",
    "            #assume that dialation = 1 and stride = 1\n",
    "            self.padding = (math.floor((kernel_size[0] - 1)/2), math.floor((kernel_size[1] -1)/2))\n",
    "        else:\n",
    "            self.padding = 0\n",
    "        self.Conv = nn.Conv2d(input_channel, num_filter, kernel_size, padding= self.padding)\n",
    "        self.use_BN = use_BN\n",
    "        self.activation_func = activation_func\n",
    "        if self.use_BN:\n",
    "            self.BN = nn.BatchNorm2d(num_filter)\n",
    "\n",
    "    def forward(self, input_data: '(torch.tensor) dimension= (batch_size, num_channel_in, in_height, in_width)') \\\n",
    "    -> '(torch.tensor) shape= (batch_size, num_filter, in_height, in_width)':\n",
    "        tmp_compute = self.Conv(input_data.float())\n",
    "        if self.use_BN:\n",
    "            tmp_compute = self.BN(tmp_compute)\n",
    "        if self.activation_func:\n",
    "            tmp_compute = nn.ReLU()(tmp_compute)\n",
    "        return tmp_compute\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2))\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)\n",
    "\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "class AttentionBetweenWordsAndChars(nn.Module):\n",
    "    def __init__(self, hidden_size: '(int) size of key, query and value vectors',\\\n",
    "    input_vec_size: '(int) incase of fasttext input_vec_size=300'):\n",
    "        super().__init__()\n",
    "        self.K_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.Q_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.V_FCN = nn.Linear(input_vec_size, hidden_size)\n",
    "        self.AttLayer = ScaledDotProductAttention(math.sqrt(hidden_size), 0.1)\n",
    "    def forward(self, char_vectors, word_vectors):\n",
    "        batch_size, word_size, _ = word_vectors.size()\n",
    "        word_vectors = word_vectors.float()\n",
    "        char_vectors = char_vectors.float()\n",
    "#         print(word_vectors.size())\n",
    "#         print(char_vectors.size())\n",
    "        K = torch.stack([self.K_FCN(word_vectors),self.K_FCN(char_vectors)],dim = 2)\n",
    "        Q = torch.stack([self.Q_FCN(word_vectors),self.Q_FCN(char_vectors)],dim = 2)\n",
    "        V = torch.stack([self.V_FCN(word_vectors),self.V_FCN(char_vectors)],dim = 2)\n",
    "        all_output_list = []\n",
    "        for word_ind in range(word_size):\n",
    "            all_output_list.append(self.AttLayer(Q[:,word_ind,:,:], \\\n",
    "            K[:,word_ind,:,:], V[:,word_ind,:,:])[0].view(batch_size,-1))\n",
    "\n",
    "        return torch.stack(all_output_list,dim = 1)\n",
    "    \n",
    "class over_all_NER(nn.Module):\n",
    "    def __init__(self, Batch_size: '(int)',\\\n",
    "                 size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "                 max_len_char: '(int) see overall_char_embedding',\\\n",
    "                 num_conv_filters: '(list[int]) see in overall_char_embedding', \\\n",
    "                 use_BN: '(bool) see in overall_char_embedding', \\\n",
    "                 use_activation: '(bool) see in overall_char_embedding', \\\n",
    "                 num_conv_input_channel: '(int) see in overall_char_embedding', \\\n",
    "                 kernel_sizes: '(list[tuple[int, int]]) see in overall_char_embedding', \\\n",
    "                 use_same_padding: '(bool) see in overall_char_embedding', \\\n",
    "                 num_words: '(int) see in overall_char_embedding', \\\n",
    "                 num_char_encoding_size: '(int) see in overall_char_embedding', \\\n",
    "                 att_hidden_size: '(int) see in AttentionBetweenWordsAndChars', \\\n",
    "                 num_input_features: '(int) see in gru_crf', gru_hidden_size: '(int) see in gru_crf', \\\n",
    "                 dropout_gru: '(double) see in gru_crf', bidirectional: '(bool)', \\\n",
    "                 tags: '(dict[int: str]) see in gru_crf'):\n",
    "        super().__init__()\n",
    "        self.char_embed = overall_char_embedding((Batch_size,size_of_embedding), max_len_char, num_conv_filters, \\\n",
    "                                                 use_BN, use_activation, num_conv_input_channel, kernel_sizes, \\\n",
    "                                                 use_same_padding, num_words, num_char_encoding_size)\n",
    "        self.my_attention = AttentionBetweenWordsAndChars(att_hidden_size, size_of_embedding)\n",
    "        self.gru_crf_layer = gru_crf(num_input_features, gru_hidden_size, num_words, dropout_gru, \\\n",
    "                                bidirectional, tags)\n",
    "        self.Batch_size = Batch_size\n",
    "    def forward(self, x):\n",
    "        tmp_compute = self.char_embed(x[0])\n",
    "        tmp_att = self.my_attention(tmp_compute, x[1])\n",
    "        tmp_gru_crf = self.gru_crf_layer(tmp_att, x[2], x[3].long())\n",
    "        return tmp_gru_crf#/self.Batch_size\n",
    "    def predict(self, x):\n",
    "        tmp_compute = self.char_embed(x[0])\n",
    "        tmp_att = self.my_attention(tmp_compute, x[1])\n",
    "        tmp_tags = self.gru_crf_layer.predict(tmp_att, x[3].long())\n",
    "        return tmp_tags\n",
    "\n",
    "def get_indices_random_train_test_split(dataset_size:'(int) number of rows', random_seed: '(int)',\\\n",
    "                                        validation_split: '(double)', shuffle_dataset: '(bool)'):\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return train_sampler, valid_sampler\n",
    "  \n",
    "def get_indices_random_val_test_split(dataset_size:'(int) number of rows', random_seed: '(int)',\\\n",
    "                                        validation_split: '(double)', shuffle_dataset: '(bool)'):\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    test_indices, val_indices = indices[split: 2*split], indices[:split]\n",
    "    # Creating PT data samplers and loaders:\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    return test_sampler, valid_sampler\n",
    "\n",
    "def eval_score(tags: '(dict[int: str])', pred: '(list[(list, float)])', label: 'torch.tensor'):\n",
    "    pred = np.array([np.array(i[0]) for i in pred])\n",
    "    label = label.cpu().numpy().astype('int8')\n",
    "    label = [label[i][:len(pred[i])] for i in range(len(pred))]\n",
    "    conf_mat = np.zeros((len(tags), len(tags)))\n",
    "#     print(len(label))\n",
    "#     print(len(pred))\n",
    "#     print('---------------')\n",
    "    for i in range(len(label)):\n",
    "#         print(len(label[i]))\n",
    "#         print(len(pred[i]))\n",
    "        conf_mat += confusion_matrix(label[i],pred[i],range(len(tags)))\n",
    "    performance_mat = np.zeros((len(tags), 3))#recall, precision, f1-score\n",
    "    for i in range(len(tags)):\n",
    "        if np.sum(conf_mat[i]) == 0:\n",
    "            performance_mat[i][0] = 0\n",
    "        else:\n",
    "            performance_mat[i][0] = conf_mat[i][i]/np.sum(conf_mat[i])\n",
    "        if np.sum(conf_mat[:,i]) == 0:\n",
    "            performance_mat[i][1] = 0\n",
    "        else:\n",
    "            performance_mat[i][1] = conf_mat[i][i]/np.sum(conf_mat[:,i])\n",
    "        if performance_mat[i][1]+performance_mat[i][0] == 0:\n",
    "            performance_mat[i][2] = 0\n",
    "        else:\n",
    "            performance_mat[i][2] = (2*performance_mat[i][0]*performance_mat[i][1])/(performance_mat[i][1]+performance_mat[i][0])\n",
    "    return performance_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "epoch 0\n",
      "0\n",
      "time per batch: 4.17745304107666\n",
      "tensor(42.5975, grad_fn=<MulBackward>)\n",
      "time per batch: 2.901552200317383\n",
      "tensor(100.1544, grad_fn=<MulBackward>)\n",
      "time per batch: 2.372246026992798\n",
      "tensor(61.3648, grad_fn=<MulBackward>)\n",
      "time per batch: 2.416790008544922\n",
      "tensor(73.5869, grad_fn=<MulBackward>)\n",
      "time per batch: 2.3500452041625977\n",
      "tensor(81.5008, grad_fn=<MulBackward>)\n",
      "5\n",
      "time per batch: 2.4607222080230713\n",
      "tensor(58.1430, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4254212379455566\n",
      "tensor(74.5243, grad_fn=<MulBackward>)\n",
      "time per batch: 2.3986759185791016\n",
      "tensor(130.3741, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4162909984588623\n",
      "tensor(49.1455, grad_fn=<MulBackward>)\n",
      "time per batch: 2.427771806716919\n",
      "tensor(33.7512, grad_fn=<MulBackward>)\n",
      "10\n",
      "time per batch: 2.3170104026794434\n",
      "tensor(45.8107, grad_fn=<MulBackward>)\n",
      "time per batch: 2.5479819774627686\n",
      "tensor(46.8537, grad_fn=<MulBackward>)\n",
      "time per batch: 2.463021755218506\n",
      "tensor(47.6579, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4610238075256348\n",
      "tensor(45.2003, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4637579917907715\n",
      "tensor(49.8008, grad_fn=<MulBackward>)\n",
      "15\n",
      "time per batch: 2.4872519969940186\n",
      "tensor(57.1823, grad_fn=<MulBackward>)\n",
      "time per batch: 2.451835870742798\n",
      "tensor(60.7307, grad_fn=<MulBackward>)\n",
      "time per batch: 2.799398899078369\n",
      "tensor(27.0416, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 60.30113220214844\n",
      "testing\n",
      "[[0.         0.         0.        ]\n",
      " [0.05555556 0.05555556 0.05555556]\n",
      " [0.91318882 0.93945907 0.92452166]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.326692404496192\n",
      "--------------------\n",
      "epoch 1\n",
      "0\n",
      "time per batch: 2.1884899139404297\n",
      "tensor(39.4730, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4781010150909424\n",
      "tensor(48.9578, grad_fn=<MulBackward>)\n",
      "time per batch: 2.41287899017334\n",
      "tensor(50.4240, grad_fn=<MulBackward>)\n",
      "time per batch: 2.427678108215332\n",
      "tensor(116.1294, grad_fn=<MulBackward>)\n",
      "time per batch: 2.606065034866333\n",
      "tensor(55.8254, grad_fn=<MulBackward>)\n",
      "5\n",
      "time per batch: 3.0333032608032227\n",
      "tensor(74.8548, grad_fn=<MulBackward>)\n",
      "time per batch: 2.7333061695098877\n",
      "tensor(38.0399, grad_fn=<MulBackward>)\n",
      "time per batch: 2.638143301010132\n",
      "tensor(46.3716, grad_fn=<MulBackward>)\n",
      "time per batch: 2.772073984146118\n",
      "tensor(63.6482, grad_fn=<MulBackward>)\n",
      "time per batch: 2.6667561531066895\n",
      "tensor(29.3469, grad_fn=<MulBackward>)\n",
      "10\n",
      "time per batch: 2.977363109588623\n",
      "tensor(56.4148, grad_fn=<MulBackward>)\n",
      "time per batch: 2.437894105911255\n",
      "tensor(78.7128, grad_fn=<MulBackward>)\n",
      "time per batch: 2.8768551349639893\n",
      "tensor(27.1548, grad_fn=<MulBackward>)\n",
      "time per batch: 2.4744057655334473\n",
      "tensor(49.6284, grad_fn=<MulBackward>)\n",
      "time per batch: 2.8349242210388184\n",
      "tensor(30.3884, grad_fn=<MulBackward>)\n",
      "15\n",
      "time per batch: 2.4513792991638184\n",
      "tensor(64.1658, grad_fn=<MulBackward>)\n",
      "time per batch: 2.484029769897461\n",
      "tensor(37.1270, grad_fn=<MulBackward>)\n",
      "time per batch: 2.3258609771728516\n",
      "tensor(83.6838, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 55.019264221191406\n",
      "testing\n",
      "[[0.         0.         0.        ]\n",
      " [0.05555556 0.05555556 0.05555556]\n",
      " [0.91946024 0.93965561 0.92844629]\n",
      " [0.         0.         0.        ]]\n",
      "overall score: 0.3280006152164777\n",
      "--------------------\n",
      "epoch 2\n",
      "0\n",
      "time per batch: 2.2447071075439453\n",
      "tensor(66.8276, grad_fn=<MulBackward>)\n",
      "time per batch: 3.0451979637145996\n",
      "tensor(65.9215, grad_fn=<MulBackward>)\n",
      "time per batch: 2.916518211364746\n",
      "tensor(36.3964, grad_fn=<MulBackward>)\n",
      "time per batch: 2.847944974899292\n",
      "tensor(38.3397, grad_fn=<MulBackward>)\n",
      "time per batch: 3.3143978118896484\n",
      "tensor(65.6907, grad_fn=<MulBackward>)\n",
      "5\n",
      "time per batch: 3.1391851902008057\n",
      "tensor(39.4991, grad_fn=<MulBackward>)\n",
      "time per batch: 3.783554792404175\n",
      "tensor(38.5180, grad_fn=<MulBackward>)\n",
      "time per batch: 2.916192054748535\n",
      "tensor(48.5648, grad_fn=<MulBackward>)\n",
      "time per batch: 2.9892048835754395\n",
      "tensor(72.9235, grad_fn=<MulBackward>)\n",
      "time per batch: 3.379408836364746\n",
      "tensor(93.6782, grad_fn=<MulBackward>)\n",
      "10\n",
      "time per batch: 3.5297319889068604\n",
      "tensor(47.9432, grad_fn=<MulBackward>)\n",
      "time per batch: 4.528730869293213\n",
      "tensor(68.9992, grad_fn=<MulBackward>)\n",
      "time per batch: 3.695003032684326\n",
      "tensor(25.6352, grad_fn=<MulBackward>)\n",
      "time per batch: 2.7957940101623535\n",
      "tensor(52.7484, grad_fn=<MulBackward>)\n",
      "time per batch: 3.051600217819214\n",
      "tensor(46.2495, grad_fn=<MulBackward>)\n",
      "15\n",
      "time per batch: 3.501244068145752\n",
      "tensor(58.6961, grad_fn=<MulBackward>)\n",
      "time per batch: 3.115799903869629\n",
      "tensor(41.0924, grad_fn=<MulBackward>)\n",
      "time per batch: 3.809262990951538\n",
      "tensor(13.3285, grad_fn=<MulBackward>)\n",
      "total loss of epoch: 51.1695442199707\n",
      "testing\n"
     ]
    }
   ],
   "source": [
    "BS = 4\n",
    "tags = {0:'I', 1:'B', 2:'O', 3:'<pad>'}\n",
    "scheduler_n = 15\n",
    "word_length = 84\n",
    "early_stop_n = 5\n",
    "max_size_char = 6\n",
    "num_search = 50\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "data = MyDataloader('../clean84withpos.txt', '../label84withpos.txt', RULEs, \\\n",
    "                    word_length, '|', 'char_vec_dictionary.txt',max_size_char, \\\n",
    "                    '../fasttext.th.vec', 300, device, '../pos_tag84withpos.txt',POSMAP)\n",
    "\n",
    "\n",
    "tr, te = get_indices_random_val_test_split(len(data), 1, 0.0005, True)\n",
    "train_loader = DataLoader(data, batch_size=BS, sampler=tr)\n",
    "test_loader = DataLoader(data, batch_size=BS, sampler=te)\n",
    "\n",
    "# NER = over_all_NER(BS,300, max_size_char, num_kernels,True,True,1,kernel_sizes,\\\n",
    "#                    True,word_length,135,attention_in, attention_out, gru_hidden_size, \\\n",
    "#                    gru_dropout, True, tags)\n",
    "#####\n",
    "# Batch_size: '(int)',\\\n",
    "#                  num_char_vec_features: '(int)',\\\n",
    "#                  hidden_size: '(int)',\\\n",
    "#                  max_num_char: '(int)',\\\n",
    "#                  dropout_gru_char: '(double)',\\\n",
    "#                  bidirectional_char: '(bool)',\\\n",
    "#                  output_char_embed_size: '(int)',\\\n",
    "#                  size_of_embedding: '(int) size of each word embedding vector',\\\n",
    "#                  num_words: '(int) see in overall_char_embedding', \\\n",
    "#                  gru_hidden_size: '(int) see in gru_crf', \\\n",
    "#                  dropout_gru: '(double) see in gru_crf', \\\n",
    "#                  bidirectional: '(bool)', \\\n",
    "#                  tags: '(dict[int: str]) see in gru_crf', DO_FCN_GRUCRF: '(double)', DOchar_FCN: '(double)')\n",
    "#####\n",
    "for cur_ind in range(num_search):\n",
    "    torch.cuda.empty_cache()\n",
    "    grucrf_dropout = random.uniform(0.1,0.6)#0.5\n",
    "    gruchar_dropout = random.uniform(0.1,0.6)#0.5\n",
    "    DO_FCN_GRUCRF = random.uniform(0.1,0.6)#0.5\n",
    "    DO_FCN_CHAR = random.uniform(0.1,0.6)#0.5\n",
    "    grucrf_hidden_size = random.choice([8,16,32,64,128])#5\n",
    "    hidden_size_char_gru = random.choice([8,16,32,64,128])#20\n",
    "    LR = 5*10**random.uniform(-3,-5)#0.001\n",
    "    with open('my_logs.txt', 'a', encoding ='utf8') as f:\n",
    "        f.write(f'cur_ind: {cur_ind}\\n')\n",
    "        f.write(f'grucrf_dropout: {grucrf_dropout}, gruchar_dropout: {gruchar_dropout}\\n')\n",
    "        f.write(f'DO_FCN_GRUCRF: {DO_FCN_GRUCRF}, DO_FCN_CHAR: {DO_FCN_CHAR}\\n')\n",
    "        f.write(f'grucrf_hidden_size: {grucrf_hidden_size}, hidden_size_char_gru: {hidden_size_char_gru}\\n')\n",
    "        f.write(f'LR: {LR}\\n')\n",
    "\n",
    "    NER = over_all_NER2(BS, 135, hidden_size_char_gru, max_size_char, gruchar_dropout,\\\n",
    "        True, 100, 300, word_length, grucrf_hidden_size, grucrf_dropout, True, \\\n",
    "            tags, DO_FCN_GRUCRF, DO_FCN_CHAR, len(POSMAP))\n",
    "\n",
    "    optimizer = optim.Adam(NER.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4, amsgrad=True)\n",
    "    my_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "    print(device)\n",
    "    NER.to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_mat = np.zeros((len(tags)-1,3))\n",
    "    cnt_idle = 0\n",
    "    for epoch in range(6):\n",
    "        print(f'epoch {epoch}')\n",
    "        all_loss = []\n",
    "        for ind, batch_x in enumerate(train_loader):\n",
    "            if ind%5 == 0:\n",
    "                print(ind)\n",
    "\n",
    "            NER = NER.train()\n",
    "            NER.zero_grad()\n",
    "            t1 = time()\n",
    "            loss = NER(batch_x)\n",
    "            loss = loss*(-1)\n",
    "            print(f'time per batch: {time() - t1}')\n",
    "            print(loss)\n",
    "            all_loss.append(loss)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_value_(NER.parameters(), 10)\n",
    "            optimizer.step()\n",
    "        total_loss = sum(all_loss)/(ind + 1)\n",
    "        my_scheduler.step(total_loss)\n",
    "        print(f'total loss of epoch: {total_loss.item()}')\n",
    "        print('testing')\n",
    "        per_mat = np.zeros((len(tags), 3))\n",
    "        for ind, batch_test in enumerate(test_loader):\n",
    "            NER = NER.eval()\n",
    "            output = NER.predict(batch_test)\n",
    "            per_mat += eval_score(tags, output, batch_test[2])\n",
    "        per_mat = per_mat/(ind+1)\n",
    "        per_mat = per_mat[:len(tags),:]\n",
    "        print(per_mat)\n",
    "        score = sum(per_mat[:,2])/(len(tags)-1)\n",
    "        if best_score < score:\n",
    "            best_mat=per_mat\n",
    "            best_score = score\n",
    "            cnt_idle = 0\n",
    "        else:\n",
    "            cnt_idle += 1\n",
    "        print(f'overall score: {score}')\n",
    "        print('--------------------')\n",
    "        if early_stop_n == cnt_idle:\n",
    "            break\n",
    "    with open('my_logs.txt', 'a', encoding ='utf8') as f:\n",
    "        f.write(f'best_score: {best_score}\\n')\n",
    "        f.write(f'best_mat\\n')\n",
    "        f.write(f'I => recall: {best_mat[0,0]}, precision: {best_mat[0,1]}, , f1: {best_mat[0,2]}\\n')\n",
    "        f.write(f'B => recall: {best_mat[1,0]}, precision: {best_mat[1,1]}, , f1: {best_mat[1,2]}\\n')\n",
    "        f.write(f'O => recall: {best_mat[2,0]}, precision: {best_mat[2,1]}, , f1: {best_mat[2,2]}\\n')\n",
    "        f.write(f'best_mat\\n')\n",
    "        f.write(f'----------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "allennlp2",
   "language": "python",
   "name": "allennlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
